[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Voleon R Bootcamp",
    "section": "",
    "text": "The bootcamp will be a fast-paced introduction to R, with the assumption that attendees have some previous programming experience, such as in Python, R, MATLAB, or Julia.\nPlease check the preparation guide to be prepared in advance.",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Voleon R Bootcamp",
    "section": "Schedule",
    "text": "Schedule\n\n\n   Session 0 (optional)\n\n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Tue June 24 (11 am - noon, Pacific):\n           \n           Module 0 Basic Introduction to R Syntax\n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Session 1\n\n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Tue June 24 (1-5 pm, Pacific):\n           \n           Module 1 Data Structures and Manipulations\n           \n                \n           \n                \n           \n        \n\n           \n           \n           Module 2 Calculations and Efficiency\n           \n                \n           \n                \n           \n        \n\n           \n           \n           Module 3 Programming Concepts\n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Session 2\n\n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Thu June 26 (1-5 pm, Pacific):\n           \n           Module 4 Data Wrangling (Tidyverse and data.table)\n           \n                \n           \n                \n           \n        \n\n           \n           \n           Module 5 Plotting (ggplot)\n           \n                \n           \n                \n           \n        \n\n           \n           \n           Module 6 Analysis and Common Packages\n           \n                \n           \n                \n           \n        \n\n           \n           \n           Module 7 Speeding Up R: Parallelization and Rcpp\n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n\nNo matching items",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "prep.html",
    "href": "prep.html",
    "title": "Preparation",
    "section": "",
    "text": "If your version of R is older than 4.0.0, please install the latest version (R 4.5.1).\nTo install R, see:\n\nMacOS: https://cran.rstudio.com/bin/macosx.\n\nYou’ll need to choose between the version for the newer M1/M2 Macs (Apple Silicon / ARM) and older Intel-based Macs.\n\nWindows: https://cran.rstudio.com/bin/windows/base/\nLinux: https://cran.rstudio.com/bin/linux/\n\nThen install RStudio. To do so, see https://posit.co/download/rstudio-desktop and click the blue button to download for your operating system (or in some cases you may need look up the version for your operating system in the table).\nOnce you have RStudio installed, verify that you can install add-on R packages by installing the gapminder package. In RStudio, select Tools -&gt; Install Packages in the top menu bar. In the resulting dialog box, enter ‘gapminder’ (without quotes) in the ‘Packages’ field.\nThat should just work, but there’s a chance there might be a slight complication. Depending on the location specified in the ‘Install to Library’ field, you may need to enter your administrator password. To be able to install packages to the directory of an individual user, you may need to do the following:\n\nIn R, enter the command Sys.getenv()['R_LIBS_USER'].\nCreate the directory specified in the result that R returns, e.g., on a Mac, this might be ~/Library/R/4.5/library.\n\nR has many, many add-on packages that provide additional functionality. We’ll use some of them during the bootcamp, and it’s best if you’ve already installed them (though you can install them as needed).\nTo install the packages for the bootcamp, please run the following command within R (note as of 2025-06-18 – this list will likely change a bit over the next few days):\ninstall.packages(c('chron','colorspace','codetools','data.table', 'DBI','devtools','dichromat','digest',\n  'dplyr', 'fields', 'future', 'gapminder', 'ggplot2', 'gridExtra','gtable','inline','iterators',\n  'knitr','labeling','lattice','mapproj','maps','munsell', 'patchwork', 'proftools', 'proto', 'rbenchmark',\n  'RColorBrewer','Rcpp','reshape2','rJava','RSQLite','scales','spam', 'stringr','tidyr','xtable'),\n  repos = \"https://cran.r-project.org\")",
    "crumbs": [
      "Preparation"
    ]
  },
  {
    "objectID": "prep.html#installing-r-and-rstudio",
    "href": "prep.html#installing-r-and-rstudio",
    "title": "Preparation",
    "section": "",
    "text": "If your version of R is older than 4.0.0, please install the latest version (R 4.5.1).\nTo install R, see:\n\nMacOS: https://cran.rstudio.com/bin/macosx.\n\nYou’ll need to choose between the version for the newer M1/M2 Macs (Apple Silicon / ARM) and older Intel-based Macs.\n\nWindows: https://cran.rstudio.com/bin/windows/base/\nLinux: https://cran.rstudio.com/bin/linux/\n\nThen install RStudio. To do so, see https://posit.co/download/rstudio-desktop and click the blue button to download for your operating system (or in some cases you may need look up the version for your operating system in the table).\nOnce you have RStudio installed, verify that you can install add-on R packages by installing the gapminder package. In RStudio, select Tools -&gt; Install Packages in the top menu bar. In the resulting dialog box, enter ‘gapminder’ (without quotes) in the ‘Packages’ field.\nThat should just work, but there’s a chance there might be a slight complication. Depending on the location specified in the ‘Install to Library’ field, you may need to enter your administrator password. To be able to install packages to the directory of an individual user, you may need to do the following:\n\nIn R, enter the command Sys.getenv()['R_LIBS_USER'].\nCreate the directory specified in the result that R returns, e.g., on a Mac, this might be ~/Library/R/4.5/library.\n\nR has many, many add-on packages that provide additional functionality. We’ll use some of them during the bootcamp, and it’s best if you’ve already installed them (though you can install them as needed).\nTo install the packages for the bootcamp, please run the following command within R (note as of 2025-06-18 – this list will likely change a bit over the next few days):\ninstall.packages(c('chron','colorspace','codetools','data.table', 'DBI','devtools','dichromat','digest',\n  'dplyr', 'fields', 'future', 'gapminder', 'ggplot2', 'gridExtra','gtable','inline','iterators',\n  'knitr','labeling','lattice','mapproj','maps','munsell', 'patchwork', 'proftools', 'proto', 'rbenchmark',\n  'RColorBrewer','Rcpp','reshape2','rJava','RSQLite','scales','spam', 'stringr','tidyr','xtable'),\n  repos = \"https://cran.r-project.org\")",
    "crumbs": [
      "Preparation"
    ]
  },
  {
    "objectID": "prep.html#optional-module-0-r-syntax",
    "href": "prep.html#optional-module-0-r-syntax",
    "title": "Preparation",
    "section": "Optional Module “0”: R syntax",
    "text": "Optional Module “0”: R syntax\nThis module will cover the basics of R syntax, including basic syntax for programming such a if-then-else, for loops, and defining functions.\nIf you’ve never used R, I suggest that you do the following in advance of the first half-day session on June 24:\n\nWork through module 0 in advance on your own, trying out the basic syntax to start to develop some “muscle memory”.\nIf you think it would help to see a demo after you’ve looked at the syntax yourself, please join us for the optional module 0 demo that I’ll present 11 am - noon on Day 1.",
    "crumbs": [
      "Preparation"
    ]
  },
  {
    "objectID": "units/analysis.html",
    "href": "units/analysis.html",
    "title": "Basic Analysis/Useful Packages",
    "section": "",
    "text": "glm fits a generalized linear model with your choice of family/link function (Gaussian, logit, Poisson, etc.)\n\nlm is just a standard linear regression (equivalent to glm with family = gaussian(link = “identity”))\n\nThe basic glm call looks something like this:\n\nglm(formula = y ~ x1 + x2 + x3 + ..., family = familyname(link = \"linkname\"),\n            data = )\n\nThere are a bunch of families and links to use (help(family) for a full list), but some essentials are:\n\nbinomial(link = \"logit\")\ngaussian(link = \"identity\")\npoisson(link = \"log\")\n\nIf you’re using lm, the call looks the same but without the family argument.\nExample: suppose we want to regress the life expectency on the GDP per capita and the population, as well as the continent and year. The lm/glm call would be something like this:\n\nreg &lt;- lm(formula = lifeExp ~ log(gdpPercap) + log(pop) + continent + year, \n                data = gapminder)\n\n\n\n\n\n\n\n# View components contained in the regression output\nnames(reg)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"contrasts\"     \"xlevels\"       \"call\"          \"terms\"        \n[13] \"model\"        \n\n# Examine regression coefficients\nreg$coefficients\n\n      (Intercept)    log(gdpPercap)          log(pop) continentAmericas \n     -460.8132741         5.0756110         0.1530312         8.7453560 \n    continentAsia   continentEurope  continentOceania              year \n        6.8254916        12.2808442        12.5398669         0.2377202 \n\n# Examine regression degrees of freedom\nreg$df.residual\n\n[1] 1696\n\n# See the standard (diagnostic) plots for a regression\nplot(reg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(reg)\n\n\nCall:\nlm(formula = lifeExp ~ log(gdpPercap) + log(pop) + continent + \n    year, data = gapminder)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.0572  -3.2857   0.3289   3.7062  15.0650 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -4.608e+02  1.697e+01 -27.154   &lt;2e-16 ***\nlog(gdpPercap)     5.076e+00  1.627e-01  31.191   &lt;2e-16 ***\nlog(pop)           1.530e-01  9.668e-02   1.583    0.114    \ncontinentAmericas  8.745e+00  4.766e-01  18.349   &lt;2e-16 ***\ncontinentAsia      6.825e+00  4.232e-01  16.128   &lt;2e-16 ***\ncontinentEurope    1.228e+01  5.292e-01  23.205   &lt;2e-16 ***\ncontinentOceania   1.254e+01  1.281e+00   9.788   &lt;2e-16 ***\nyear               2.377e-01  8.932e-03  26.614   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.811 on 1696 degrees of freedom\nMultiple R-squared:  0.7985,    Adjusted R-squared:  0.7976 \nF-statistic:   960 on 7 and 1696 DF,  p-value: &lt; 2.2e-16\n\n\nOne can also extract useful things from the summary object\n\n# Store summary method results\nsumm_reg &lt;- summary(reg)\n# View summary method results objects\nobjects(summ_reg)\n\n [1] \"adj.r.squared\" \"aliased\"       \"call\"          \"coefficients\" \n [5] \"cov.unscaled\"  \"df\"            \"fstatistic\"    \"r.squared\"    \n [9] \"residuals\"     \"sigma\"         \"terms\"        \n\n# View table of coefficients\nsumm_reg$coefficients\n\n                      Estimate   Std. Error    t value      Pr(&gt;|t|)\n(Intercept)       -460.8132741 16.970277820 -27.154138 3.961833e-135\nlog(gdpPercap)       5.0756110  0.162724177  31.191499 3.371693e-169\nlog(pop)             0.1530312  0.096677948   1.582897  1.136315e-01\ncontinentAmericas    8.7453560  0.476599244  18.349496  9.605994e-69\ncontinentAsia        6.8254916  0.423203644  16.128149  1.492420e-54\ncontinentEurope     12.2808442  0.529239698  23.204692 1.123344e-103\ncontinentOceania    12.5398669  1.281141831   9.788040  4.798636e-22\nyear                 0.2377202  0.008932106  26.614126 1.058968e-130\n\n\nNote that, in our results, R has broken up our variables into their different factor levels (as it will do whenever your regressors have factor levels)\nIf your data aren’t factorized, you can tell lm/glm to factorize a variable (i.e. create dummy variables on the fly), e.g.:\n\nglm(formula = y ~ x1 + x2 + factor(x3), family = family(link = \"link\"),\n            data = )\n\n\n\n\n\nThere are also some useful shortcuts for regressing on interaction terms:\nx1:x2 interacts all terms in x1 with all terms in x2\n\nsummary(lm(lifeExp ~ log(gdpPercap) + log(pop) +\n                    continent:factor(year), \n                    data = gapminder))\n\n\nCall:\nlm(formula = lifeExp ~ log(gdpPercap) + log(pop) + continent:factor(year), \n    data = gapminder)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5678  -2.5530   0.0044   2.9146  15.5667 \n\nCoefficients: (1 not defined because of singularities)\n                                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         27.18384    4.68490   5.802 7.83e-09 ***\nlog(gdpPercap)                       5.07950    0.16049  31.650  &lt; 2e-16 ***\nlog(pop)                             0.07894    0.09427   0.837 0.402510    \ncontinentAfrica:factor(year)1952   -24.14252    4.11250  -5.871 5.25e-09 ***\ncontinentAmericas:factor(year)1952 -16.44650    4.16627  -3.948 8.23e-05 ***\ncontinentAsia:factor(year)1952     -19.33470    4.14083  -4.669 3.27e-06 ***\ncontinentEurope:factor(year)1952    -7.09176    4.13518  -1.715 0.086537 .  \ncontinentOceania:factor(year)1952   -6.06350    5.65111  -1.073 0.283440    \ncontinentAfrica:factor(year)1957   -22.49637    4.10985  -5.474 5.09e-08 ***\ncontinentAmericas:factor(year)1957 -14.36734    4.16433  -3.450 0.000575 ***\ncontinentAsia:factor(year)1957     -17.17434    4.13753  -4.151 3.48e-05 ***\ncontinentEurope:factor(year)1957    -5.90941    4.13272  -1.430 0.152934    \ncontinentOceania:factor(year)1957   -5.62997    5.65034  -0.996 0.319206    \ncontinentAfrica:factor(year)1962   -21.01387    4.10690  -5.117 3.47e-07 ***\ncontinentAmericas:factor(year)1962 -12.31354    4.16305  -2.958 0.003143 ** \ncontinentAsia:factor(year)1962     -15.56258    4.13513  -3.764 0.000173 ***\ncontinentEurope:factor(year)1962    -5.05421    4.13082  -1.224 0.221302    \ncontinentOceania:factor(year)1962   -5.31223    5.64979  -0.940 0.347226    \ncontinentAfrica:factor(year)1967   -19.70336    4.10348  -4.802 1.72e-06 ***\ncontinentAmericas:factor(year)1967 -10.93238    4.16129  -2.627 0.008690 ** \ncontinentAsia:factor(year)1967     -13.15690    4.13270  -3.184 0.001482 ** \ncontinentEurope:factor(year)1967    -4.91343    4.12905  -1.190 0.234232    \ncontinentOceania:factor(year)1967   -5.77117    5.64916  -1.022 0.307122    \ncontinentAfrica:factor(year)1972   -18.14692    4.10075  -4.425 1.03e-05 ***\ncontinentAmericas:factor(year)1972  -9.65366    4.15954  -2.321 0.020417 *  \ncontinentAsia:factor(year)1972     -11.60139    4.12929  -2.810 0.005020 ** \ncontinentEurope:factor(year)1972    -4.97628    4.12753  -1.206 0.228133    \ncontinentOceania:factor(year)1972   -5.80936    5.64868  -1.028 0.303891    \ncontinentAfrica:factor(year)1977   -16.18475    4.09960  -3.948 8.22e-05 ***\ncontinentAmericas:factor(year)1977  -8.33819    4.15801  -2.005 0.045092 *  \ncontinentAsia:factor(year)1977     -10.12201    4.12699  -2.453 0.014285 *  \ncontinentEurope:factor(year)1977    -4.55230    4.12667  -1.103 0.270128    \ncontinentOceania:factor(year)1977   -5.12322    5.64848  -0.907 0.364535    \ncontinentAfrica:factor(year)1982   -14.19333    4.09899  -3.463 0.000549 ***\ncontinentAmericas:factor(year)1982  -6.59214    4.15772  -1.586 0.113041    \ncontinentAsia:factor(year)1982      -7.60009    4.12571  -1.842 0.065636 .  \ncontinentEurope:factor(year)1982    -4.11846    4.12623  -0.998 0.318370    \ncontinentOceania:factor(year)1982   -4.05526    5.64827  -0.718 0.472882    \ncontinentAfrica:factor(year)1987   -12.18504    4.09947  -2.972 0.002998 ** \ncontinentAmericas:factor(year)1987  -4.71568    4.15765  -1.134 0.256870    \ncontinentAsia:factor(year)1987      -5.69142    4.12491  -1.380 0.167846    \ncontinentEurope:factor(year)1987    -3.72976    4.12583  -0.904 0.366126    \ncontinentOceania:factor(year)1987   -3.51642    5.64805  -0.623 0.533640    \ncontinentAfrica:factor(year)1992   -11.80275    4.09942  -2.879 0.004039 ** \ncontinentAmericas:factor(year)1992  -3.28548    4.15749  -0.790 0.429492    \ncontinentAsia:factor(year)1992      -4.38228    4.12405  -1.063 0.288113    \ncontinentEurope:factor(year)1992    -2.51508    4.12618  -0.610 0.542249    \ncontinentOceania:factor(year)1992   -1.98041    5.64799  -0.351 0.725904    \ncontinentAfrica:factor(year)1997   -11.95773    4.09861  -2.918 0.003576 ** \ncontinentAmericas:factor(year)1997  -2.16110    4.15661  -0.520 0.603190    \ncontinentAsia:factor(year)1997      -3.50157    4.12279  -0.849 0.395826    \ncontinentEurope:factor(year)1997    -2.08430    4.12564  -0.505 0.613482    \ncontinentOceania:factor(year)1997   -1.44783    5.64778  -0.256 0.797710    \ncontinentAfrica:factor(year)2002   -12.52375    4.09722  -3.057 0.002274 ** \ncontinentAmericas:factor(year)2002  -0.98980    4.15641  -0.238 0.811804    \ncontinentAsia:factor(year)2002      -2.67982    4.12205  -0.650 0.515707    \ncontinentEurope:factor(year)2002    -1.57345    4.12518  -0.381 0.702937    \ncontinentOceania:factor(year)2002   -0.47345    5.64768  -0.084 0.933201    \ncontinentAfrica:factor(year)2007   -11.65685    4.09478  -2.847 0.004472 ** \ncontinentAmericas:factor(year)2007  -0.69311    4.15497  -0.167 0.867536    \ncontinentAsia:factor(year)2007      -2.20076    4.12023  -0.534 0.593320    \ncontinentEurope:factor(year)2007    -1.52841    4.12475  -0.371 0.711024    \ncontinentOceania:factor(year)2007         NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.648 on 1642 degrees of freedom\nMultiple R-squared:  0.8157,    Adjusted R-squared:  0.8088 \nF-statistic: 119.1 on 61 and 1642 DF,  p-value: &lt; 2.2e-16\n\n\nx1*x2 produces the cross of x1 and x2, or x1+x2+x1:x2\n\nsummary(lm(lifeExp ~ log(gdpPercap) + log(pop) + continent*factor(year), \n                data = gapminder))\n\n\nCall:\nlm(formula = lifeExp ~ log(gdpPercap) + log(pop) + continent * \n    factor(year), data = gapminder)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5678  -2.5530   0.0044   2.9146  15.5667 \n\nCoefficients:\n                                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         3.04133    2.07409   1.466 0.142746    \nlog(gdpPercap)                      5.07950    0.16049  31.650  &lt; 2e-16 ***\nlog(pop)                            0.07894    0.09427   0.837 0.402510    \ncontinentAmericas                   7.69602    1.39324   5.524 3.85e-08 ***\ncontinentAsia                       4.80781    1.26567   3.799 0.000151 ***\ncontinentEurope                    17.05075    1.32948  12.825  &lt; 2e-16 ***\ncontinentOceania                   18.07902    4.08899   4.421 1.05e-05 ***\nfactor(year)1957                    1.64615    1.10777   1.486 0.137470    \nfactor(year)1962                    3.12865    1.10838   2.823 0.004819 ** \nfactor(year)1967                    4.43915    1.10969   4.000 6.61e-05 ***\nfactor(year)1972                    5.99560    1.11134   5.395 7.85e-08 ***\nfactor(year)1977                    7.95776    1.11240   7.154 1.27e-12 ***\nfactor(year)1982                    9.94918    1.11336   8.936  &lt; 2e-16 ***\nfactor(year)1987                   11.95748    1.11375  10.736  &lt; 2e-16 ***\nfactor(year)1992                   12.33976    1.11463  11.071  &lt; 2e-16 ***\nfactor(year)1997                   12.18479    1.11605  10.918  &lt; 2e-16 ***\nfactor(year)2002                   11.61877    1.11805  10.392  &lt; 2e-16 ***\nfactor(year)2007                   12.48567    1.12120  11.136  &lt; 2e-16 ***\ncontinentAmericas:factor(year)1957  0.43301    1.94383   0.223 0.823748    \ncontinentAsia:factor(year)1957      0.51422    1.77764   0.289 0.772410    \ncontinentEurope:factor(year)1957   -0.46380    1.83127  -0.253 0.800095    \ncontinentOceania:factor(year)1957  -1.21261    5.75524  -0.211 0.833150    \ncontinentAmericas:factor(year)1962  1.00431    1.94383   0.517 0.605458    \ncontinentAsia:factor(year)1962      0.64348    1.77767   0.362 0.717414    \ncontinentEurope:factor(year)1962   -1.09110    1.83146  -0.596 0.551422    \ncontinentOceania:factor(year)1962  -2.37738    5.75524  -0.413 0.679601    \ncontinentAmericas:factor(year)1967  1.07497    1.94383   0.553 0.580329    \ncontinentAsia:factor(year)1967      1.73865    1.77767   0.978 0.328194    \ncontinentEurope:factor(year)1967   -2.26082    1.83170  -1.234 0.217278    \ncontinentOceania:factor(year)1967  -4.14682    5.75524  -0.721 0.471302    \ncontinentAmericas:factor(year)1972  0.79724    1.94383   0.410 0.681756    \ncontinentAsia:factor(year)1972      1.73772    1.77790   0.977 0.328513    \ncontinentEurope:factor(year)1972   -3.88011    1.83221  -2.118 0.034348 *  \ncontinentOceania:factor(year)1972  -5.74146    5.75524  -0.998 0.318618    \ncontinentAmericas:factor(year)1977  0.15055    1.94389   0.077 0.938277    \ncontinentAsia:factor(year)1977      1.25493    1.77837   0.706 0.480498    \ncontinentEurope:factor(year)1977   -5.41829    1.83293  -2.956 0.003160 ** \ncontinentOceania:factor(year)1977  -7.01748    5.75525  -1.219 0.222899    \ncontinentAmericas:factor(year)1982 -0.09483    1.94391  -0.049 0.961100    \ncontinentAsia:factor(year)1982      1.78543    1.77884   1.004 0.315670    \ncontinentEurope:factor(year)1982   -6.97588    1.83363  -3.804 0.000147 ***\ncontinentOceania:factor(year)1982  -7.94094    5.75529  -1.380 0.167847    \ncontinentAmericas:factor(year)1987 -0.22666    1.94400  -0.117 0.907197    \ncontinentAsia:factor(year)1987      1.68580    1.77960   0.947 0.343629    \ncontinentEurope:factor(year)1987   -8.59548    1.83497  -4.684 3.04e-06 ***\ncontinentOceania:factor(year)1987  -9.41040    5.75542  -1.635 0.102230    \ncontinentAmericas:factor(year)1992  0.82125    1.94407   0.422 0.672760    \ncontinentAsia:factor(year)1992      2.61266    1.78035   1.468 0.142431    \ncontinentEurope:factor(year)1992   -7.76308    1.83465  -4.231 2.45e-05 ***\ncontinentOceania:factor(year)1992  -8.25667    5.75549  -1.435 0.151599    \ncontinentAmericas:factor(year)1997  2.10061    1.94427   1.080 0.280118    \ncontinentAsia:factor(year)1997      3.64834    1.78125   2.048 0.040700 *  \ncontinentEurope:factor(year)1997   -7.17732    1.83581  -3.910 9.62e-05 ***\ncontinentOceania:factor(year)1997  -7.56911    5.75567  -1.315 0.188670    \ncontinentAmericas:factor(year)2002  3.83793    1.94418   1.974 0.048542 *  \ncontinentAsia:factor(year)2002      5.03611    1.78142   2.827 0.004755 ** \ncontinentEurope:factor(year)2002   -6.10046    1.83686  -3.321 0.000916 ***\ncontinentOceania:factor(year)2002  -6.02872    5.75579  -1.047 0.295061    \ncontinentAmericas:factor(year)2007  3.26772    1.94437   1.681 0.093029 .  \ncontinentAsia:factor(year)2007      4.64828    1.78228   2.608 0.009188 ** \ncontinentEurope:factor(year)2007   -6.92231    1.83777  -3.767 0.000171 ***\ncontinentOceania:factor(year)2007  -6.42217    5.75579  -1.116 0.264682    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.648 on 1642 degrees of freedom\nMultiple R-squared:  0.8157,    Adjusted R-squared:  0.8088 \nF-statistic: 119.1 on 61 and 1642 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Modules",
      "Basic Analysis/Useful Packages"
    ]
  },
  {
    "objectID": "units/analysis.html#regression-output",
    "href": "units/analysis.html#regression-output",
    "title": "Basic Analysis/Useful Packages",
    "section": "",
    "text": "# View components contained in the regression output\nnames(reg)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"contrasts\"     \"xlevels\"       \"call\"          \"terms\"        \n[13] \"model\"        \n\n# Examine regression coefficients\nreg$coefficients\n\n      (Intercept)    log(gdpPercap)          log(pop) continentAmericas \n     -460.8132741         5.0756110         0.1530312         8.7453560 \n    continentAsia   continentEurope  continentOceania              year \n        6.8254916        12.2808442        12.5398669         0.2377202 \n\n# Examine regression degrees of freedom\nreg$df.residual\n\n[1] 1696\n\n# See the standard (diagnostic) plots for a regression\nplot(reg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(reg)\n\n\nCall:\nlm(formula = lifeExp ~ log(gdpPercap) + log(pop) + continent + \n    year, data = gapminder)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.0572  -3.2857   0.3289   3.7062  15.0650 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -4.608e+02  1.697e+01 -27.154   &lt;2e-16 ***\nlog(gdpPercap)     5.076e+00  1.627e-01  31.191   &lt;2e-16 ***\nlog(pop)           1.530e-01  9.668e-02   1.583    0.114    \ncontinentAmericas  8.745e+00  4.766e-01  18.349   &lt;2e-16 ***\ncontinentAsia      6.825e+00  4.232e-01  16.128   &lt;2e-16 ***\ncontinentEurope    1.228e+01  5.292e-01  23.205   &lt;2e-16 ***\ncontinentOceania   1.254e+01  1.281e+00   9.788   &lt;2e-16 ***\nyear               2.377e-01  8.932e-03  26.614   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.811 on 1696 degrees of freedom\nMultiple R-squared:  0.7985,    Adjusted R-squared:  0.7976 \nF-statistic:   960 on 7 and 1696 DF,  p-value: &lt; 2.2e-16\n\n\nOne can also extract useful things from the summary object\n\n# Store summary method results\nsumm_reg &lt;- summary(reg)\n# View summary method results objects\nobjects(summ_reg)\n\n [1] \"adj.r.squared\" \"aliased\"       \"call\"          \"coefficients\" \n [5] \"cov.unscaled\"  \"df\"            \"fstatistic\"    \"r.squared\"    \n [9] \"residuals\"     \"sigma\"         \"terms\"        \n\n# View table of coefficients\nsumm_reg$coefficients\n\n                      Estimate   Std. Error    t value      Pr(&gt;|t|)\n(Intercept)       -460.8132741 16.970277820 -27.154138 3.961833e-135\nlog(gdpPercap)       5.0756110  0.162724177  31.191499 3.371693e-169\nlog(pop)             0.1530312  0.096677948   1.582897  1.136315e-01\ncontinentAmericas    8.7453560  0.476599244  18.349496  9.605994e-69\ncontinentAsia        6.8254916  0.423203644  16.128149  1.492420e-54\ncontinentEurope     12.2808442  0.529239698  23.204692 1.123344e-103\ncontinentOceania    12.5398669  1.281141831   9.788040  4.798636e-22\nyear                 0.2377202  0.008932106  26.614126 1.058968e-130\n\n\nNote that, in our results, R has broken up our variables into their different factor levels (as it will do whenever your regressors have factor levels)\nIf your data aren’t factorized, you can tell lm/glm to factorize a variable (i.e. create dummy variables on the fly), e.g.:\n\nglm(formula = y ~ x1 + x2 + factor(x3), family = family(link = \"link\"),\n            data = )",
    "crumbs": [
      "Modules",
      "Basic Analysis/Useful Packages"
    ]
  },
  {
    "objectID": "units/analysis.html#setting-up-regression-interactions",
    "href": "units/analysis.html#setting-up-regression-interactions",
    "title": "Basic Analysis/Useful Packages",
    "section": "",
    "text": "There are also some useful shortcuts for regressing on interaction terms:\nx1:x2 interacts all terms in x1 with all terms in x2\n\nsummary(lm(lifeExp ~ log(gdpPercap) + log(pop) +\n                    continent:factor(year), \n                    data = gapminder))\n\n\nCall:\nlm(formula = lifeExp ~ log(gdpPercap) + log(pop) + continent:factor(year), \n    data = gapminder)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5678  -2.5530   0.0044   2.9146  15.5667 \n\nCoefficients: (1 not defined because of singularities)\n                                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         27.18384    4.68490   5.802 7.83e-09 ***\nlog(gdpPercap)                       5.07950    0.16049  31.650  &lt; 2e-16 ***\nlog(pop)                             0.07894    0.09427   0.837 0.402510    \ncontinentAfrica:factor(year)1952   -24.14252    4.11250  -5.871 5.25e-09 ***\ncontinentAmericas:factor(year)1952 -16.44650    4.16627  -3.948 8.23e-05 ***\ncontinentAsia:factor(year)1952     -19.33470    4.14083  -4.669 3.27e-06 ***\ncontinentEurope:factor(year)1952    -7.09176    4.13518  -1.715 0.086537 .  \ncontinentOceania:factor(year)1952   -6.06350    5.65111  -1.073 0.283440    \ncontinentAfrica:factor(year)1957   -22.49637    4.10985  -5.474 5.09e-08 ***\ncontinentAmericas:factor(year)1957 -14.36734    4.16433  -3.450 0.000575 ***\ncontinentAsia:factor(year)1957     -17.17434    4.13753  -4.151 3.48e-05 ***\ncontinentEurope:factor(year)1957    -5.90941    4.13272  -1.430 0.152934    \ncontinentOceania:factor(year)1957   -5.62997    5.65034  -0.996 0.319206    \ncontinentAfrica:factor(year)1962   -21.01387    4.10690  -5.117 3.47e-07 ***\ncontinentAmericas:factor(year)1962 -12.31354    4.16305  -2.958 0.003143 ** \ncontinentAsia:factor(year)1962     -15.56258    4.13513  -3.764 0.000173 ***\ncontinentEurope:factor(year)1962    -5.05421    4.13082  -1.224 0.221302    \ncontinentOceania:factor(year)1962   -5.31223    5.64979  -0.940 0.347226    \ncontinentAfrica:factor(year)1967   -19.70336    4.10348  -4.802 1.72e-06 ***\ncontinentAmericas:factor(year)1967 -10.93238    4.16129  -2.627 0.008690 ** \ncontinentAsia:factor(year)1967     -13.15690    4.13270  -3.184 0.001482 ** \ncontinentEurope:factor(year)1967    -4.91343    4.12905  -1.190 0.234232    \ncontinentOceania:factor(year)1967   -5.77117    5.64916  -1.022 0.307122    \ncontinentAfrica:factor(year)1972   -18.14692    4.10075  -4.425 1.03e-05 ***\ncontinentAmericas:factor(year)1972  -9.65366    4.15954  -2.321 0.020417 *  \ncontinentAsia:factor(year)1972     -11.60139    4.12929  -2.810 0.005020 ** \ncontinentEurope:factor(year)1972    -4.97628    4.12753  -1.206 0.228133    \ncontinentOceania:factor(year)1972   -5.80936    5.64868  -1.028 0.303891    \ncontinentAfrica:factor(year)1977   -16.18475    4.09960  -3.948 8.22e-05 ***\ncontinentAmericas:factor(year)1977  -8.33819    4.15801  -2.005 0.045092 *  \ncontinentAsia:factor(year)1977     -10.12201    4.12699  -2.453 0.014285 *  \ncontinentEurope:factor(year)1977    -4.55230    4.12667  -1.103 0.270128    \ncontinentOceania:factor(year)1977   -5.12322    5.64848  -0.907 0.364535    \ncontinentAfrica:factor(year)1982   -14.19333    4.09899  -3.463 0.000549 ***\ncontinentAmericas:factor(year)1982  -6.59214    4.15772  -1.586 0.113041    \ncontinentAsia:factor(year)1982      -7.60009    4.12571  -1.842 0.065636 .  \ncontinentEurope:factor(year)1982    -4.11846    4.12623  -0.998 0.318370    \ncontinentOceania:factor(year)1982   -4.05526    5.64827  -0.718 0.472882    \ncontinentAfrica:factor(year)1987   -12.18504    4.09947  -2.972 0.002998 ** \ncontinentAmericas:factor(year)1987  -4.71568    4.15765  -1.134 0.256870    \ncontinentAsia:factor(year)1987      -5.69142    4.12491  -1.380 0.167846    \ncontinentEurope:factor(year)1987    -3.72976    4.12583  -0.904 0.366126    \ncontinentOceania:factor(year)1987   -3.51642    5.64805  -0.623 0.533640    \ncontinentAfrica:factor(year)1992   -11.80275    4.09942  -2.879 0.004039 ** \ncontinentAmericas:factor(year)1992  -3.28548    4.15749  -0.790 0.429492    \ncontinentAsia:factor(year)1992      -4.38228    4.12405  -1.063 0.288113    \ncontinentEurope:factor(year)1992    -2.51508    4.12618  -0.610 0.542249    \ncontinentOceania:factor(year)1992   -1.98041    5.64799  -0.351 0.725904    \ncontinentAfrica:factor(year)1997   -11.95773    4.09861  -2.918 0.003576 ** \ncontinentAmericas:factor(year)1997  -2.16110    4.15661  -0.520 0.603190    \ncontinentAsia:factor(year)1997      -3.50157    4.12279  -0.849 0.395826    \ncontinentEurope:factor(year)1997    -2.08430    4.12564  -0.505 0.613482    \ncontinentOceania:factor(year)1997   -1.44783    5.64778  -0.256 0.797710    \ncontinentAfrica:factor(year)2002   -12.52375    4.09722  -3.057 0.002274 ** \ncontinentAmericas:factor(year)2002  -0.98980    4.15641  -0.238 0.811804    \ncontinentAsia:factor(year)2002      -2.67982    4.12205  -0.650 0.515707    \ncontinentEurope:factor(year)2002    -1.57345    4.12518  -0.381 0.702937    \ncontinentOceania:factor(year)2002   -0.47345    5.64768  -0.084 0.933201    \ncontinentAfrica:factor(year)2007   -11.65685    4.09478  -2.847 0.004472 ** \ncontinentAmericas:factor(year)2007  -0.69311    4.15497  -0.167 0.867536    \ncontinentAsia:factor(year)2007      -2.20076    4.12023  -0.534 0.593320    \ncontinentEurope:factor(year)2007    -1.52841    4.12475  -0.371 0.711024    \ncontinentOceania:factor(year)2007         NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.648 on 1642 degrees of freedom\nMultiple R-squared:  0.8157,    Adjusted R-squared:  0.8088 \nF-statistic: 119.1 on 61 and 1642 DF,  p-value: &lt; 2.2e-16\n\n\nx1*x2 produces the cross of x1 and x2, or x1+x2+x1:x2\n\nsummary(lm(lifeExp ~ log(gdpPercap) + log(pop) + continent*factor(year), \n                data = gapminder))\n\n\nCall:\nlm(formula = lifeExp ~ log(gdpPercap) + log(pop) + continent * \n    factor(year), data = gapminder)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5678  -2.5530   0.0044   2.9146  15.5667 \n\nCoefficients:\n                                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         3.04133    2.07409   1.466 0.142746    \nlog(gdpPercap)                      5.07950    0.16049  31.650  &lt; 2e-16 ***\nlog(pop)                            0.07894    0.09427   0.837 0.402510    \ncontinentAmericas                   7.69602    1.39324   5.524 3.85e-08 ***\ncontinentAsia                       4.80781    1.26567   3.799 0.000151 ***\ncontinentEurope                    17.05075    1.32948  12.825  &lt; 2e-16 ***\ncontinentOceania                   18.07902    4.08899   4.421 1.05e-05 ***\nfactor(year)1957                    1.64615    1.10777   1.486 0.137470    \nfactor(year)1962                    3.12865    1.10838   2.823 0.004819 ** \nfactor(year)1967                    4.43915    1.10969   4.000 6.61e-05 ***\nfactor(year)1972                    5.99560    1.11134   5.395 7.85e-08 ***\nfactor(year)1977                    7.95776    1.11240   7.154 1.27e-12 ***\nfactor(year)1982                    9.94918    1.11336   8.936  &lt; 2e-16 ***\nfactor(year)1987                   11.95748    1.11375  10.736  &lt; 2e-16 ***\nfactor(year)1992                   12.33976    1.11463  11.071  &lt; 2e-16 ***\nfactor(year)1997                   12.18479    1.11605  10.918  &lt; 2e-16 ***\nfactor(year)2002                   11.61877    1.11805  10.392  &lt; 2e-16 ***\nfactor(year)2007                   12.48567    1.12120  11.136  &lt; 2e-16 ***\ncontinentAmericas:factor(year)1957  0.43301    1.94383   0.223 0.823748    \ncontinentAsia:factor(year)1957      0.51422    1.77764   0.289 0.772410    \ncontinentEurope:factor(year)1957   -0.46380    1.83127  -0.253 0.800095    \ncontinentOceania:factor(year)1957  -1.21261    5.75524  -0.211 0.833150    \ncontinentAmericas:factor(year)1962  1.00431    1.94383   0.517 0.605458    \ncontinentAsia:factor(year)1962      0.64348    1.77767   0.362 0.717414    \ncontinentEurope:factor(year)1962   -1.09110    1.83146  -0.596 0.551422    \ncontinentOceania:factor(year)1962  -2.37738    5.75524  -0.413 0.679601    \ncontinentAmericas:factor(year)1967  1.07497    1.94383   0.553 0.580329    \ncontinentAsia:factor(year)1967      1.73865    1.77767   0.978 0.328194    \ncontinentEurope:factor(year)1967   -2.26082    1.83170  -1.234 0.217278    \ncontinentOceania:factor(year)1967  -4.14682    5.75524  -0.721 0.471302    \ncontinentAmericas:factor(year)1972  0.79724    1.94383   0.410 0.681756    \ncontinentAsia:factor(year)1972      1.73772    1.77790   0.977 0.328513    \ncontinentEurope:factor(year)1972   -3.88011    1.83221  -2.118 0.034348 *  \ncontinentOceania:factor(year)1972  -5.74146    5.75524  -0.998 0.318618    \ncontinentAmericas:factor(year)1977  0.15055    1.94389   0.077 0.938277    \ncontinentAsia:factor(year)1977      1.25493    1.77837   0.706 0.480498    \ncontinentEurope:factor(year)1977   -5.41829    1.83293  -2.956 0.003160 ** \ncontinentOceania:factor(year)1977  -7.01748    5.75525  -1.219 0.222899    \ncontinentAmericas:factor(year)1982 -0.09483    1.94391  -0.049 0.961100    \ncontinentAsia:factor(year)1982      1.78543    1.77884   1.004 0.315670    \ncontinentEurope:factor(year)1982   -6.97588    1.83363  -3.804 0.000147 ***\ncontinentOceania:factor(year)1982  -7.94094    5.75529  -1.380 0.167847    \ncontinentAmericas:factor(year)1987 -0.22666    1.94400  -0.117 0.907197    \ncontinentAsia:factor(year)1987      1.68580    1.77960   0.947 0.343629    \ncontinentEurope:factor(year)1987   -8.59548    1.83497  -4.684 3.04e-06 ***\ncontinentOceania:factor(year)1987  -9.41040    5.75542  -1.635 0.102230    \ncontinentAmericas:factor(year)1992  0.82125    1.94407   0.422 0.672760    \ncontinentAsia:factor(year)1992      2.61266    1.78035   1.468 0.142431    \ncontinentEurope:factor(year)1992   -7.76308    1.83465  -4.231 2.45e-05 ***\ncontinentOceania:factor(year)1992  -8.25667    5.75549  -1.435 0.151599    \ncontinentAmericas:factor(year)1997  2.10061    1.94427   1.080 0.280118    \ncontinentAsia:factor(year)1997      3.64834    1.78125   2.048 0.040700 *  \ncontinentEurope:factor(year)1997   -7.17732    1.83581  -3.910 9.62e-05 ***\ncontinentOceania:factor(year)1997  -7.56911    5.75567  -1.315 0.188670    \ncontinentAmericas:factor(year)2002  3.83793    1.94418   1.974 0.048542 *  \ncontinentAsia:factor(year)2002      5.03611    1.78142   2.827 0.004755 ** \ncontinentEurope:factor(year)2002   -6.10046    1.83686  -3.321 0.000916 ***\ncontinentOceania:factor(year)2002  -6.02872    5.75579  -1.047 0.295061    \ncontinentAmericas:factor(year)2007  3.26772    1.94437   1.681 0.093029 .  \ncontinentAsia:factor(year)2007      4.64828    1.78228   2.608 0.009188 ** \ncontinentEurope:factor(year)2007   -6.92231    1.83777  -3.767 0.000171 ***\ncontinentOceania:factor(year)2007  -6.42217    5.75579  -1.116 0.264682    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.648 on 1642 degrees of freedom\nMultiple R-squared:  0.8157,    Adjusted R-squared:  0.8088 \nF-statistic: 119.1 on 61 and 1642 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Modules",
      "Basic Analysis/Useful Packages"
    ]
  },
  {
    "objectID": "units/analysis.html#mgcvgam-in-action",
    "href": "units/analysis.html#mgcvgam-in-action",
    "title": "Basic Analysis/Useful Packages",
    "section": "mgcv::gam in action",
    "text": "mgcv::gam in action\nDo we think there should be a linear relationship of life expectancy with GDP and year?\n\nlibrary(mgcv)\n\nLoading required package: nlme\n\n\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\nmod &lt;- gam(lifeExp ~ s(gdpPercap, k = 30) + s(year, k = 10), data = gapminder)\n\nplot(mod)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(mod)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nlifeExp ~ s(gdpPercap, k = 30) + s(year, k = 10)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  59.4744     0.1605   370.6   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                edf Ref.df     F p-value    \ns(gdpPercap) 12.619  15.50 226.4  &lt;2e-16 ***\ns(year)       3.148   3.91 110.9  &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.737   Deviance explained = 73.9%\nGCV = 44.315  Scale est. = 43.879    n = 1704\n\nmod2 &lt;- gam(lifeExp ~ s(log(gdpPercap), k = 30) + s(year, k = 10), data = gapminder)\nplot(mod2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding on that, we could use the same kind of functionality as in lm/glm in terms of factors and interactions.",
    "crumbs": [
      "Modules",
      "Basic Analysis/Useful Packages"
    ]
  },
  {
    "objectID": "units/analysis.html#how-does-gam-choose-how-much-to-smooth",
    "href": "units/analysis.html#how-does-gam-choose-how-much-to-smooth",
    "title": "Basic Analysis/Useful Packages",
    "section": "How does GAM choose how much to smooth?",
    "text": "How does GAM choose how much to smooth?\nGAM uses the data to choose how much smoothing to do. Roughly one can think of what it is doing as carrying out cross-validation and choosing the best amount of smoothing for predicting held-out data, but without having to actually do cross-validation.\nk simply sets an upper bound on the amount of smoothing (you can think of k as the number of degrees of freedom - “1” would be a linear fit).\n\nMake sure k is less than the number of unique values of the predictor variable\nThe default for k is relatively small and in some cases this may overly limit the smoothness of the curve.\n\nYou can try increasing k and see if it improves the fit.\nIf summary reports an edf that is close to k that often suggests that k should be increased.",
    "crumbs": [
      "Modules",
      "Basic Analysis/Useful Packages"
    ]
  },
  {
    "objectID": "units/analysis.html#distributions-in-action",
    "href": "units/analysis.html#distributions-in-action",
    "title": "Basic Analysis/Useful Packages",
    "section": "Distributions in action",
    "text": "Distributions in action\n\npnorm(1.96)\n\n[1] 0.9750021\n\nqnorm(.975)\n\n[1] 1.959964\n\ndbinom(0:10, size = 10, prob = 0.3)\n\n [1] 0.0282475249 0.1210608210 0.2334744405 0.2668279320 0.2001209490\n [6] 0.1029193452 0.0367569090 0.0090016920 0.0014467005 0.0001377810\n[11] 0.0000059049\n\ndnorm(5)\n\n[1] 1.48672e-06\n\ndt(5, df = 1)\n\n[1] 0.01224269\n\nx &lt;- seq(-5, 5, length = 100)\nplot(x, dnorm(x), type = 'l')\nlines(x, dt(x, df = 1), col = 'red')\n\n\n\n\n\n\n\n\n\nrmultinom(1, 100, prob = c(.1, .1, .2, .3, .25, .05)) \n\n     [,1]\n[1,]    9\n[2,]   11\n[3,]   24\n[4,]   35\n[5,]   18\n[6,]    3\n\nx &lt;- seq(0, 10, length = 100)\nplot(x, dchisq(x, df = 1), type = 'l')\nlines(x, dchisq(x, df = 2), col = 'red')",
    "crumbs": [
      "Modules",
      "Basic Analysis/Useful Packages"
    ]
  },
  {
    "objectID": "units/analysis.html#sampling-from-a-finite-set",
    "href": "units/analysis.html#sampling-from-a-finite-set",
    "title": "Basic Analysis/Useful Packages",
    "section": "Sampling from a finite set",
    "text": "Sampling from a finite set\nWe can draw a sample with or without replacement.\n\nsample(1:nrow(gapminder), 20, replace = FALSE)\n\n [1]  706  321  119 1516   67 1238  650  344  313 1614  120  141  717  620   40\n[16]  459 1249 1352  977  259\n\n\nHere’s an example of some code that would be part of coding up a bootstrap. As I mentioned previously, this would be a weird dataset to do formal statistical inference on given it includes most of the countries in the world, though one could think about fitting models for the variation over time, treating short-term fluctuations as random.\n\n# actual mean\nmean(gapminder$lifeExp, na.rm = TRUE)\n\n[1] 59.47444\n\n# here's a bootstrap sample:\nsmp &lt;- sample(seq_len(nrow(gapminder)), replace = TRUE) \nmean(gapminder$lifeExp[smp], na.rm = TRUE)\n\n[1] 60.1616\n\n\nIt’s a good idea to use seq_along() and seq_len() and not syntax like 1:length(gapminder) in sample() because the outcome of length() might in some cases be unexpected (e.g., if you’re taking subsets of a dataset). Similar reasoning holds when setting up for loops: e.g.,\n\nfor(i in seq_len(nrow(gapminder))) {\n# blah\n}",
    "crumbs": [
      "Modules",
      "Basic Analysis/Useful Packages"
    ]
  },
  {
    "objectID": "units/analysis.html#the-random-seed",
    "href": "units/analysis.html#the-random-seed",
    "title": "Basic Analysis/Useful Packages",
    "section": "The Random Seed",
    "text": "The Random Seed\nA few key facts about generating random numbers\n\nRandom number generation is based on generating uniformly between 0 and 1 and then transforming to the kind of random number of interest: normal, categorical, etc.\nRandom numbers on a computer are pseudo-random; they are generated deterministically from a very, very, very long sequence that repeats\nThe seed determines where you are in that sequence\n\nTo replicate any work involving random numbers, make sure to set the seed first.\n\nset.seed(1)\nvals &lt;- sample(1:nrow(gapminder), 10)\nvals\n\n [1] 1017  679  129  930 1533  471  299  270 1211 1331\n\nvals &lt;- sample(1:nrow(gapminder), 10)\nvals\n\n [1]  597 1301 1518  330 1615   37 1129  729  878  485\n\nset.seed(1)\nvals &lt;- sample(1:nrow(gapminder), 15)\nvals[1:10]\n\n [1] 1017  679  129  930 1533  471  299  270 1211 1331\n\nvals[11:15]\n\n[1]  597 1301 1518  330 1615",
    "crumbs": [
      "Modules",
      "Basic Analysis/Useful Packages"
    ]
  },
  {
    "objectID": "units/analysis.html#dates",
    "href": "units/analysis.html#dates",
    "title": "Basic Analysis/Useful Packages",
    "section": "Dates",
    "text": "Dates\nR has built-in functionality to handle dates (don’t reinvent the wheel!).\n\ndate1 &lt;- as.Date(\"03-01-2011\", format = \"%m-%d-%Y\")\ndate2 &lt;- as.Date(\"03/02/11\", format = \"%m/%d/%y\")\ndate3 &lt;- as.Date(\"07-May-11\", format = \"%d-%b-%y\")\n\ndate1; date2\n\n[1] \"2011-03-01\"\n\n\n[1] \"2011-03-02\"\n\nclass(date1)\n\n[1] \"Date\"\n\ndates &lt;- c(date1, date2, date3)\nweekdays(dates)\n\n[1] \"Tuesday\"   \"Wednesday\" \"Saturday\" \n\ndates + 30\n\n[1] \"2011-03-31\" \"2011-04-01\" \"2011-06-06\"\n\ndate3 - date2\n\nTime difference of 66 days\n\nunclass(dates)\n\n[1] 15034 15035 15101\n\n\nThe “origin” date in R is January 1, 1970",
    "crumbs": [
      "Modules",
      "Basic Analysis/Useful Packages"
    ]
  },
  {
    "objectID": "units/tidyverse.html",
    "href": "units/tidyverse.html",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "",
    "text": "A lot of analysis time in many cases is spent on manipulating tabular data. The tidyverse provides a nice suite of packages for doing this.\nThe tidyverse is a suite of packages designed specifically to help with both these steps; some of which we will be introducing in this module. These are by no means the only packages out there for data wrangling but they are popular for their readable, straightforward syntax and sensible default behaviors.\nAn alternative for working quickly with very large datasets is the data.table package. It’s fast and a good choice. While the core syntax is not as nice, one can also use dplyr syntax with data.table objects.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#selecting-columns-dplyrselect",
    "href": "units/tidyverse.html#selecting-columns-dplyrselect",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Selecting columns: dplyr::select",
    "text": "Selecting columns: dplyr::select\nImagine that we just received the gapminder dataset, but are only interested in a few variables in it. The select() function can help us to keep only the columns corresponding to variables we select.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nyear_country_gdp_dplyr &lt;- select(gapminder, year, country, gdpPercap)\nhead(year_country_gdp_dplyr)\n\n# A tibble: 6 × 3\n   year country     gdpPercap\n  &lt;int&gt; &lt;fct&gt;           &lt;dbl&gt;\n1  1952 Afghanistan      779.\n2  1957 Afghanistan      821.\n3  1962 Afghanistan      853.\n4  1967 Afghanistan      836.\n5  1972 Afghanistan      740.\n6  1977 Afghanistan      786.\n\n\n\nWe see the new dataframe only contains the year, country and gdpPercap. This is equivalent to the base R subsetting operator:\n\nyear_country_gdp_base &lt;- gapminder[ , c(\"year\", \"country\", \"gdpPercap\")]\nhead(year_country_gdp_base)\n\n# A tibble: 6 × 3\n   year country     gdpPercap\n  &lt;int&gt; &lt;fct&gt;           &lt;dbl&gt;\n1  1952 Afghanistan      779.\n2  1957 Afghanistan      821.\n3  1962 Afghanistan      853.\n4  1967 Afghanistan      836.\n5  1972 Afghanistan      740.\n6  1977 Afghanistan      786.\n\n\nBut, as we will see, dplyr makes for much more readable, efficient code because of its pipe operator.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#piping-with-dplyr",
    "href": "units/tidyverse.html#piping-with-dplyr",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Piping with dplyr",
    "text": "Piping with dplyr\nAbove, we used what’s called “normal” grammar, but the strengths of dplyr lie in combining several functions using pipes.\nIn typical base R code, a simple operation might be written like:\n\n# NOT run\ncupcakes &lt;- bake(pour(mix(ingredients)))\n\nA computer has no trouble understanding this and your cupcakes will be made just fine but a person has to read right to left to understand the order of operations - the opposite of how most western languages are read - making it harder to understand what is being done!\nTo be more readable without pipes, we might break up this code into intermediate objects…\n\n# NOT run\nbatter &lt;- mix(ingredients)\nmuffin_tin &lt;- pour(batter)\ncupcakes &lt;- bake(muffin_tin)\n\nbut this can clutter our environment with a lot of variables that aren’t very useful to us, and often are named very similar things (e.g. step, step1, step2…) which can lead to confusion and bugs.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#enter-the-pipe",
    "href": "units/tidyverse.html#enter-the-pipe",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Enter the pipe…",
    "text": "Enter the pipe…\nThe pipe makes it easier to read code because it lays out the operations left to right so each line can be read like a line of a recipe for the perfect data frame!\nPipes take the input on the left side of the |&gt; symbol and pass it in as the first argument to the function on the right side.\nWith pipes, our cupcake example might be written like:\n\ncupcakes &lt;- ingredients |&gt; \n  mix() |&gt; \n  pour() |&gt; \n  bake()",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#pipe-example",
    "href": "units/tidyverse.html#pipe-example",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Pipe example",
    "text": "Pipe example\nLet’s repeat what we did above with the gapminder dataset using pipes:\n\nyear_country_gdp &lt;- gapminder |&gt; select(year, country, gdpPercap)\n\nFirst, we summon the gapminder data frame and pass it on to the next step using the pipe symbol |&gt;. The second step is the select() function. In this case we don’t specify which data object we use in the call to select() since we’ve piped it in.\nNote that lack of quotations around the column names. This is called “non-standard evaluation” and is used a lot in the tidyverse (including in ggplot).",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#filtering-rows-dplyrfilter",
    "href": "units/tidyverse.html#filtering-rows-dplyrfilter",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Filtering rows: dplyr::filter",
    "text": "Filtering rows: dplyr::filter\nNow let’s say we’re only interested in African countries. We can combine select and filter to select only the observations where continent is Africa.\n\nyear_country_gdp_africa &lt;- gapminder |&gt;\n    filter(continent == \"Africa\") |&gt;\n    select(year,country,gdpPercap)\n\nAs with last time, first we pass the gapminder data frame to the filter() function, then we pass the filtered version of the gapminder data frame to the select() function.\nNote: The order of operations is important in this case. If we used ‘select’ first, filter would not be able to find the variable continent since we would have removed it in the previous step.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#dplyr-calculations-across-groups-split-apply-combine",
    "href": "units/tidyverse.html#dplyr-calculations-across-groups-split-apply-combine",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "dplyr calculations across groups: split-apply-combine",
    "text": "dplyr calculations across groups: split-apply-combine\nA common task you’ll encounter when working with data is running calculations on different groups within the data. For instance, what if we wanted to calculate the mean GDP per capita for each continent?\nThis general task is known as “split-apply-combine”:\n\nWe want to split our data into groups (in this case continents), apply some calculations on each group, then combine the results together afterwards.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#stratifying-dplyrgroup_by",
    "href": "units/tidyverse.html#stratifying-dplyrgroup_by",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Stratifying: dplyr::group_by",
    "text": "Stratifying: dplyr::group_by\nWe’ve already seen how filter() can help us select observations that meet certain criteria (in the above: continent == \"Europe\"). More helpful, however, is the group_by() function, which will essentially use every unique criteria that we could have used in filter().\nA grouped_df can be thought of as a list where each item in the list is a data.frame which contains only the rows that correspond to a particular value of one or more grouping variables (continent in our example).",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#reduction-operations-dplyrsummarize",
    "href": "units/tidyverse.html#reduction-operations-dplyrsummarize",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Reduction operations: dplyr::summarize",
    "text": "Reduction operations: dplyr::summarize\ngroup_by() on its own is not particularly interesting; instead it’s generally used with summarize().\nThis will allow use to create new variable(s) by applying transformations to variables in each of the continent-specific data frames.\nIn other words, using the group_by() function, we split our original data frame into multiple pieces, which we then apply summary functions to (e.g., mean() or sd()) within summarize(). The output is a new data frame reduced in size, with one row per group.\n\ngdp_bycontinents &lt;- gapminder |&gt;\n    group_by(continent) |&gt;\n    summarize(mean_gdpPercap = mean(gdpPercap))\nhead(gdp_bycontinents)\n\n# A tibble: 5 × 2\n  continent mean_gdpPercap\n  &lt;fct&gt;              &lt;dbl&gt;\n1 Africa             2194.\n2 Americas           7136.\n3 Asia               7902.\n4 Europe            14469.\n5 Oceania           18622.\n\n\n\nThat allowed us to calculate the mean gdpPercap for each continent. But it gets even better – the function group_by() allows us to group by multiple variables. Let’s group by year and continent.\n\ngdp_bycontinents_byyear &lt;- gapminder |&gt;\n    group_by(continent, year) |&gt;\n    summarize(mean_gdpPercap = mean(gdpPercap))\n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\nhead(gdp_bycontinents_byyear)\n\n# A tibble: 6 × 3\n# Groups:   continent [1]\n  continent  year mean_gdpPercap\n  &lt;fct&gt;     &lt;int&gt;          &lt;dbl&gt;\n1 Africa     1952          1253.\n2 Africa     1957          1385.\n3 Africa     1962          1598.\n4 Africa     1967          2050.\n5 Africa     1972          2340.\n6 Africa     1977          2586.\n\n\nYou’re not limited to defining one new variable in summarize().\n\ngdp_pop_bycontinents_byyear &lt;- gapminder |&gt;\n    group_by(continent, year) |&gt;\n    summarize(mean_gdpPercap = mean(gdpPercap),\n              sd_gdpPercap = sd(gdpPercap),\n              mean_pop = mean(pop),\n              sd_pop = sd(pop))\n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\nhead(gdp_pop_bycontinents_byyear)\n\n# A tibble: 6 × 6\n# Groups:   continent [1]\n  continent  year mean_gdpPercap sd_gdpPercap mean_pop    sd_pop\n  &lt;fct&gt;     &lt;int&gt;          &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Africa     1952          1253.         983. 4570010.  6317450.\n2 Africa     1957          1385.        1135. 5093033.  7076042.\n3 Africa     1962          1598.        1462. 5702247.  7957545.\n4 Africa     1967          2050.        2848. 6447875.  8985505.\n5 Africa     1972          2340.        3287. 7305376. 10130833.\n6 Africa     1977          2586.        4142. 8328097. 11585184.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#adding-columns-dplyrmutate",
    "href": "units/tidyverse.html#adding-columns-dplyrmutate",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Adding columns: dplyr::mutate",
    "text": "Adding columns: dplyr::mutate\nWhat if we wanted to add these values to our original data frame instead of creating a new object? For this, we can use the mutate() function, which is similar to summarize() except it creates new variables in the same data frame that you pass into it.\n\ngap_with_extra_vars &lt;- gapminder |&gt;\n    group_by(continent, year) |&gt;\n    mutate(mean_gdpPercap = mean(gdpPercap),\n              sd_gdpPercap = sd(gdpPercap),\n              mean_pop = mean(pop),\n              sd_pop = sd(pop))\nhead(gap_with_extra_vars)\n\n# A tibble: 6 × 10\n# Groups:   continent, year [6]\n  country   continent  year lifeExp    pop gdpPercap mean_gdpPercap sd_gdpPercap\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;     &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1 Afghanis… Asia       1952    28.8 8.43e6      779.          5195.       18635.\n2 Afghanis… Asia       1957    30.3 9.24e6      821.          5788.       19507.\n3 Afghanis… Asia       1962    32.0 1.03e7      853.          5729.       16416.\n4 Afghanis… Asia       1967    34.0 1.15e7      836.          5971.       14063.\n5 Afghanis… Asia       1972    36.1 1.31e7      740.          8187.       19088.\n6 Afghanis… Asia       1977    38.4 1.49e7      786.          7791.       11816.\n# ℹ 2 more variables: mean_pop &lt;dbl&gt;, sd_pop &lt;dbl&gt;\n\n\nWe can use also use mutate() to create new variables prior to (or even after) summarizing information. Note that mutate() does not need to operate on grouped data and it can do element-wise transformations.\n\ngdp_pop_bycontinents_byyear &lt;- gapminder |&gt;\n    mutate(gdp_billion = gdpPercap*pop/10^9) |&gt;\n    group_by(continent, year) |&gt;\n    summarize(mean_gdpPercap = mean(gdpPercap),\n              sd_gdpPercap = sd(gdpPercap),\n              mean_pop = mean(pop),\n              sd_pop = sd(pop),\n              mean_gdp_billion = mean(gdp_billion),\n              sd_gdp_billion = sd(gdp_billion))\n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\nhead(gdp_pop_bycontinents_byyear)\n\n# A tibble: 6 × 8\n# Groups:   continent [1]\n  continent  year mean_gdpPercap sd_gdpPercap mean_pop   sd_pop mean_gdp_billion\n  &lt;fct&gt;     &lt;int&gt;          &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;\n1 Africa     1952          1253.         983. 4570010.   6.32e6             5.99\n2 Africa     1957          1385.        1135. 5093033.   7.08e6             7.36\n3 Africa     1962          1598.        1462. 5702247.   7.96e6             8.78\n4 Africa     1967          2050.        2848. 6447875.   8.99e6            11.4 \n5 Africa     1972          2340.        3287. 7305376.   1.01e7            15.1 \n6 Africa     1977          2586.        4142. 8328097.   1.16e7            18.7 \n# ℹ 1 more variable: sd_gdp_billion &lt;dbl&gt;",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#mutate-vs.-summarize",
    "href": "units/tidyverse.html#mutate-vs.-summarize",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "mutate vs. summarize",
    "text": "mutate vs. summarize\nIt can be confusing to decide whether to use mutate or summarize. The key distinction is whether you want the output to have one row for each group or one row for each row in the original data frame:\n\nmutate: creates new columns with as many rows as the original data frame\nsummarize: creates a data frame with as many rows as groups\n\nNote that if you use an aggregation function such as mean() within mutate() without using groupby(), you’ll simply do the summary over all the rows of the input data frame.\nAnd if you use an aggregation function such as mean() within summarize() without using groupby(), you’ll simply create an output data frame with one row (i.e., the whole input data frame is a single group).",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#sorting-dplyrarrange",
    "href": "units/tidyverse.html#sorting-dplyrarrange",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Sorting: dplyr::arrange",
    "text": "Sorting: dplyr::arrange\nAs a last step, let’s say we want to sort the rows in our data frame according to values in a certain column. We can use the arrange() function to do this. For instance, let’s organize our rows by year (recent first), and then by continent.\n\ngap_with_extra_vars &lt;- gapminder |&gt;\n    group_by(continent, year) |&gt;\n    mutate(mean_gdpPercap = mean(gdpPercap),\n              sd_gdpPercap = sd(gdpPercap),\n              mean_pop = mean(pop),\n              sd_pop = sd(pop)) |&gt;\n    arrange(desc(year), continent) # `desc()` = descending order\nhead(gap_with_extra_vars)\n\n# A tibble: 6 × 10\n# Groups:   continent, year [1]\n  country   continent  year lifeExp    pop gdpPercap mean_gdpPercap sd_gdpPercap\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;     &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1 Algeria   Africa     2007    72.3 3.33e7     6223.          3089.        3618.\n2 Angola    Africa     2007    42.7 1.24e7     4797.          3089.        3618.\n3 Benin     Africa     2007    56.7 8.08e6     1441.          3089.        3618.\n4 Botswana  Africa     2007    50.7 1.64e6    12570.          3089.        3618.\n5 Burkina … Africa     2007    52.3 1.43e7     1217.          3089.        3618.\n6 Burundi   Africa     2007    49.6 8.39e6      430.          3089.        3618.\n# ℹ 2 more variables: mean_pop &lt;dbl&gt;, sd_pop &lt;dbl&gt;",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#dplyr-take-aways",
    "href": "units/tidyverse.html#dplyr-take-aways",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "dplyr take-aways",
    "text": "dplyr take-aways\n\nHuman readable: the function names describe the action being done\nPiping: chain functions in a step-by-step way, rather than nesting",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#dplyr-and-non-standard-evaluation",
    "href": "units/tidyverse.html#dplyr-and-non-standard-evaluation",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "dplyr and “non-standard evaluation”",
    "text": "dplyr and “non-standard evaluation”\nYou may run across the term “non-standard evaluation”. The use of data frame variables without quotes around them is an example of this.\nWhy is this strange?\n\ngapminder |&gt; select(continent, year) |&gt; tail()\n\nCompare it to:\n\ngapminder[ , c('continent', 'year')]\ngapminder[ , 'continent']\n\nBecause continent and year are not variables our current environment! dplyr does some manipulation of language objects behind the scenes to save us from typing the quotes.\nThis is fine if you have a data analysis workflow but if you want to write a function that, for example, selects an arbitrary set of columns, you’ll run into trouble.\n\n## here's a helper function that computes the mean of a variable, stratifying by a grouping variable\ngrouped_mean &lt;- function(data, group_var, summary_var) {\n  data |&gt;\n    group_by(group_var) |&gt;\n    summarise(mean = mean(summary_var))\n}\ngapminder |&gt; grouped_mean(continent, lifeExp)\ngapminder |&gt; grouped_mean('continent', 'lifeExp')\n\nSee the rlang (or wrapr) package for how one can deal with this problem in this context of using functions.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#wide-vs.-long-formats",
    "href": "units/tidyverse.html#wide-vs.-long-formats",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Wide vs. long formats",
    "text": "Wide vs. long formats\nTabular datasets can be arranged in many ways. For instance, consider the data below. Each data set displays information on heart rate observed in individuals across 3 different time periods. But the data are organized differently in each table.\n\nwide &lt;- data.frame(\n  name = c(\"Wilbur\", \"Petunia\", \"Gregory\"),\n  time1 = c(67, 80, 64),\n  time2 = c(56, 90, 50),\n  time3 = c(70, 67, 101)\n)\nwide\n\n     name time1 time2 time3\n1  Wilbur    67    56    70\n2 Petunia    80    90    67\n3 Gregory    64    50   101\n\nlong &lt;- data.frame(\n  name = c(\"Wilbur\", \"Petunia\", \"Gregory\", \"Wilbur\", \"Petunia\", \"Gregory\", \"Wilbur\", \"Petunia\", \"Gregory\"),\n  time = c(1, 1, 1, 2, 2, 2, 3, 3, 3),\n  heartrate = c(67, 80, 64, 56, 90, 50, 70, 67, 10)\n)\nlong\n\n     name time heartrate\n1  Wilbur    1        67\n2 Petunia    1        80\n3 Gregory    1        64\n4  Wilbur    2        56\n5 Petunia    2        90\n6 Gregory    2        50\n7  Wilbur    3        70\n8 Petunia    3        67\n9 Gregory    3        10\n\n\nWe often refer to these different structures as “long” vs. “wide” formats. In the “long” format, you usually have 1 column for the observed variable and the other columns are ID variables.\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of the ‘wide’ and ‘long’ objects do you prefer in terms of how the heartrate ‘data’ are formatted?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe first data frame (the “wide” one) would not be considered tidy because values (i.e., heartrate) are spread across multiple columns.\n\n\n\nFor the “wide” format each row is often a site/subject/patient and you have multiple observation variables containing the same type of data. These can be either repeated observations over time, or observation of multiple variables (or a mix of both). In the above case, we had the same kind of data (heart rate) entered across 3 different columns, corresponding to three different time periods.\n\nYou may find data input may be simpler and some programs/functions may prefer the “wide” format. However, many of R’s functions (particularly in the tidyverse) have been designed assuming you have “long” format data.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#tidying-the-gapminder-data",
    "href": "units/tidyverse.html#tidying-the-gapminder-data",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Tidying the Gapminder data",
    "text": "Tidying the Gapminder data\nLets look at the structure of our original gapminder data frame:\n\nhead(gapminder)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\n\nQuestion: Is this data frame wide or long?\nAnswer: This data frame is somewhere in between the purely ‘long’ and ‘wide’ formats. We have 3 “ID variables” (continent, country, year) and 3 “Observation variables” (pop, lifeExp, gdpPercap).\nDespite not having ALL observations in 1 column, this intermediate format makes sense given that all 3 observation variables have different units. As we have seen, many of the functions in R are often vector based, and you usually do not want to do mathematical operations on values with different units.\nOn the other hand, there are some instances in which a purely long or wide format is ideal (e.g. plotting). Likewise, sometimes you’ll get data on your desk that is poorly organized, and you’ll need to reshape it.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#converting-to-long-format-tidyrpivot_longer",
    "href": "units/tidyverse.html#converting-to-long-format-tidyrpivot_longer",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Converting to long format: tidyr::pivot_longer",
    "text": "Converting to long format: tidyr::pivot_longer\nThe tidyr package will help you efficiently transform your data regardless of original format.\nUntil now, we’ve been using the nicely formatted original gapminder data set. This data set is not quite wide and not quite long – it’s something in the middle, but “real” data (i.e., our own research data) will never be so well organized. Here let’s start with the wide format version of the gapminder data set.\n\ngap_wide &lt;- read.csv(file.path(\"..\", \"data\", \"gapminder_wide.csv\"))\nhead(gap_wide)\n\n  continent      country gdpPercap_1952 gdpPercap_1957 gdpPercap_1962\n1    Africa      Algeria      2449.0082      3013.9760      2550.8169\n2    Africa       Angola      3520.6103      3827.9405      4269.2767\n3    Africa        Benin      1062.7522       959.6011       949.4991\n4    Africa     Botswana       851.2411       918.2325       983.6540\n5    Africa Burkina Faso       543.2552       617.1835       722.5120\n6    Africa      Burundi       339.2965       379.5646       355.2032\n  gdpPercap_1967 gdpPercap_1972 gdpPercap_1977 gdpPercap_1982 gdpPercap_1987\n1      3246.9918      4182.6638      4910.4168      5745.1602      5681.3585\n2      5522.7764      5473.2880      3008.6474      2756.9537      2430.2083\n3      1035.8314      1085.7969      1029.1613      1277.8976      1225.8560\n4      1214.7093      2263.6111      3214.8578      4551.1421      6205.8839\n5       794.8266       854.7360       743.3870       807.1986       912.0631\n6       412.9775       464.0995       556.1033       559.6032       621.8188\n  gdpPercap_1992 gdpPercap_1997 gdpPercap_2002 gdpPercap_2007 lifeExp_1952\n1      5023.2166      4797.2951      5288.0404      6223.3675       43.077\n2      2627.8457      2277.1409      2773.2873      4797.2313       30.015\n3      1191.2077      1232.9753      1372.8779      1441.2849       38.223\n4      7954.1116      8647.1423     11003.6051     12569.8518       47.622\n5       931.7528       946.2950      1037.6452      1217.0330       31.975\n6       631.6999       463.1151       446.4035       430.0707       39.031\n  lifeExp_1957 lifeExp_1962 lifeExp_1967 lifeExp_1972 lifeExp_1977 lifeExp_1982\n1       45.685       48.303       51.407       54.518       58.014       61.368\n2       31.999       34.000       35.985       37.928       39.483       39.942\n3       40.358       42.618       44.885       47.014       49.190       50.904\n4       49.618       51.520       53.298       56.024       59.319       61.484\n5       34.906       37.814       40.697       43.591       46.137       48.122\n6       40.533       42.045       43.548       44.057       45.910       47.471\n  lifeExp_1987 lifeExp_1992 lifeExp_1997 lifeExp_2002 lifeExp_2007 pop_1952\n1       65.799       67.744       69.152       70.994       72.301  9279525\n2       39.906       40.647       40.963       41.003       42.731  4232095\n3       52.337       53.919       54.777       54.406       56.728  1738315\n4       63.622       62.745       52.556       46.634       50.728   442308\n5       49.557       50.260       50.324       50.650       52.295  4469979\n6       48.211       44.736       45.326       47.360       49.580  2445618\n  pop_1957 pop_1962 pop_1967 pop_1972 pop_1977 pop_1982 pop_1987 pop_1992\n1 10270856 11000948 12760499 14760787 17152804 20033753 23254956 26298373\n2  4561361  4826015  5247469  5894858  6162675  7016384  7874230  8735988\n3  1925173  2151895  2427334  2761407  3168267  3641603  4243788  4981671\n4   474639   512764   553541   619351   781472   970347  1151184  1342614\n5  4713416  4919632  5127935  5433886  5889574  6634596  7586551  8878303\n6  2667518  2961915  3330989  3529983  3834415  4580410  5126023  5809236\n  pop_1997 pop_2002 pop_2007\n1 29072015 31287142 33333216\n2  9875024 10866106 12420476\n3  6066080  7026113  8078314\n4  1536536  1630347  1639131\n5 10352843 12251209 14326203\n6  6121610  7021078  8390505\n\n\nThe first step towards getting our nice intermediate data format is to first convert from the wide to the long format. The function pivot_longer() will ‘gather’ the observation variables into a single variable. This is sometimes called “melting” your data, because it melts the table from wide to long. Those data will be melted into two variables: one for the variable names, and the other for the variable values.\n\nlibrary(tidyr)\ngap_long &lt;- gap_wide |&gt; pivot_longer(gdpPercap_1952:pop_2007)\nhead(gap_long)\n\n# A tibble: 6 × 4\n  continent country name           value\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 Africa    Algeria gdpPercap_1952 2449.\n2 Africa    Algeria gdpPercap_1957 3014.\n3 Africa    Algeria gdpPercap_1962 2551.\n4 Africa    Algeria gdpPercap_1967 3247.\n5 Africa    Algeria gdpPercap_1972 4183.\n6 Africa    Algeria gdpPercap_1977 4910.\n\n\nFormerly one used the function gather to do this, but many people found it not to be intuitive to use.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#specifying-column-names-tidyrselect",
    "href": "units/tidyverse.html#specifying-column-names-tidyrselect",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Specifying column names: tidyr::select",
    "text": "Specifying column names: tidyr::select\nIf there are a lot of columns or they’re named in a consistent pattern, we might not want to select them using the column numbers. It’d be easier to use some information contained in the names themselves. We can select variables using:\n\nvariable indices\nvariable names (without quotes)\nx:z to select all variables between x and z\n-y to exclude y\nstarts_with(x, ignore.case = TRUE): all names that starts with x\nends_with(x, ignore.case = TRUE): all names that ends with x\ncontains(x, ignore.case = TRUE): all names that contain x\n\nSee the select() function in dplyr for more options.\nFor instance, here we do the same gather operation with (1) the starts_with function, and (2) the - operator:\n\n# with the starts_with() function\ngap_long &lt;- gap_wide |&gt;\n    pivot_longer(c(starts_with('pop'), starts_with('lifeExp'), starts_with('gdpPercap')))\nhead(gap_long)\n\n# A tibble: 6 × 4\n  continent country name        value\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;\n1 Africa    Algeria pop_1952  9279525\n2 Africa    Algeria pop_1957 10270856\n3 Africa    Algeria pop_1962 11000948\n4 Africa    Algeria pop_1967 12760499\n5 Africa    Algeria pop_1972 14760787\n6 Africa    Algeria pop_1977 17152804\n\n# with the - operator\ngap_long &lt;- gap_wide |&gt;\n  pivot_longer(c(-continent, -country))\nhead(gap_long)\n\n# A tibble: 6 × 4\n  continent country name           value\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 Africa    Algeria gdpPercap_1952 2449.\n2 Africa    Algeria gdpPercap_1957 3014.\n3 Africa    Algeria gdpPercap_1962 2551.\n4 Africa    Algeria gdpPercap_1967 3247.\n5 Africa    Algeria gdpPercap_1972 4183.\n6 Africa    Algeria gdpPercap_1977 4910.\n\n\nHowever you choose to do it, notice that the output collapses all of the measure variables into two columns: one containing new ID variable, the other containing the observation value for that row.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#cleaning-column-names-tidyrseparate",
    "href": "units/tidyverse.html#cleaning-column-names-tidyrseparate",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Cleaning column names: tidyr::separate",
    "text": "Cleaning column names: tidyr::separate\nYou’ll notice that in our long dataset, name actually contains 2 pieces of information, the observation type (pop, lifeExp, or gdpPercap) and the year.\nWe can use the separate() function to split the character strings into multiple variables:\n\ngap_long_sep &lt;- gap_long |&gt;\n  separate(name, into = c('obs_type','year'), sep = \"_\") |&gt;\n  mutate(year = as.integer(year))\nhead(gap_long_sep)\n\n# A tibble: 6 × 5\n  continent country obs_type   year value\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt;\n1 Africa    Algeria gdpPercap  1952 2449.\n2 Africa    Algeria gdpPercap  1957 3014.\n3 Africa    Algeria gdpPercap  1962 2551.\n4 Africa    Algeria gdpPercap  1967 3247.\n5 Africa    Algeria gdpPercap  1972 4183.\n6 Africa    Algeria gdpPercap  1977 4910.\n\n\nIf you didn’t use tidyr to do this, you’d have to use the strsplit function and use multiple lines of code to replace the column in gap_long with two new columns. This solution is much cleaner.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#converting-to-wide-format-tidyrpivot_wider",
    "href": "units/tidyverse.html#converting-to-wide-format-tidyrpivot_wider",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Converting to wide format: tidyr::pivot_wider",
    "text": "Converting to wide format: tidyr::pivot_wider\nThe opposite of pivot_longer() is pivot_wider(). It spreads our observation variables back out to make a wider table. We can use this function to spread our gap_long() to the original “medium” format.\n\ngap_medium &lt;- gap_long_sep |&gt;\n  pivot_wider(names_from = obs_type, values_from = value)\nhead(gap_medium)\n\n# A tibble: 6 × 6\n  continent country  year gdpPercap lifeExp      pop\n  &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 Africa    Algeria  1952     2449.    43.1  9279525\n2 Africa    Algeria  1957     3014.    45.7 10270856\n3 Africa    Algeria  1962     2551.    48.3 11000948\n4 Africa    Algeria  1967     3247.    51.4 12760499\n5 Africa    Algeria  1972     4183.    54.5 14760787\n6 Africa    Algeria  1977     4910.    58.0 17152804\n\n\nFormerly one used the function spread to do this, but many people found it not to be intuitive to use.\nAll we need is some quick fixes to make this dataset identical to the original gapminder dataset:\n\nhead(gapminder)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\n# rearrange columns\ngap_medium &lt;- gap_medium[,names(gapminder)]\nhead(gap_medium)\n\n# A tibble: 6 × 6\n  country continent  year lifeExp      pop gdpPercap\n  &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Algeria Africa     1952    43.1  9279525     2449.\n2 Algeria Africa     1957    45.7 10270856     3014.\n3 Algeria Africa     1962    48.3 11000948     2551.\n4 Algeria Africa     1967    51.4 12760499     3247.\n5 Algeria Africa     1972    54.5 14760787     4183.\n6 Algeria Africa     1977    58.0 17152804     4910.\n\n# arrange by country, continent, and year\ngap_medium &lt;- gap_medium |&gt;\n  arrange(country, continent, year)\nhead(gap_medium)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;chr&gt;       &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#extra-resources",
    "href": "units/tidyverse.html#extra-resources",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Extra Resources",
    "text": "Extra Resources\ndplyr and tidyr have many more functions to help you wrangle and manipulate your data. See the Data Wrangling Cheat Sheet for more.\nHere are some additional functions/verbs for use with dplyr:\nThere are some other useful packages in the tidyverse:\n\nggplot2 for plotting (We’ll cover this in Unit 5)\nreadr and haven for reading in data\npurrr for working with lists and operations similar to the lapply family introduced in Module 4.\nstringr, lubridate, forcats for manipulating strings, dates, and factors, respectively\nmany many more! Take a peak at the tidyverse github page…",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#data.table-syntax",
    "href": "units/tidyverse.html#data.table-syntax",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "data.table syntax",
    "text": "data.table syntax\nHere’s some syntax examples:\n\n# Filter rows:\nair[Dest == \"BOS\" & DepDelay &gt; 100]\n# Select columns:\nair[ , c(\"Dest\", \"DepDelay\")]\n# Mutate (create new columns):\nair[ , DepDelayHr := DepDelay / 60]\n# Summarize\nair[ , .(meanDelayByDest = mean(DepDelay, na.rm = TRUE)), by = Dest]\n# Chaining operations (ugly!):\nair[ , DepDelayHr := DepDelay / 60][ , .(meanDelayByDest = mean(DepDelayHr, na.rm = TRUE)), by = Dest]\n# Join:\nair[another_dt, on = \"keycolumn\"]\n# Sort:\nair[order(Dest, -DepDelay)]\n\nAn important area for efficiency is to use an index, which can improve lookup speed dramatically. For this small dataset, everyting is fast already, so it’s not a good example.\n\nair &lt;- fread(file.path('..', 'data', 'airline.csv'))\n## Subset without an index\nsystem.time(sub &lt;- air[Dest == \"BOS\"])  \n\n   user  system elapsed \n  0.027   0.000   0.016 \n\n## Now set index and subset\nsystem.time(setindex(air, Dest))\n\n   user  system elapsed \n  0.010   0.000   0.004 \n\nsystem.time(sub2 &lt;- air[Dest == \"BOS\"]) # essentially instantaneous\n\n   user  system elapsed \n  0.007   0.000   0.005 \n\n\ndata.table has a lot of functionality and can be used to do a variety of sophisticated queries and manipulations (including aggregation operations), but it has its own somewhat involved syntax and concepts. The above just scratches the surface of what you can do with it.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#using-dplyr-syntax-with-data.table",
    "href": "units/tidyverse.html#using-dplyr-syntax-with-data.table",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Using dplyr syntax with data.table",
    "text": "Using dplyr syntax with data.table\nRather than learning the data.table syntax, one can also use dplyr syntax with data.table objects.\nWe can use dplyr syntax directly with data table objects, but the efficiency may not be what you want.\n\nair &lt;- fread(file.path('..', 'data', 'airline.csv'))\n\nsystem.time(result &lt;- air[ , .(meanDelayByDest = mean(DepDelay, na.rm = TRUE)), by = Dest])  # 0.008 sec.\n\n   user  system elapsed \n  0.042   0.000   0.012 \n\nsystem.time(result &lt;- air |&gt; group_by(Dest) |&gt; summarize(meanDepDelay = mean(DepDelay)))   # 0.019 sec.\n\n   user  system elapsed \n  0.015   0.000   0.014 \n\n\nInstead, one can also use dtplyr to set use a data table as a back end for dplyr manipulations. Using lazy_dt allows dtplyr to do some optimization as it generates the translation from dplyr syntax to data table syntax, though this simple example doesn’t illustrate the usefulness of that (and using system.time for fine differentiation of timing is not generally a good idea).\n\nlibrary(dtplyr)\nlazy_air &lt;- lazy_dt(air)\nsystem.time(result &lt;- lazy_air |&gt; group_by(Dest) |&gt; summarize(meanDepDelay = mean(DepDelay))) # 0.007\n\n   user  system elapsed \n  0.005   0.000   0.006 \n\n\nFinally the tidytable package (not shown) also allows you to use dplyr syntax as well as other tidyverse syntax, such as tidyr functions.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#working-with-data-on-disk",
    "href": "units/tidyverse.html#working-with-data-on-disk",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Working with data on disk",
    "text": "Working with data on disk\nIn some cases you may not have enough memory to use tools that bring all the data into memory in R.\nSome alternatives include:\n\nDuckDB (or SQLite) databases, accessed from R\nUsing Apache Arrow via the arrow package\n\nOr you may need to move to another language, such as using Dask in Python, or database/data lake functionality provided by clould providers.",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#database-example",
    "href": "units/tidyverse.html#database-example",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Database example",
    "text": "Database example\nYou can get an example database of information about Stack Overflow questions and answers from http://www.stat.berkeley.edu/share/paciorek/stackoverflow-2016.duckdb. Stack Overflow is a website where programmers and software users can pose questions and get answers to technical problems.\n\nlibrary(duckdb)  # DBI is a dependency\n\nLoading required package: DBI\n\ndbfile &lt;- file.path(\"..\", \"data\", \"stackoverflow-2021.duckdb\")\ndb &lt;- dbConnect(duckdb(), dbfile)  # This will vary depending on the back-end database\n## stackoverflow-2016.db is an DuckDB database\n\n## The syntax below works regardless of the back-end database.\n\n## metadata\ndbListTables(db)\n\n[1] \"answers\"        \"questions\"      \"questions_tags\" \"users\"         \n\ndbListFields(db, \"questions\")\n\n[1] \"questionid\"    \"creationdate\"  \"score\"         \"viewcount\"    \n[5] \"answercount\"   \"commentcount\"  \"favoritecount\" \"title\"        \n[9] \"ownerid\"      \n\n## A simple filter operation:\npopular &lt;- dbGetQuery(db, \"select * from questions \n   where viewcount &gt; 10000\")\n## A join followed by a filter operation:\npopularR &lt;- dbGetQuery(db, \"select * from questions join questions_tags\n   on questions.questionid = questions_tags.questionid\n   where viewcount &gt; 10000 and\n   tag = 'r'\")\n\ndim(popularR)\n\n[1] 23 11\n\nclass(popularR)\n\n[1] \"data.frame\"\n\ndbDisconnect(db)",
    "crumbs": [
      "Modules",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/calculation.html",
    "href": "units/calculation.html",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "At the core of R is the idea of doing calculations on entire vectors.\n\n## Vectorized arithmetic\ngdpTotal &lt;- gapminder$gdpPercap * gapminder$pop\n\ngapminder2007 &lt;- gapminder[gapminder$year == 2007, ]\n\n## Vectorized comparisons\nwealthy &lt;- gapminder2007$gdpPercap &gt;= 30000\n\npoorOrWealthy &lt;- gapminder2007$gdpPercap &gt;= 100000 | gapminder2007$gdpPercap &lt; 1000\nasiaWealthy &lt;- gapminder2007$gdpPercap &gt;= 100000 &  gapminder$continent == \"Asia\"\n\nvec1 &lt;- rnorm(5)\nvec2 &lt;- rnorm(5)\nvec1 &gt; vec2\n\n[1] FALSE  TRUE FALSE FALSE  TRUE\n\n## Vectorized boolean operations\nvec1 == vec2\n\n[1] FALSE FALSE FALSE FALSE FALSE\n\nvec1 != vec2\n\n[1] TRUE TRUE TRUE TRUE TRUE\n\n## careful: \nvec1 = vec2\nidentical(vec1, vec2)\n\n[1] TRUE\n\n\n\n\n\nAn important related concept is that of recycling\n\nvec10 &lt;- sample(1:10, 10, replace = TRUE)\nvec3 &lt;- sample(1:10, 3, replace = TRUE)\nvec5 &lt;- sample(1:10, 5, replace = TRUE)\nvec10\n\n [1]  4  7  4  8  7  2  3  8  7 10\n\nvec3\n\n[1]  2  3 10\n\nvec5\n\n[1] 7 1 3 3 7\n\nvec10 + vec5\n\n [1] 11  8  7 11 14  9  4 11 10 17\n\nvec10 + vec3\n\nWarning in vec10 + vec3: longer object length is not a multiple of shorter\nobject length\n\n\n [1]  6 10 14 10 10 12  5 11 17 12\n\n\nWhat choices were made by the R developers?\n\n\n\nImagine how this code would look if written using a loop, or three separate loops.\n\nvals &lt;- rnorm(1000)\nchi2vals &lt;- vals^2\nchi2_df1000 &lt;- sum(chi2vals)\n\nAdvantages:\n\nmuch faster than looping\neasier to code\neasier to read and understand the code\n\nVectorized code is generally fast because the underlying loop is executed in compiled C code rather than by the R interpreter.\nWe’ve already seen that lots of functions (and operators) in R are vectorized (i.e., they can take a single value or a vector as an input argument).\n\n\n\nRecall that +, -,*, / do vectorized calculations:\n\nA &lt;- matrix(1:9, 3)\nB &lt;- matrix(seq(4,36, by = 4), 3)\n\nA*7\n\n     [,1] [,2] [,3]\n[1,]    7   28   49\n[2,]   14   35   56\n[3,]   21   42   63\n\nA + B\n\n     [,1] [,2] [,3]\n[1,]    5   20   35\n[2,]   10   25   40\n[3,]   15   30   45\n\nA + B[ , 1]\n\n     [,1] [,2] [,3]\n[1,]    5    8   11\n[2,]   10   13   16\n[3,]   15   18   21\n\nA * B\n\n     [,1] [,2] [,3]\n[1,]    4   64  196\n[2,]   16  100  256\n[3,]   36  144  324\n\nA * B[ , 1]\n\n     [,1] [,2] [,3]\n[1,]    4   16   28\n[2,]   16   40   64\n[3,]   36   72  108\n\n\n\n\n\n\nA %*% B[ , 1]\n\n     [,1]\n[1,]  120\n[2,]  144\n[3,]  168\n\nA %*% B\n\n     [,1] [,2] [,3]\n[1,]  120  264  408\n[2,]  144  324  504\n[3,]  168  384  600\n\nidentical(t(A)%*%A, crossprod(A))\n\n[1] TRUE\n\n\nNow let’s do a bit of manipulation and see if you can infer how R represents matrices internally.\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nConsider our matrix ‘mat’:\n\nmat &lt;- matrix(1:16, nrow = 4, ncol = 4)\n\nSuppose I run this code: mat[4].\nWhat do you think will be returned?\n\n13\n4\n13, 14, 15, 16\n4, 8, 12, 16\nan error\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMatrices are stored column-major\n\nmat[4]\nattributes(mat) &lt;- NULL\nmat\nis.matrix(mat)\n\nThis is like Fortran, MATLAB and Julia but not like C or Python(numpy).\n\n\n\n\n\n\nR can do essentially any linear algebra you need. It uses system-level packages called BLAS (basic linear algebra subroutines) and LAPACK (linear algebra package). Note that these calculations will be essentially as fast as if you wrote C code because R just calls C and Fortran routines to do the calculations.\nThe BLAS that comes with R is fairly slow. It’s possible to use a faster BLAS, as well as one that uses multiple cores automatically. This can in some cases give you an order of magnitude speedup if your work involves a lot of matrix manipulations/linear algebra.\n\n\n\nHere are some examples of common matrix decompositions: Cholesky decomposition, eigenvalues/eigenvectors, and SVD. These all use BLAS+LAPACK.\n\n## next 3 lines generate a positive definite matrix\nlibrary(fields)\n\nLoading required package: spam\n\n\nSpam version 2.11-1 (2025-01-20) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAttaching package: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nLoading required package: viridisLite\n\n\n\nTry help(fields) to get started.\n\ntimes &lt;- seq(0, 1, length = 100)\nR &lt;- exp(-rdist(times) / 0.2) # a correlation matrix\n######################################################\ne &lt;- eigen(R)\nrange(e$values)\n\n[1]  0.02525338 32.85537225\n\ne$vectors[ , 1]\n\n  [1] 0.05195413 0.05448567 0.05698864 0.05946173 0.06190363 0.06431308\n  [7] 0.06668879 0.06902954 0.07133409 0.07360123 0.07582978 0.07801856\n [13] 0.08016643 0.08227226 0.08433494 0.08635341 0.08832659 0.09025345\n [19] 0.09213298 0.09396420 0.09574615 0.09747789 0.09915851 0.10078713\n [25] 0.10236291 0.10388500 0.10535262 0.10676499 0.10812137 0.10942106\n [31] 0.11066337 0.11184765 0.11297327 0.11403965 0.11504623 0.11599249\n [37] 0.11687791 0.11770205 0.11846447 0.11916476 0.11980256 0.12037754\n [43] 0.12088940 0.12133786 0.12172270 0.12204370 0.12230071 0.12249358\n [49] 0.12262222 0.12268655 0.12268655 0.12262222 0.12249358 0.12230071\n [55] 0.12204370 0.12172270 0.12133786 0.12088940 0.12037754 0.11980256\n [61] 0.11916476 0.11846447 0.11770205 0.11687791 0.11599249 0.11504623\n [67] 0.11403965 0.11297327 0.11184765 0.11066337 0.10942106 0.10812137\n [73] 0.10676499 0.10535262 0.10388500 0.10236291 0.10078713 0.09915851\n [79] 0.09747789 0.09574615 0.09396420 0.09213298 0.09025345 0.08832659\n [85] 0.08635341 0.08433494 0.08227226 0.08016643 0.07801856 0.07582978\n [91] 0.07360123 0.07133409 0.06902954 0.06668879 0.06431308 0.06190363\n [97] 0.05946173 0.05698864 0.05448567 0.05195413\n\nsv &lt;- svd(R)\nU &lt;- chol(R)\n\ndevs &lt;- rnorm(100)\nRinvb &lt;- solve(R, devs)  # R^{-1} b\nRinv &lt;- solve(R) # R^{-1} -- try to avoid this (slower and less numerically stable)",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#vectorized-calculations-and-comparisons",
    "href": "units/calculation.html#vectorized-calculations-and-comparisons",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "At the core of R is the idea of doing calculations on entire vectors.\n\n## Vectorized arithmetic\ngdpTotal &lt;- gapminder$gdpPercap * gapminder$pop\n\ngapminder2007 &lt;- gapminder[gapminder$year == 2007, ]\n\n## Vectorized comparisons\nwealthy &lt;- gapminder2007$gdpPercap &gt;= 30000\n\npoorOrWealthy &lt;- gapminder2007$gdpPercap &gt;= 100000 | gapminder2007$gdpPercap &lt; 1000\nasiaWealthy &lt;- gapminder2007$gdpPercap &gt;= 100000 &  gapminder$continent == \"Asia\"\n\nvec1 &lt;- rnorm(5)\nvec2 &lt;- rnorm(5)\nvec1 &gt; vec2\n\n[1] FALSE  TRUE FALSE FALSE  TRUE\n\n## Vectorized boolean operations\nvec1 == vec2\n\n[1] FALSE FALSE FALSE FALSE FALSE\n\nvec1 != vec2\n\n[1] TRUE TRUE TRUE TRUE TRUE\n\n## careful: \nvec1 = vec2\nidentical(vec1, vec2)\n\n[1] TRUE",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#recycling",
    "href": "units/calculation.html#recycling",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "An important related concept is that of recycling\n\nvec10 &lt;- sample(1:10, 10, replace = TRUE)\nvec3 &lt;- sample(1:10, 3, replace = TRUE)\nvec5 &lt;- sample(1:10, 5, replace = TRUE)\nvec10\n\n [1]  4  7  4  8  7  2  3  8  7 10\n\nvec3\n\n[1]  2  3 10\n\nvec5\n\n[1] 7 1 3 3 7\n\nvec10 + vec5\n\n [1] 11  8  7 11 14  9  4 11 10 17\n\nvec10 + vec3\n\nWarning in vec10 + vec3: longer object length is not a multiple of shorter\nobject length\n\n\n [1]  6 10 14 10 10 12  5 11 17 12\n\n\nWhat choices were made by the R developers?",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#why-vectorize",
    "href": "units/calculation.html#why-vectorize",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "Imagine how this code would look if written using a loop, or three separate loops.\n\nvals &lt;- rnorm(1000)\nchi2vals &lt;- vals^2\nchi2_df1000 &lt;- sum(chi2vals)\n\nAdvantages:\n\nmuch faster than looping\neasier to code\neasier to read and understand the code\n\nVectorized code is generally fast because the underlying loop is executed in compiled C code rather than by the R interpreter.\nWe’ve already seen that lots of functions (and operators) in R are vectorized (i.e., they can take a single value or a vector as an input argument).",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#vectorization-with-matrices",
    "href": "units/calculation.html#vectorization-with-matrices",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "Recall that +, -,*, / do vectorized calculations:\n\nA &lt;- matrix(1:9, 3)\nB &lt;- matrix(seq(4,36, by = 4), 3)\n\nA*7\n\n     [,1] [,2] [,3]\n[1,]    7   28   49\n[2,]   14   35   56\n[3,]   21   42   63\n\nA + B\n\n     [,1] [,2] [,3]\n[1,]    5   20   35\n[2,]   10   25   40\n[3,]   15   30   45\n\nA + B[ , 1]\n\n     [,1] [,2] [,3]\n[1,]    5    8   11\n[2,]   10   13   16\n[3,]   15   18   21\n\nA * B\n\n     [,1] [,2] [,3]\n[1,]    4   64  196\n[2,]   16  100  256\n[3,]   36  144  324\n\nA * B[ , 1]\n\n     [,1] [,2] [,3]\n[1,]    4   16   28\n[2,]   16   40   64\n[3,]   36   72  108",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#linear-algebra-matrixvector-multiplication",
    "href": "units/calculation.html#linear-algebra-matrixvector-multiplication",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "A %*% B[ , 1]\n\n     [,1]\n[1,]  120\n[2,]  144\n[3,]  168\n\nA %*% B\n\n     [,1] [,2] [,3]\n[1,]  120  264  408\n[2,]  144  324  504\n[3,]  168  384  600\n\nidentical(t(A)%*%A, crossprod(A))\n\n[1] TRUE\n\n\nNow let’s do a bit of manipulation and see if you can infer how R represents matrices internally.",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#matrix-and-array-internals",
    "href": "units/calculation.html#matrix-and-array-internals",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "Question\n\n\n\nConsider our matrix ‘mat’:\n\nmat &lt;- matrix(1:16, nrow = 4, ncol = 4)\n\nSuppose I run this code: mat[4].\nWhat do you think will be returned?\n\n13\n4\n13, 14, 15, 16\n4, 8, 12, 16\nan error\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMatrices are stored column-major\n\nmat[4]\nattributes(mat) &lt;- NULL\nmat\nis.matrix(mat)\n\nThis is like Fortran, MATLAB and Julia but not like C or Python(numpy).",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#linear-algebra",
    "href": "units/calculation.html#linear-algebra",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "R can do essentially any linear algebra you need. It uses system-level packages called BLAS (basic linear algebra subroutines) and LAPACK (linear algebra package). Note that these calculations will be essentially as fast as if you wrote C code because R just calls C and Fortran routines to do the calculations.\nThe BLAS that comes with R is fairly slow. It’s possible to use a faster BLAS, as well as one that uses multiple cores automatically. This can in some cases give you an order of magnitude speedup if your work involves a lot of matrix manipulations/linear algebra.",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#matrix-decompositions",
    "href": "units/calculation.html#matrix-decompositions",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "Here are some examples of common matrix decompositions: Cholesky decomposition, eigenvalues/eigenvectors, and SVD. These all use BLAS+LAPACK.\n\n## next 3 lines generate a positive definite matrix\nlibrary(fields)\n\nLoading required package: spam\n\n\nSpam version 2.11-1 (2025-01-20) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAttaching package: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nLoading required package: viridisLite\n\n\n\nTry help(fields) to get started.\n\ntimes &lt;- seq(0, 1, length = 100)\nR &lt;- exp(-rdist(times) / 0.2) # a correlation matrix\n######################################################\ne &lt;- eigen(R)\nrange(e$values)\n\n[1]  0.02525338 32.85537225\n\ne$vectors[ , 1]\n\n  [1] 0.05195413 0.05448567 0.05698864 0.05946173 0.06190363 0.06431308\n  [7] 0.06668879 0.06902954 0.07133409 0.07360123 0.07582978 0.07801856\n [13] 0.08016643 0.08227226 0.08433494 0.08635341 0.08832659 0.09025345\n [19] 0.09213298 0.09396420 0.09574615 0.09747789 0.09915851 0.10078713\n [25] 0.10236291 0.10388500 0.10535262 0.10676499 0.10812137 0.10942106\n [31] 0.11066337 0.11184765 0.11297327 0.11403965 0.11504623 0.11599249\n [37] 0.11687791 0.11770205 0.11846447 0.11916476 0.11980256 0.12037754\n [43] 0.12088940 0.12133786 0.12172270 0.12204370 0.12230071 0.12249358\n [49] 0.12262222 0.12268655 0.12268655 0.12262222 0.12249358 0.12230071\n [55] 0.12204370 0.12172270 0.12133786 0.12088940 0.12037754 0.11980256\n [61] 0.11916476 0.11846447 0.11770205 0.11687791 0.11599249 0.11504623\n [67] 0.11403965 0.11297327 0.11184765 0.11066337 0.10942106 0.10812137\n [73] 0.10676499 0.10535262 0.10388500 0.10236291 0.10078713 0.09915851\n [79] 0.09747789 0.09574615 0.09396420 0.09213298 0.09025345 0.08832659\n [85] 0.08635341 0.08433494 0.08227226 0.08016643 0.07801856 0.07582978\n [91] 0.07360123 0.07133409 0.06902954 0.06668879 0.06431308 0.06190363\n [97] 0.05946173 0.05698864 0.05448567 0.05195413\n\nsv &lt;- svd(R)\nU &lt;- chol(R)\n\ndevs &lt;- rnorm(100)\nRinvb &lt;- solve(R, devs)  # R^{-1} b\nRinv &lt;- solve(R) # R^{-1} -- try to avoid this (slower and less numerically stable)",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#pre-allocation",
    "href": "units/calculation.html#pre-allocation",
    "title": "Calculations and Efficiency",
    "section": "Pre-allocation",
    "text": "Pre-allocation\nThis is slow.\n\nvals &lt;- 0\nn &lt;- 50000\nsystem.time({\nfor(i in 1:n)\n      vals &lt;- c(vals, i)\n})\n\n   user  system elapsed \n  2.952   0.037   2.989 \n\n\nThe same holds for using rbind(), cbind(), or adding to a list, one element at a time.\nQuestion: Thoughts on why this are so slow? Think about what R might be doing behind the scenes in terms of storage in memory.\nNote: This is one area where Python and some other languages handle the situation in a more sophisticated way.",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#the-answer-is-to-pre-allocate-memory",
    "href": "units/calculation.html#the-answer-is-to-pre-allocate-memory",
    "title": "Calculations and Efficiency",
    "section": "The answer is to pre-allocate memory",
    "text": "The answer is to pre-allocate memory\nThis is not so slow. (Please ignore the fact that this is a silly way to do this in R.)\n\nn &lt;- 50000\nsystem.time({\nvals &lt;- rep(0, n)\nfor(i in 1:n)\n      vals[i] &lt;- i\n})\n\n   user  system elapsed \n  0.004   0.000   0.004",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#apply",
    "href": "units/calculation.html#apply",
    "title": "Calculations and Efficiency",
    "section": "apply",
    "text": "apply\nSome functions aren’t vectorized, or you may want to use a function on every row or column of a matrix/data frame, every element of a list, etc.\nFor this we use the apply() family of functions to make our code more readable.\n\nmat &lt;- matrix(rnorm(100*1000), nr = 100)\nrow_min &lt;- apply(mat, MARGIN = 1, FUN = min)\ncol_max &lt;- apply(mat, MARGIN = 2, FUN = max)\n\nThere are actually some even faster specialized functions:\n\nrow_mean &lt;- rowMeans(mat)\ncol_sum &lt;- colSums(mat)",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#lapply-and-sapply",
    "href": "units/calculation.html#lapply-and-sapply",
    "title": "Calculations and Efficiency",
    "section": "lapply() and sapply()",
    "text": "lapply() and sapply()\nThese are “map” operations that apply a function to each element of a list.\n\nmyList &lt;- list(rnorm(3), rnorm(3), rnorm(5))\nlapply(myList, min)\n\n[[1]]\n[1] -1.408063\n\n[[2]]\n[1] 1.44249\n\n[[3]]\n[1] -1.739095\n\nsapply(myList, min)\n\n[1] -1.408063  1.442490 -1.739095\n\n\n\n\n\n\n\n\nWhy use lapply and sapply?\n\n\n\nThe *array functions won’t generally be faster than loops. Rather, they’re generally used in order to have cleaner, more readable code.\n\n\nNote that we don’t generally want to use apply() on a data frame.",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#lapply-and-sapply-with-vectors",
    "href": "units/calculation.html#lapply-and-sapply-with-vectors",
    "title": "Calculations and Efficiency",
    "section": "lapply() and sapply() with vectors",
    "text": "lapply() and sapply() with vectors\nYou can use lapply() and sapply() on regular vectors, such as vectors of indices, which can come in handy. This is a bit silly but it illustrates the idea:\n\nmyfun &lt;- function(i) {\n   max(rnorm(100))\n}   \n\nout &lt;- lapply(1:6, myfun)\nout\n\n[[1]]\n[1] 2.73752\n\n[[2]]\n[1] 2.011486\n\n[[3]]\n[1] 2.770487\n\n[[4]]\n[1] 1.914722\n\n[[5]]\n[1] 2.199235\n\n[[6]]\n[1] 1.924321\n\n## Or, 'in-line' the function:\n\nout &lt;- sapply(1:10, function(x) x^2)\nout\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of these give exactly this result: pi, 2*pi, 3*pi, …?\n\n(1:n)*pi\nout &lt;- rep(0, n); for(x in 1:n) out &lt;- x*pi\nsapply(1:n, function(x) x*pi)\nout &lt;- rep(0, n); for(x in 1:n) out[i] &lt;- x*pi\nlapply(1:n, function(x) x*pi)\nsapply(1:n, “*“, pi)\n1:n*pi",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#whenwhy-are-loops-in-r-slow",
    "href": "units/calculation.html#whenwhy-are-loops-in-r-slow",
    "title": "Calculations and Efficiency",
    "section": "When/why are loops in R slow?",
    "text": "When/why are loops in R slow?\nConsider this code:\n\nx &lt;- 3\nx*7\nx &lt;- 'hi'\nx*7\n\n￼ Because of dynamic typing, when the interpreter sees x*7 it needs to check if x is something that can be multiplied by 7, including dealing with the fact that x could be a vector with many numbers in it. In addition it needs to (using scoping rules) look up the value of x. (Consider that x might not even exist at the point that x*7 is called.) Only then can the multiplication happen.\nLet’s consider writing a loop:\n\nfor(i in 1:10) {\n  if(runif(1) &gt; 0) x &lt;- 'hi'\n  if(runif(1) &gt; 0.5) rm(x)\n  x[i] &lt;- exp(x[i])\n}  \n\n￼ Because of the dynamic typing and lack of compilation, the interpreter needs to check if x exists, if it is a vector of sufficient length, if it contains numeric values, and it needs to go retrieve the required value, EVERY TIME the exp() is executed.\nThe R interpreter is a C program, so in some sense everything that happens is running as compiled code, but there are lots more things being done to accomplish a given task using interpreted code than if the task had been written directly in code that is compiled. By analogy, consider talking directly to a person in a language you both know compared to talking to a person via an interpreter who has to translate between two languages. Ultimately, the same information gets communicated (hopefully!) but the number of words spoken and time involved is much greater.",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#when-are-loops-not-slow",
    "href": "units/calculation.html#when-are-loops-not-slow",
    "title": "Calculations and Efficiency",
    "section": "When are loops not slow?",
    "text": "When are loops not slow?\nWhen the bulk of the time in the loop involves actual computation rather than checking, e.g., a loop that fits a separate machine learning model at each iteration.\nConclusions: use vectorization when you can, especially when the individual calculations are fast, but don’t obsess when the individual calculations are intensive (and often will call out to C directly).",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#some-efficiency-tips-not-r-specific",
    "href": "units/calculation.html#some-efficiency-tips-not-r-specific",
    "title": "Calculations and Efficiency",
    "section": "Some efficiency tips (not R-specific)",
    "text": "Some efficiency tips (not R-specific)\n\nConsider the order of operations:\n\nn &lt;- 3000\nA &lt;- matrix(rnorm(n^2),n)\nB &lt;- matrix(rnorm(n^2),n)\nx &lt;- rnorm(n)\nsystem.time(A %*% B %*% x)\n\n   user  system elapsed \n  3.099   1.094   0.751 \n\nsystem.time(A %*% (B %*% x))\n\n   user  system elapsed \n  0.074   0.037   0.026 \n\n\nAvoid duplicated computation\n\nDon’t duplicate operations within iterations of a loop unnecessarily (precompute them)\n\nTry to work with adjacent elements (in memory) of large vectors/matrices/arrays to efficiently use the CPU cache.\n\nIn R, generally work column-wise rather than row-wise with matrices\n\nIn R, look up elements by numerical index rather than by name for O(1) computation",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#timing-your-code",
    "href": "units/calculation.html#timing-your-code",
    "title": "Calculations and Efficiency",
    "section": "Timing your code",
    "text": "Timing your code\nFirst, a cautionary note…\n\npremature optimization is the root of all evil\n— Donald Knuth, 1974\n\nThere are a few tools in R for timing your code.\n\nsystem.time(mean(rnorm(1e7)))\n\n   user  system elapsed \n  0.601   0.022   0.623 \n\nlibrary(rbenchmark)\nn &lt;- 1000\nx &lt;- matrix(rnorm(n^2), n)\nbenchmark(t(x) %*% x,\n          crossprod(x),\n          replications = 5,\n          columns = c('test', 'replications', 'elapsed'))\n\n          test replications elapsed\n2 crossprod(x)            5   0.144\n1   t(x) %*% x            5   0.216\n\n\nConsider why the automatic crossproduct may be faster than the manual version. Note that crossprod calls out directly to a linear algebra system routine.",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#microbenchmark",
    "href": "units/calculation.html#microbenchmark",
    "title": "Calculations and Efficiency",
    "section": "Microbenchmark",
    "text": "Microbenchmark\nTo time code that runs very quickly, you should use the microbenchmark package. Of course one would generally only care about accurately timing quick calculations if a larger operation does the quick calculation very many times. Here’s a comparison of different ways of accessing an element of a dataframe.\n\nlibrary(microbenchmark)\ndf &lt;- data.frame(vals = 1:3, labs = c('a','b','c'))\nvec &lt;- c(\"a\"=5, \"b\" = 7, \"c\" = 9)\nmicrobenchmark(\n  df[2,1],\n  df$vals[2],\n  df[2, 'vals'],\n  vec[2],\n  vec[\"b\"]\n)\n\nUnit: nanoseconds\n          expr  min     lq     mean median      uq    max neval cld\n      df[2, 1] 8560 9333.0 15469.86 9781.0 10374.0 174751   100  a \n    df$vals[2]  647  891.5  1486.92 1016.5  1329.0  13394   100   b\n df[2, \"vals\"] 8746 9304.0 13052.53 9733.5 10208.0  48658   100  a \n        vec[2]  267  346.0   524.01  397.5   484.5   5854   100   b\n      vec[\"b\"]  307  393.0   571.58  451.5   551.5   2763   100   b",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#memory-use",
    "href": "units/calculation.html#memory-use",
    "title": "Calculations and Efficiency",
    "section": "Memory use",
    "text": "Memory use\nYou should know how much memory (RAM) the computer you are using has and keep in mind how big your objects are and how much memory you code might use. All objects in R are stored in RAM unlike a database or certain tools for working with big data (e.g., Python’s Dask package and certain R packages).\nIf in total, the jobs on a machine approach the physical RAM, the machine may (depending on how it is set up) start to use the hard disk as ‘virtual memory’. This is called paging or swapping, and once this happens you’re often toast (i.e., your code may take essentially forever to finish). And if paging doesn’t happen, your job will die with an out-of-memory (OOM) error.\nYou can assess memory use with top or ps or free in Linux/Mac or the Task Manager in Windows.\nOften it’s a good idea to roughly estimate how much memory an object will take up even before creating it in R. You can do this with some simple arithmetic.\n\nx &lt;- matrix(rnorm(1e6*10), 1e6)\nobject.size(x)\n\n80000216 bytes\n\n1e6 * 10 *8/ 1e6  # direct calculation of Mb\n\n[1] 80\n\nprint(object.size(x), units = 'auto')\n\n76.3 Mb",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#garbage-collection",
    "href": "units/calculation.html#garbage-collection",
    "title": "Calculations and Efficiency",
    "section": "Garbage collection",
    "text": "Garbage collection\nA variable is just a name that references a location (object) in memory. When a name is used for a different object, the memory for the old object is freed to be used again.\n\nlibrary(pryr)\nx &lt;- rnorm(1e8)\nobject.size(x)\n\n800000048 bytes\n\nmem_used()\n\n1.09 GB\n\nx &lt;- \"hello\"\nmem_used()\n\n292 MB",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#copy-on-modify",
    "href": "units/calculation.html#copy-on-modify",
    "title": "Calculations and Efficiency",
    "section": "Copy-on-modify",
    "text": "Copy-on-modify\nThe semantics of R say that &lt;- creates a new copy of an object.\nThe implementation in the R interpreter is that copies are only made when needed.\n\nlibrary(pryr)\nsystem.time(x &lt;- rnorm(1e8))\n\n   user  system elapsed \n  6.014   0.249   6.264 \n\nobject.size(x)\n\n800000048 bytes\n\nmem_used()\n\n1.09 GB\n\nsystem.time(y &lt;- x)\n\n   user  system elapsed \n      0       0       0 \n\nmem_used()\n\n1.09 GB\n\naddress(x)\n\n[1] \"0x7f3328318010\"\n\naddress(y)\n\n[1] \"0x7f3328318010\"\n\nsystem.time(x[1] &lt;- 3)  # Clearly more time than just modifying one element!\n\n   user  system elapsed \n  0.155   0.203   0.358 \n\nmem_used()\n\n1.89 GB\n\naddress(x)\n\n[1] \"0x7f32f8827010\"\n\naddress(y)\n\n[1] \"0x7f3328318010\"\n\n\nInternally R manages this by keeping track of how many variables (references) there are to a given object in memory.",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#memory-and-lists",
    "href": "units/calculation.html#memory-and-lists",
    "title": "Calculations and Efficiency",
    "section": "Memory and lists",
    "text": "Memory and lists\nR plays various games with lists and character strings (essentially copy-on-change) to avoid redundant copies of identical data. We won’t go into details.",
    "crumbs": [
      "Modules",
      "Calculation"
    ]
  },
  {
    "objectID": "units/intro.html",
    "href": "units/intro.html",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "The syntax for doing interactive calculations in R is similar to other languages such as Python, MATLAB, and Julia, though some of the operators differ.\nHere are some examples that you should be able to replicate yourself in a plain R session or in the console/command window of RStudio. The console window will by default be the left (or perhaps lower left) window pane when you start RStudio.\n\n2 + 2 # add numbers\n\n[1] 4\n\n2 * pi # multiply by a constant\n\n[1] 6.283185\n\n7 + runif(1) # add a random number\n\n[1] 7.291361\n\n3^4 # powers\n\n[1] 81\n\nsqrt(4^4) # functions\n\n[1] 16\n\nlog(10)\n\n[1] 2.302585\n\nlog(100, base = 10)\n\n[1] 2\n\n23 %/% 2 \n\n[1] 11\n\n23 %% 2\n\n[1] 1\n\n# scientific notation\n5000000000 * 1000\n\n[1] 5e+12\n\n5e9 * 1e3\n\n[1] 5e+12\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBy default, RStudio shows output of code chunks in the code window pane (a notebook-style approach similar to Jupyter notebooks). To turn this off, go to Tools -&gt; Global Options, select the R Markdown left tab and unclick “Show output inline for all R Markdown documents”.\n\n\n\n\n\n\nQuestion\n\n\n\nHow do I calculate the cosine of 2 pi?\n\ncosine(2pi)\ncosine(2*pi)\ncos(2 * pi)\ncos(2 x pi)\ncos(2*pi)\ncos(2 * 3.14159)\ncos[2*pi]\n\nNote that exploring the results of running the code will also help to understand R’s error messages.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe function name is cos not cosine.\nA function call specifies the arguments in parentheses (), not brackets [].\nSpaces don’t generally matter (there are exceptions).\npi is an object in the R language.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat happens if you do this (hitting enter/return after “pi”)?\n\ncos(2*pi\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSince we didn’t enter the closing parenthesis, R is waiting for additional input with the “continuation” prompt of +.\n&gt; cos(2*pi\n+ \nYou can either enter the missing syntax or hit Ctrl-C or Esc to kill the partial syntax and return to the usual prompt.\nThis happens often – with missing or non-matching closing parentheses/brackets or quotation symbols.\n\n\n\n\n\nA key action in R (similar to other languages) is to store values in the form of R objects, and to examine the value of R objects.\n\nval &lt;- 3\nval\n\n[1] 3\n\nprint(val)  # The same as just typing `val`\n\n[1] 3\n\nVal &lt;- 7 # case-sensitive!\nprint(val)\n\n[1] 3\n\nprint(Val)\n\n[1] 7\n\n\nHere is some other syntax to create objects.\n\nmySeq &lt;- 1:6\nmySeq\n\n[1] 1 2 3 4 5 6\n\nyears &lt;- seq(1952, 2007, by = 5)\nyears\n\n [1] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 2002 2007\n\nlength(years)\n\n[1] 12\n\n## This is a comment: here is an example of non-numeric data\ncountry &lt;- rep(\"Afghanistan\", 12)\ncountry \n\n [1] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\"\n [6] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\"\n[11] \"Afghanistan\" \"Afghanistan\"\n\n\nR gives us a lot of flexibility (within certain rules) for assigning to (parts of) objects from (parts of) other objects. We’ll see this through the bootcamp.\n\n\n\nThe most basic form of an R object is a vector (i.e., a 1-dimensional array). The various objects mySeq, years, country from above are all vectors.\nIn fact, individual (scalar) values are vectors of length one, so val and Val from above are also vectors.\nWe can concatenate values into a vector with c().\n\n## numeric vector\nnums &lt;- c(1.1, 3, -5.7)\ndevs &lt;- rnorm(5)   # Five random normal values.\ndevs\n\n[1]  0.02204586  0.65701743 -2.37699051 -1.57274557  0.38950304\n\n\nThis is not valid syntax in R. Let’s try it and see what happens.\n\nnums &lt;- (1.1, 3, -5.7)\nnums &lt;- [1.1, 3, -5.7]\n\n\n\n\nWe can subset (aka “slice”) using a variety of approaches.\n\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nletters[3]\n\n[1] \"c\"\n\nletters[3:5]\n\n[1] \"c\" \"d\" \"e\"\n\nletters[c(1, 3, 6)]\n\n[1] \"a\" \"c\" \"f\"\n\nletters[-c(1, 3, 6)]\n\n [1] \"b\" \"d\" \"e\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\" \"u\" \"v\"\n[20] \"w\" \"x\" \"y\" \"z\"\n\nletters[c(rep(TRUE, 6), rep(FALSE, 19), TRUE)]\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"z\"\n\n\nWe can substitute values into vectors:\n\nletters[2] &lt;- \"β\"\nletters[1:5]\n\n[1] \"a\" \"β\" \"c\" \"d\" \"e\"\n\nletters[3:4] &lt;- c(\"d\",\"c\")\nletters[1:5]\n\n[1] \"a\" \"β\" \"d\" \"c\" \"e\"\n\nletters[2:4] &lt;- \"β\" # Recycling\nletters[1:5]\n\n[1] \"a\" \"β\" \"β\" \"β\" \"e\"\n\n\nThe last substitution uses “recycling” to match the left-hand-side extent (3 elements) with the right-hand-side extent (1 element)\n\n\n\n\n\n\nQuestion\n\n\n\nSuppose you have a vector, such vals &lt;- rnorm(4). Which of these will work to extract a subset of a vector?\n\nvals[3]\nvals[2,3]\nvals[c(2,3)]\nvals(2,3)\nvals[c(FALSE, TRUE, TRUE, FALSE)]\nvals[c(f,t,t,f)]\nvals(3)\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nSubsetting uses square brackets so answers #4 and #7 don’t work.\nTo create a set of indices to use in subsetting/slicing, you need to use c() to create a vector of indices, so answers #3 and #5 work.\nBooleans in R use the canonical syntax of TRUE and FALSE, so answer #5 works but not answer #6.\n\n\n\n\n\n\n\n\nFunctions generally take arguments, some of which are often optional:\n\n\nlog(10)\n\n[1] 2.302585\n\nlog(10, base = 10)\n\n[1] 1\n\n\n\nWe can embed function calls:\n\n\nhist(rnorm(1000))\n\n\n\n\nA histogram\n\n\n\n\n\nWe can (usually) see the code of a function:\n\n\nlm\n\nfunction (formula, data, subset, weights, na.action, method = \"qr\", \n    model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, \n    contrasts = NULL, offset, ...) \n{\n    ret.x &lt;- x\n    ret.y &lt;- y\n    cl &lt;- match.call()\n    mf &lt;- match.call(expand.dots = FALSE)\n    m &lt;- match(c(\"formula\", \"data\", \"subset\", \"weights\", \"na.action\", \n        \"offset\"), names(mf), 0L)\n    mf &lt;- mf[c(1L, m)]\n    mf$drop.unused.levels &lt;- TRUE\n    mf[[1L]] &lt;- quote(stats::model.frame)\n    mf &lt;- eval(mf, parent.frame())\n    if (method == \"model.frame\") \n        return(mf)\n    else if (method != \"qr\") \n        warning(gettextf(\"method = '%s' is not supported. Using 'qr'\", \n            method), domain = NA)\n    mt &lt;- attr(mf, \"terms\")\n    y &lt;- model.response(mf, \"numeric\")\n    w &lt;- as.vector(model.weights(mf))\n    if (!is.null(w) && !is.numeric(w)) \n        stop(\"'weights' must be a numeric vector\")\n    offset &lt;- model.offset(mf)\n    mlm &lt;- is.matrix(y)\n    ny &lt;- if (mlm) \n        nrow(y)\n    else length(y)\n    if (!is.null(offset)) {\n        if (!mlm) \n            offset &lt;- as.vector(offset)\n        if (NROW(offset) != ny) \n            stop(gettextf(\"number of offsets is %d, should equal %d (number of observations)\", \n                NROW(offset), ny), domain = NA)\n    }\n    if (is.empty.model(mt)) {\n        x &lt;- NULL\n        z &lt;- list(coefficients = if (mlm) matrix(NA_real_, 0, \n            ncol(y)) else numeric(), residuals = y, fitted.values = 0 * \n            y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w != \n            0) else ny)\n        if (!is.null(offset)) {\n            z$fitted.values &lt;- offset\n            z$residuals &lt;- y - offset\n        }\n    }\n    else {\n        x &lt;- model.matrix(mt, mf, contrasts)\n        z &lt;- if (is.null(w)) \n            lm.fit(x, y, offset = offset, singular.ok = singular.ok, \n                ...)\n        else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok, \n            ...)\n    }\n    class(z) &lt;- c(if (mlm) \"mlm\", \"lm\")\n    z$na.action &lt;- attr(mf, \"na.action\")\n    z$offset &lt;- offset\n    z$contrasts &lt;- attr(x, \"contrasts\")\n    z$xlevels &lt;- .getXlevels(mt, mf)\n    z$call &lt;- cl\n    z$terms &lt;- mt\n    if (model) \n        z$model &lt;- mf\n    if (ret.x) \n        z$x &lt;- x\n    if (ret.y) \n        z$y &lt;- y\n    if (!qr) \n        z$qr &lt;- NULL\n    z\n}\n&lt;bytecode: 0x5590821aa638&gt;\n&lt;environment: namespace:stats&gt;\n\n\n\n\n\n\n\nTo get information about a function you know exists, use help or ?, e.g., ?lm (results not shown).\n\nhelp(lm)\n?lm\n\n?log\n\n\n\n\nIf you’re starting to type something you’ve typed before, or you are typing the long name of an R object or function, STOP! You likely don’t need to type all of that.\n\nTab completion: type a few letters of an object/function and hit Tab for autocompletion\nCommand history: recover and reuse/edit previous commands used with:\n\nup/down arrows\nCtrl-{up arrow} or Command-{up arrow}\n\nRStudio: select a line or block for execution via Ctrl-Enter\nFor keyboard shortcuts in RStudio see:\n\nTools -&gt; Keyboard Shortcuts Help or\nthis and this blog posts.\n\nOther tips for saving time in RStudio and R Markdown\n\n\n\n\nR has functions for learning about the collection of objects in your workspace. Some of this is built in to RStudio (see the Environment tab in upper right pane).\nLet’s first create a few objects.\n\nx &lt;- rnorm(5)\ny &lt;- c(5L, 2L, 7L)\nz &lt;- list(a = 3, b = c('sam', 'yang'))\n\nNow let’s see the objects in our workspace and delete one of them.\n\nls()  # search the user workspace (global environment)\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"x\"       \"y\"       \"years\"   \"z\"      \n\nrm(x)    # delete a variable\nls()\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"y\"       \"years\"   \"z\"      \n\nls.str() # list and describe variables\n\ncountry :  chr [1:12] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\ndevs :  num [1:5] 0.022 0.657 -2.377 -1.573 0.39\nletters :  chr [1:26] \"a\" \"β\" \"β\" \"β\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" ...\nmySeq :  int [1:6] 1 2 3 4 5 6\nnums :  num [1:3] 1.1 3 -5.7\nval :  num 3\nVal :  num 7\ny :  int [1:3] 5 2 7\nyears :  num [1:12] 1952 1957 1962 1967 1972 ...\nz : List of 2\n $ a: num 3\n $ b: chr [1:2] \"sam\" \"yang\"\n\n\n\n\n\nFinally we can save the objects in our R session in a compact, binary format for later use (or to give to someone else, even if they are on a different operating system):\n\nls()\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"y\"       \"years\"   \"z\"      \n\nsave.image('intro.Rda')\nrm(list = ls())\nls()\n\ncharacter(0)\n\nload('intro.Rda') \n# the result of this may not be quite right in the slide version\nls()\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"y\"       \"years\"   \"z\"      \n\n\n\n\n\nTo read and write from R, you need to have a firm grasp of where in the computer’s filesystem you are reading and writing from. Here’s some syntax (results not shown and will vary by machine).\n\n## What directory does R look for files in (working directory)?\ngetwd()\n\n## Changing the working directory (Linux/Mac specific)\nsetwd('~/Desktop') # change the working directory\nsetwd('/Users/paciorek/Desktop') # absolute path (here on MacOS)\ngetwd()\nsetwd('r-voleon-2025/units') # relative path\nsetwd('../tmp') # relative path, up and back down the tree\n\n## Changing the working directory (Windows specific)\n## Windows - use either \\\\ or / to indicate directories\n# setwd('C:\\\\Users\\\\Your_username\\\\Desktop\\\\r-voleon-2025')\n# setwd('..\\\\r-voleon-2025')\n\n## Changing the working directory (platform-agnostic)\nsetwd(file.path('~', 'Desktop', 'r-voleon-2025', 'modules')) # change the working directory\nsetwd(file.path('/', 'Users', 'paciorek', 'Desktop', 'r-voleon-2025', 'modules')) # absolute path\ngetwd()\nsetwd(file.path('..', 'data')) # relative path\n\nMany errors and much confusion result from you and R not being on the same page in terms of where in the directory structure you are.\nIn RStudio, you can use Session -&gt; Set Working Directory instead of setwd.\n\n\n\n\nLet’s check out the packages on CRAN. In particular check out the CRAN Task Views.\nEssentially any well-established and many not-so-established statistical methods and other functionality is available in a package.\nIf you want to sound like an R expert, make sure to call them packages and not libraries. A library is the location in the directory structure where the packages are installed/stored.\n\n\nTwo steps (similar to Python and Julia):\n\nInstall the package on your machine\n\none-time only - the package will be a set of files in the filesystem\n\nLoad the package\n\nevery time you start R and need to use a given package - the package will be loaded into memory\n\n\nTo install a package, in RStudio, just do Packages-&gt;Install Packages.\nFrom the command line, you generally will just do\n\ninstall.packages('gapminder') \n\nIf you’re on a network and are not the administrator of the machine, you may need to explicitly tell R to install it in a directory you are able to write in:\n\ninstall.packages('gapminder', lib = file.path('~', 'R'))\n\nIf you’re using R directly installed on your laptop, now would be a good point to install the various packages we need for the bootcamp, which can be done easily with the following command:\n\ninstall.packages(c('chron','data.table','devtools','dplyr',\n                   'doFuture','dplyr','dtplyr','fields','foreach',\n                   'foreign','future','future.apply','gapminder',\n                   'ggplot2','gridExtra','microbenchmark',\n                   'patchwork', 'pryr', 'R6', 'Rcpp',\n                   'rbenchmark', 'RSQLite', 'stringr', 'tidyr'))\n\nNote that packages often are dependent on other packages so these dependencies may be installed and loaded automatically. E.g., fields depends on maps and on spam.\n\n\n\nYou can use syntax as follows to get a list of the objects in a package and a brief description:\n\nlibrary(help = packageName)\n\nOn CRAN there often vignettes that are an overview and describe usage of a package if you click on a specific package. The reference manual is just a single document with the help files for all of the objects/functions in a package. That may be helpful, but often it’s hard to get the big picture view from that.\n\n\n\n\n\n\nHere’s an example of the syntax for writing our own function.\n\nadd_constant &lt;- function(x, constant = 0) {\n   result &lt;- x + constant\n   return(result)\n}\n\nadd_constant(7)\n\n[1] 7\n\nadd_constant(7, 5)\n\n[1] 12\n\nadd_constant(1:6, 5)\n\n[1]  6  7  8  9 10 11\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nNotice the lack of checking of the inputs to the function. The function works for vectors and related types of objects (e.g., matrices), but see what happens if you pass a string as the first argument. Where is the error trapped?\n\n\n\n\n\nR can match arguments by name (when provided) or by position (the fall-back). It also allows one to specify default values so that the user doesn’t have to explicitly provide all the arguments.\n\nlog(100)\n\n[1] 4.60517\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\nlog(base = 10, 100)  # This is a bit unusual and wouldn't work in Python.\n\n[1] 2\n\nlog(base = 10, x = 100)\n\n[1] 2\n\n\n\n\n\nOften we need our code to do different things depending on whether some condition is true or false.\nHere’s a simple example to illustrate the syntax. Note that the then is implicit.\n\nval &lt;- rnorm(1)\nval\n\n[1] -1.191488\n\nif (val &lt; 0) {\n  print(\"val is negative\")\n} else {\n  print(\"val is positive\")\n}\n\n[1] \"val is negative\"\n\n\nWe can chain together if statements as follows.\n\nval &lt;- rnorm(1)\nval\n\n[1] 0.4783144\n\nif (val &lt; -1) {\n  print(\"val is more than one standard deviation below the mean.\")\n} else if (abs(val) &lt;= 1) {\n  print(\"val is within one standard deviation of the mean.\")\n} else {\n  print(\"val is more than one standard deviation above the mean.\")\n}\n\n[1] \"val is within one standard deviation of the mean.\"\n\n\nIn general, the { brackets are only needed if you have multiple R expressions, but R will complain when an else starts a line of code, so generally using the { is good practice. That said, this works fine:\n\nif (val &lt; 0) print(\"val is negative\") else print(\"val is positive\")\n\n[1] \"val is positive\"\n\n\n\n\n\nIn many languages, looping (for loops, while loops, etc.) is one of the main constructs used to carry out computation. Loops are not emphasized as much in R, both because they can be slow and because other syntax (vectorized calls, lapply, etc.) is often cleaner, as we’ll see in a later module.\nBut there are lots of times when using a loop does make sense.\nMost of you are probably familiar at least with the basic idea of iterating through a series of steps. A for loop iterates through a pre-determined number of iterations, while a while loop iterates until some condition is met. For loops are more common in R, but while loops can be handy particularly for things like optimization.\nHere’s some example syntax.\n\nx &lt;- rnorm(50)\ncnt_neg &lt;- 0\nfor(i in seq_along(x)) {\n    if(x[i] &lt; 0) {\n       x[i] &lt;- 0\n       cnt_neg &lt;- cnt_neg + 1\n    }\n}\ncat(\"Found \", cnt_neg, \" negative values.\\n\")\n\nFound  18  negative values.\n\n\nThat said, the canonical way to do that in R is via vectorized operation:\n\ncat(\"Found \", sum(x &lt; 0), \" negative values.\\n\")\n\nFound  0  negative values.\n\nx[x &lt; 0] &lt;- 0\nx\n\n [1] 0.00000000 0.00000000 1.51206089 0.44008252 0.81560229 0.44927093\n [7] 0.27764249 0.69777452 0.00000000 0.84979133 0.80686252 0.00250907\n[13] 0.00000000 0.00000000 0.52493531 0.96574371 0.82986385 1.74360026\n[19] 1.24273138 0.00000000 0.14013192 1.58774155 0.20794429 0.02076237\n[25] 0.00000000 0.78903654 1.69028009 0.25091998 2.97061665 1.25425290\n[31] 1.49386540 0.52139108 0.69164144 0.00000000 0.00000000 0.00000000\n[37] 1.98110415 0.03696292 0.00000000 0.63301009 0.00000000 0.00000000\n[43] 0.00000000 0.00000000 0.00000000 0.41574143 0.59076070 0.00000000\n[49] 0.71183258 0.00000000\n\n\n\n\n\nIt’s not a particularly interesting example, here’s the while loop syntax:\n\nvals &lt;- rnorm(100)\nfound &lt;- FALSE\ni &lt;- 1\nwhile(!found && i &lt;= length(vals)) {\n     if(vals[i] &gt; 2) {\n       print(vals[i])\n       found &lt;- TRUE\n     }\n     i &lt;- i+1\n}\n\n[1] 2.656553\n\n\n\n\n\n\nHere are some questions to get some practice with the syntax.\n\nCreate a variable called x that contains the mean of 100 random uniform numbers.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nn &lt;- 100\nx &lt;- mean(runif(n))\n\n\n\n\nUse functions in R to round pi to two decimal places and to two significant digits.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nround(pi, digits = 2)\n\n[1] 3.14\n\nsignif(pi, digits = 2)\n\n[1] 3.1\n\n\n\n\n\nMake sure you are able to install packages from CRAN. E.g., try to install gapminder.\nFigure out what your current working directory is.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\ngetwd()\n\n[1] \"/accounts/vis/paciorek/staff/workshops/r-voleon-2025/units\"\n\n\n\n\n\nPut the data/cpds.csv file in some other directory on your computer, such as Downloads. Use setwd() to set your working directory to be that directory. Read the file in using read.csv() (it will create a data structure called a data frame). Now use setwd() to point to a different directory such as Desktop. Write the object (the data frame) out to a file using write.csv (you’ll probably need to look at the help information). You may also want to experiment with figuring out how to write it out without any row names and without quotes on the character strings.\nWrite an R function that will take an input vector and set any negative values in the vector to zero.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\ntrunc_neg &lt;- function(x) {\n   x[x &lt; 0] &lt;- 0\n   return(x)\n}",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#r-as-a-calculator",
    "href": "units/intro.html#r-as-a-calculator",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "The syntax for doing interactive calculations in R is similar to other languages such as Python, MATLAB, and Julia, though some of the operators differ.\nHere are some examples that you should be able to replicate yourself in a plain R session or in the console/command window of RStudio. The console window will by default be the left (or perhaps lower left) window pane when you start RStudio.\n\n2 + 2 # add numbers\n\n[1] 4\n\n2 * pi # multiply by a constant\n\n[1] 6.283185\n\n7 + runif(1) # add a random number\n\n[1] 7.291361\n\n3^4 # powers\n\n[1] 81\n\nsqrt(4^4) # functions\n\n[1] 16\n\nlog(10)\n\n[1] 2.302585\n\nlog(100, base = 10)\n\n[1] 2\n\n23 %/% 2 \n\n[1] 11\n\n23 %% 2\n\n[1] 1\n\n# scientific notation\n5000000000 * 1000\n\n[1] 5e+12\n\n5e9 * 1e3\n\n[1] 5e+12\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBy default, RStudio shows output of code chunks in the code window pane (a notebook-style approach similar to Jupyter notebooks). To turn this off, go to Tools -&gt; Global Options, select the R Markdown left tab and unclick “Show output inline for all R Markdown documents”.\n\n\n\n\n\n\nQuestion\n\n\n\nHow do I calculate the cosine of 2 pi?\n\ncosine(2pi)\ncosine(2*pi)\ncos(2 * pi)\ncos(2 x pi)\ncos(2*pi)\ncos(2 * 3.14159)\ncos[2*pi]\n\nNote that exploring the results of running the code will also help to understand R’s error messages.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe function name is cos not cosine.\nA function call specifies the arguments in parentheses (), not brackets [].\nSpaces don’t generally matter (there are exceptions).\npi is an object in the R language.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat happens if you do this (hitting enter/return after “pi”)?\n\ncos(2*pi\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSince we didn’t enter the closing parenthesis, R is waiting for additional input with the “continuation” prompt of +.\n&gt; cos(2*pi\n+ \nYou can either enter the missing syntax or hit Ctrl-C or Esc to kill the partial syntax and return to the usual prompt.\nThis happens often – with missing or non-matching closing parentheses/brackets or quotation symbols.\n\n\n\n\n\nA key action in R (similar to other languages) is to store values in the form of R objects, and to examine the value of R objects.\n\nval &lt;- 3\nval\n\n[1] 3\n\nprint(val)  # The same as just typing `val`\n\n[1] 3\n\nVal &lt;- 7 # case-sensitive!\nprint(val)\n\n[1] 3\n\nprint(Val)\n\n[1] 7\n\n\nHere is some other syntax to create objects.\n\nmySeq &lt;- 1:6\nmySeq\n\n[1] 1 2 3 4 5 6\n\nyears &lt;- seq(1952, 2007, by = 5)\nyears\n\n [1] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 2002 2007\n\nlength(years)\n\n[1] 12\n\n## This is a comment: here is an example of non-numeric data\ncountry &lt;- rep(\"Afghanistan\", 12)\ncountry \n\n [1] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\"\n [6] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\"\n[11] \"Afghanistan\" \"Afghanistan\"\n\n\nR gives us a lot of flexibility (within certain rules) for assigning to (parts of) objects from (parts of) other objects. We’ll see this through the bootcamp.\n\n\n\nThe most basic form of an R object is a vector (i.e., a 1-dimensional array). The various objects mySeq, years, country from above are all vectors.\nIn fact, individual (scalar) values are vectors of length one, so val and Val from above are also vectors.\nWe can concatenate values into a vector with c().\n\n## numeric vector\nnums &lt;- c(1.1, 3, -5.7)\ndevs &lt;- rnorm(5)   # Five random normal values.\ndevs\n\n[1]  0.02204586  0.65701743 -2.37699051 -1.57274557  0.38950304\n\n\nThis is not valid syntax in R. Let’s try it and see what happens.\n\nnums &lt;- (1.1, 3, -5.7)\nnums &lt;- [1.1, 3, -5.7]\n\n\n\n\nWe can subset (aka “slice”) using a variety of approaches.\n\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nletters[3]\n\n[1] \"c\"\n\nletters[3:5]\n\n[1] \"c\" \"d\" \"e\"\n\nletters[c(1, 3, 6)]\n\n[1] \"a\" \"c\" \"f\"\n\nletters[-c(1, 3, 6)]\n\n [1] \"b\" \"d\" \"e\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\" \"u\" \"v\"\n[20] \"w\" \"x\" \"y\" \"z\"\n\nletters[c(rep(TRUE, 6), rep(FALSE, 19), TRUE)]\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"z\"\n\n\nWe can substitute values into vectors:\n\nletters[2] &lt;- \"β\"\nletters[1:5]\n\n[1] \"a\" \"β\" \"c\" \"d\" \"e\"\n\nletters[3:4] &lt;- c(\"d\",\"c\")\nletters[1:5]\n\n[1] \"a\" \"β\" \"d\" \"c\" \"e\"\n\nletters[2:4] &lt;- \"β\" # Recycling\nletters[1:5]\n\n[1] \"a\" \"β\" \"β\" \"β\" \"e\"\n\n\nThe last substitution uses “recycling” to match the left-hand-side extent (3 elements) with the right-hand-side extent (1 element)\n\n\n\n\n\n\nQuestion\n\n\n\nSuppose you have a vector, such vals &lt;- rnorm(4). Which of these will work to extract a subset of a vector?\n\nvals[3]\nvals[2,3]\nvals[c(2,3)]\nvals(2,3)\nvals[c(FALSE, TRUE, TRUE, FALSE)]\nvals[c(f,t,t,f)]\nvals(3)\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nSubsetting uses square brackets so answers #4 and #7 don’t work.\nTo create a set of indices to use in subsetting/slicing, you need to use c() to create a vector of indices, so answers #3 and #5 work.\nBooleans in R use the canonical syntax of TRUE and FALSE, so answer #5 works but not answer #6.\n\n\n\n\n\n\n\n\nFunctions generally take arguments, some of which are often optional:\n\n\nlog(10)\n\n[1] 2.302585\n\nlog(10, base = 10)\n\n[1] 1\n\n\n\nWe can embed function calls:\n\n\nhist(rnorm(1000))\n\n\n\n\nA histogram\n\n\n\n\n\nWe can (usually) see the code of a function:\n\n\nlm\n\nfunction (formula, data, subset, weights, na.action, method = \"qr\", \n    model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, \n    contrasts = NULL, offset, ...) \n{\n    ret.x &lt;- x\n    ret.y &lt;- y\n    cl &lt;- match.call()\n    mf &lt;- match.call(expand.dots = FALSE)\n    m &lt;- match(c(\"formula\", \"data\", \"subset\", \"weights\", \"na.action\", \n        \"offset\"), names(mf), 0L)\n    mf &lt;- mf[c(1L, m)]\n    mf$drop.unused.levels &lt;- TRUE\n    mf[[1L]] &lt;- quote(stats::model.frame)\n    mf &lt;- eval(mf, parent.frame())\n    if (method == \"model.frame\") \n        return(mf)\n    else if (method != \"qr\") \n        warning(gettextf(\"method = '%s' is not supported. Using 'qr'\", \n            method), domain = NA)\n    mt &lt;- attr(mf, \"terms\")\n    y &lt;- model.response(mf, \"numeric\")\n    w &lt;- as.vector(model.weights(mf))\n    if (!is.null(w) && !is.numeric(w)) \n        stop(\"'weights' must be a numeric vector\")\n    offset &lt;- model.offset(mf)\n    mlm &lt;- is.matrix(y)\n    ny &lt;- if (mlm) \n        nrow(y)\n    else length(y)\n    if (!is.null(offset)) {\n        if (!mlm) \n            offset &lt;- as.vector(offset)\n        if (NROW(offset) != ny) \n            stop(gettextf(\"number of offsets is %d, should equal %d (number of observations)\", \n                NROW(offset), ny), domain = NA)\n    }\n    if (is.empty.model(mt)) {\n        x &lt;- NULL\n        z &lt;- list(coefficients = if (mlm) matrix(NA_real_, 0, \n            ncol(y)) else numeric(), residuals = y, fitted.values = 0 * \n            y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w != \n            0) else ny)\n        if (!is.null(offset)) {\n            z$fitted.values &lt;- offset\n            z$residuals &lt;- y - offset\n        }\n    }\n    else {\n        x &lt;- model.matrix(mt, mf, contrasts)\n        z &lt;- if (is.null(w)) \n            lm.fit(x, y, offset = offset, singular.ok = singular.ok, \n                ...)\n        else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok, \n            ...)\n    }\n    class(z) &lt;- c(if (mlm) \"mlm\", \"lm\")\n    z$na.action &lt;- attr(mf, \"na.action\")\n    z$offset &lt;- offset\n    z$contrasts &lt;- attr(x, \"contrasts\")\n    z$xlevels &lt;- .getXlevels(mt, mf)\n    z$call &lt;- cl\n    z$terms &lt;- mt\n    if (model) \n        z$model &lt;- mf\n    if (ret.x) \n        z$x &lt;- x\n    if (ret.y) \n        z$y &lt;- y\n    if (!qr) \n        z$qr &lt;- NULL\n    z\n}\n&lt;bytecode: 0x5590821aa638&gt;\n&lt;environment: namespace:stats&gt;\n\n\n\n\n\n\n\nTo get information about a function you know exists, use help or ?, e.g., ?lm (results not shown).\n\nhelp(lm)\n?lm\n\n?log\n\n\n\n\nIf you’re starting to type something you’ve typed before, or you are typing the long name of an R object or function, STOP! You likely don’t need to type all of that.\n\nTab completion: type a few letters of an object/function and hit Tab for autocompletion\nCommand history: recover and reuse/edit previous commands used with:\n\nup/down arrows\nCtrl-{up arrow} or Command-{up arrow}\n\nRStudio: select a line or block for execution via Ctrl-Enter\nFor keyboard shortcuts in RStudio see:\n\nTools -&gt; Keyboard Shortcuts Help or\nthis and this blog posts.\n\nOther tips for saving time in RStudio and R Markdown\n\n\n\n\nR has functions for learning about the collection of objects in your workspace. Some of this is built in to RStudio (see the Environment tab in upper right pane).\nLet’s first create a few objects.\n\nx &lt;- rnorm(5)\ny &lt;- c(5L, 2L, 7L)\nz &lt;- list(a = 3, b = c('sam', 'yang'))\n\nNow let’s see the objects in our workspace and delete one of them.\n\nls()  # search the user workspace (global environment)\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"x\"       \"y\"       \"years\"   \"z\"      \n\nrm(x)    # delete a variable\nls()\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"y\"       \"years\"   \"z\"      \n\nls.str() # list and describe variables\n\ncountry :  chr [1:12] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\ndevs :  num [1:5] 0.022 0.657 -2.377 -1.573 0.39\nletters :  chr [1:26] \"a\" \"β\" \"β\" \"β\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" ...\nmySeq :  int [1:6] 1 2 3 4 5 6\nnums :  num [1:3] 1.1 3 -5.7\nval :  num 3\nVal :  num 7\ny :  int [1:3] 5 2 7\nyears :  num [1:12] 1952 1957 1962 1967 1972 ...\nz : List of 2\n $ a: num 3\n $ b: chr [1:2] \"sam\" \"yang\"\n\n\n\n\n\nFinally we can save the objects in our R session in a compact, binary format for later use (or to give to someone else, even if they are on a different operating system):\n\nls()\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"y\"       \"years\"   \"z\"      \n\nsave.image('intro.Rda')\nrm(list = ls())\nls()\n\ncharacter(0)\n\nload('intro.Rda') \n# the result of this may not be quite right in the slide version\nls()\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"y\"       \"years\"   \"z\"      \n\n\n\n\n\nTo read and write from R, you need to have a firm grasp of where in the computer’s filesystem you are reading and writing from. Here’s some syntax (results not shown and will vary by machine).\n\n## What directory does R look for files in (working directory)?\ngetwd()\n\n## Changing the working directory (Linux/Mac specific)\nsetwd('~/Desktop') # change the working directory\nsetwd('/Users/paciorek/Desktop') # absolute path (here on MacOS)\ngetwd()\nsetwd('r-voleon-2025/units') # relative path\nsetwd('../tmp') # relative path, up and back down the tree\n\n## Changing the working directory (Windows specific)\n## Windows - use either \\\\ or / to indicate directories\n# setwd('C:\\\\Users\\\\Your_username\\\\Desktop\\\\r-voleon-2025')\n# setwd('..\\\\r-voleon-2025')\n\n## Changing the working directory (platform-agnostic)\nsetwd(file.path('~', 'Desktop', 'r-voleon-2025', 'modules')) # change the working directory\nsetwd(file.path('/', 'Users', 'paciorek', 'Desktop', 'r-voleon-2025', 'modules')) # absolute path\ngetwd()\nsetwd(file.path('..', 'data')) # relative path\n\nMany errors and much confusion result from you and R not being on the same page in terms of where in the directory structure you are.\nIn RStudio, you can use Session -&gt; Set Working Directory instead of setwd.\n\n\n\n\nLet’s check out the packages on CRAN. In particular check out the CRAN Task Views.\nEssentially any well-established and many not-so-established statistical methods and other functionality is available in a package.\nIf you want to sound like an R expert, make sure to call them packages and not libraries. A library is the location in the directory structure where the packages are installed/stored.\n\n\nTwo steps (similar to Python and Julia):\n\nInstall the package on your machine\n\none-time only - the package will be a set of files in the filesystem\n\nLoad the package\n\nevery time you start R and need to use a given package - the package will be loaded into memory\n\n\nTo install a package, in RStudio, just do Packages-&gt;Install Packages.\nFrom the command line, you generally will just do\n\ninstall.packages('gapminder') \n\nIf you’re on a network and are not the administrator of the machine, you may need to explicitly tell R to install it in a directory you are able to write in:\n\ninstall.packages('gapminder', lib = file.path('~', 'R'))\n\nIf you’re using R directly installed on your laptop, now would be a good point to install the various packages we need for the bootcamp, which can be done easily with the following command:\n\ninstall.packages(c('chron','data.table','devtools','dplyr',\n                   'doFuture','dplyr','dtplyr','fields','foreach',\n                   'foreign','future','future.apply','gapminder',\n                   'ggplot2','gridExtra','microbenchmark',\n                   'patchwork', 'pryr', 'R6', 'Rcpp',\n                   'rbenchmark', 'RSQLite', 'stringr', 'tidyr'))\n\nNote that packages often are dependent on other packages so these dependencies may be installed and loaded automatically. E.g., fields depends on maps and on spam.\n\n\n\nYou can use syntax as follows to get a list of the objects in a package and a brief description:\n\nlibrary(help = packageName)\n\nOn CRAN there often vignettes that are an overview and describe usage of a package if you click on a specific package. The reference manual is just a single document with the help files for all of the objects/functions in a package. That may be helpful, but often it’s hard to get the big picture view from that.\n\n\n\n\n\n\nHere’s an example of the syntax for writing our own function.\n\nadd_constant &lt;- function(x, constant = 0) {\n   result &lt;- x + constant\n   return(result)\n}\n\nadd_constant(7)\n\n[1] 7\n\nadd_constant(7, 5)\n\n[1] 12\n\nadd_constant(1:6, 5)\n\n[1]  6  7  8  9 10 11\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nNotice the lack of checking of the inputs to the function. The function works for vectors and related types of objects (e.g., matrices), but see what happens if you pass a string as the first argument. Where is the error trapped?\n\n\n\n\n\nR can match arguments by name (when provided) or by position (the fall-back). It also allows one to specify default values so that the user doesn’t have to explicitly provide all the arguments.\n\nlog(100)\n\n[1] 4.60517\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\nlog(base = 10, 100)  # This is a bit unusual and wouldn't work in Python.\n\n[1] 2\n\nlog(base = 10, x = 100)\n\n[1] 2\n\n\n\n\n\nOften we need our code to do different things depending on whether some condition is true or false.\nHere’s a simple example to illustrate the syntax. Note that the then is implicit.\n\nval &lt;- rnorm(1)\nval\n\n[1] -1.191488\n\nif (val &lt; 0) {\n  print(\"val is negative\")\n} else {\n  print(\"val is positive\")\n}\n\n[1] \"val is negative\"\n\n\nWe can chain together if statements as follows.\n\nval &lt;- rnorm(1)\nval\n\n[1] 0.4783144\n\nif (val &lt; -1) {\n  print(\"val is more than one standard deviation below the mean.\")\n} else if (abs(val) &lt;= 1) {\n  print(\"val is within one standard deviation of the mean.\")\n} else {\n  print(\"val is more than one standard deviation above the mean.\")\n}\n\n[1] \"val is within one standard deviation of the mean.\"\n\n\nIn general, the { brackets are only needed if you have multiple R expressions, but R will complain when an else starts a line of code, so generally using the { is good practice. That said, this works fine:\n\nif (val &lt; 0) print(\"val is negative\") else print(\"val is positive\")\n\n[1] \"val is positive\"\n\n\n\n\n\nIn many languages, looping (for loops, while loops, etc.) is one of the main constructs used to carry out computation. Loops are not emphasized as much in R, both because they can be slow and because other syntax (vectorized calls, lapply, etc.) is often cleaner, as we’ll see in a later module.\nBut there are lots of times when using a loop does make sense.\nMost of you are probably familiar at least with the basic idea of iterating through a series of steps. A for loop iterates through a pre-determined number of iterations, while a while loop iterates until some condition is met. For loops are more common in R, but while loops can be handy particularly for things like optimization.\nHere’s some example syntax.\n\nx &lt;- rnorm(50)\ncnt_neg &lt;- 0\nfor(i in seq_along(x)) {\n    if(x[i] &lt; 0) {\n       x[i] &lt;- 0\n       cnt_neg &lt;- cnt_neg + 1\n    }\n}\ncat(\"Found \", cnt_neg, \" negative values.\\n\")\n\nFound  18  negative values.\n\n\nThat said, the canonical way to do that in R is via vectorized operation:\n\ncat(\"Found \", sum(x &lt; 0), \" negative values.\\n\")\n\nFound  0  negative values.\n\nx[x &lt; 0] &lt;- 0\nx\n\n [1] 0.00000000 0.00000000 1.51206089 0.44008252 0.81560229 0.44927093\n [7] 0.27764249 0.69777452 0.00000000 0.84979133 0.80686252 0.00250907\n[13] 0.00000000 0.00000000 0.52493531 0.96574371 0.82986385 1.74360026\n[19] 1.24273138 0.00000000 0.14013192 1.58774155 0.20794429 0.02076237\n[25] 0.00000000 0.78903654 1.69028009 0.25091998 2.97061665 1.25425290\n[31] 1.49386540 0.52139108 0.69164144 0.00000000 0.00000000 0.00000000\n[37] 1.98110415 0.03696292 0.00000000 0.63301009 0.00000000 0.00000000\n[43] 0.00000000 0.00000000 0.00000000 0.41574143 0.59076070 0.00000000\n[49] 0.71183258 0.00000000\n\n\n\n\n\nIt’s not a particularly interesting example, here’s the while loop syntax:\n\nvals &lt;- rnorm(100)\nfound &lt;- FALSE\ni &lt;- 1\nwhile(!found && i &lt;= length(vals)) {\n     if(vals[i] &gt; 2) {\n       print(vals[i])\n       found &lt;- TRUE\n     }\n     i &lt;- i+1\n}\n\n[1] 2.656553\n\n\n\n\n\n\nHere are some questions to get some practice with the syntax.\n\nCreate a variable called x that contains the mean of 100 random uniform numbers.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nn &lt;- 100\nx &lt;- mean(runif(n))\n\n\n\n\nUse functions in R to round pi to two decimal places and to two significant digits.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nround(pi, digits = 2)\n\n[1] 3.14\n\nsignif(pi, digits = 2)\n\n[1] 3.1\n\n\n\n\n\nMake sure you are able to install packages from CRAN. E.g., try to install gapminder.\nFigure out what your current working directory is.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\ngetwd()\n\n[1] \"/accounts/vis/paciorek/staff/workshops/r-voleon-2025/units\"\n\n\n\n\n\nPut the data/cpds.csv file in some other directory on your computer, such as Downloads. Use setwd() to set your working directory to be that directory. Read the file in using read.csv() (it will create a data structure called a data frame). Now use setwd() to point to a different directory such as Desktop. Write the object (the data frame) out to a file using write.csv (you’ll probably need to look at the help information). You may also want to experiment with figuring out how to write it out without any row names and without quotes on the character strings.\nWrite an R function that will take an input vector and set any negative values in the vector to zero.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\ntrunc_neg &lt;- function(x) {\n   x[x &lt; 0] &lt;- 0\n   return(x)\n}",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#assigning-values-to-r-objects",
    "href": "units/intro.html#assigning-values-to-r-objects",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "A key action in R (similar to other languages) is to store values in the form of R objects, and to examine the value of R objects.\n\nval &lt;- 3\nval\n\n[1] 3\n\nprint(val)  # The same as just typing `val`\n\n[1] 3\n\nVal &lt;- 7 # case-sensitive!\nprint(val)\n\n[1] 3\n\nprint(Val)\n\n[1] 7\n\n\nHere is some other syntax to create objects.\n\nmySeq &lt;- 1:6\nmySeq\n\n[1] 1 2 3 4 5 6\n\nyears &lt;- seq(1952, 2007, by = 5)\nyears\n\n [1] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 2002 2007\n\nlength(years)\n\n[1] 12\n\n## This is a comment: here is an example of non-numeric data\ncountry &lt;- rep(\"Afghanistan\", 12)\ncountry \n\n [1] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\"\n [6] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\"\n[11] \"Afghanistan\" \"Afghanistan\"\n\n\nR gives us a lot of flexibility (within certain rules) for assigning to (parts of) objects from (parts of) other objects. We’ll see this through the bootcamp.",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#vectors-in-r",
    "href": "units/intro.html#vectors-in-r",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "The most basic form of an R object is a vector (i.e., a 1-dimensional array). The various objects mySeq, years, country from above are all vectors.\nIn fact, individual (scalar) values are vectors of length one, so val and Val from above are also vectors.\nWe can concatenate values into a vector with c().\n\n## numeric vector\nnums &lt;- c(1.1, 3, -5.7)\ndevs &lt;- rnorm(5)   # Five random normal values.\ndevs\n\n[1]  0.02204586  0.65701743 -2.37699051 -1.57274557  0.38950304\n\n\nThis is not valid syntax in R. Let’s try it and see what happens.\n\nnums &lt;- (1.1, 3, -5.7)\nnums &lt;- [1.1, 3, -5.7]",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#working-with-indices-and-subsets",
    "href": "units/intro.html#working-with-indices-and-subsets",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "We can subset (aka “slice”) using a variety of approaches.\n\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nletters[3]\n\n[1] \"c\"\n\nletters[3:5]\n\n[1] \"c\" \"d\" \"e\"\n\nletters[c(1, 3, 6)]\n\n[1] \"a\" \"c\" \"f\"\n\nletters[-c(1, 3, 6)]\n\n [1] \"b\" \"d\" \"e\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\" \"t\" \"u\" \"v\"\n[20] \"w\" \"x\" \"y\" \"z\"\n\nletters[c(rep(TRUE, 6), rep(FALSE, 19), TRUE)]\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"z\"\n\n\nWe can substitute values into vectors:\n\nletters[2] &lt;- \"β\"\nletters[1:5]\n\n[1] \"a\" \"β\" \"c\" \"d\" \"e\"\n\nletters[3:4] &lt;- c(\"d\",\"c\")\nletters[1:5]\n\n[1] \"a\" \"β\" \"d\" \"c\" \"e\"\n\nletters[2:4] &lt;- \"β\" # Recycling\nletters[1:5]\n\n[1] \"a\" \"β\" \"β\" \"β\" \"e\"\n\n\nThe last substitution uses “recycling” to match the left-hand-side extent (3 elements) with the right-hand-side extent (1 element)\n\n\n\n\n\n\nQuestion\n\n\n\nSuppose you have a vector, such vals &lt;- rnorm(4). Which of these will work to extract a subset of a vector?\n\nvals[3]\nvals[2,3]\nvals[c(2,3)]\nvals(2,3)\nvals[c(FALSE, TRUE, TRUE, FALSE)]\nvals[c(f,t,t,f)]\nvals(3)\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nSubsetting uses square brackets so answers #4 and #7 don’t work.\nTo create a set of indices to use in subsetting/slicing, you need to use c() to create a vector of indices, so answers #3 and #5 work.\nBooleans in R use the canonical syntax of TRUE and FALSE, so answer #5 works but not answer #6.",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#using-functions-in-r",
    "href": "units/intro.html#using-functions-in-r",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "Functions generally take arguments, some of which are often optional:\n\n\nlog(10)\n\n[1] 2.302585\n\nlog(10, base = 10)\n\n[1] 1\n\n\n\nWe can embed function calls:\n\n\nhist(rnorm(1000))\n\n\n\n\nA histogram\n\n\n\n\n\nWe can (usually) see the code of a function:\n\n\nlm\n\nfunction (formula, data, subset, weights, na.action, method = \"qr\", \n    model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, \n    contrasts = NULL, offset, ...) \n{\n    ret.x &lt;- x\n    ret.y &lt;- y\n    cl &lt;- match.call()\n    mf &lt;- match.call(expand.dots = FALSE)\n    m &lt;- match(c(\"formula\", \"data\", \"subset\", \"weights\", \"na.action\", \n        \"offset\"), names(mf), 0L)\n    mf &lt;- mf[c(1L, m)]\n    mf$drop.unused.levels &lt;- TRUE\n    mf[[1L]] &lt;- quote(stats::model.frame)\n    mf &lt;- eval(mf, parent.frame())\n    if (method == \"model.frame\") \n        return(mf)\n    else if (method != \"qr\") \n        warning(gettextf(\"method = '%s' is not supported. Using 'qr'\", \n            method), domain = NA)\n    mt &lt;- attr(mf, \"terms\")\n    y &lt;- model.response(mf, \"numeric\")\n    w &lt;- as.vector(model.weights(mf))\n    if (!is.null(w) && !is.numeric(w)) \n        stop(\"'weights' must be a numeric vector\")\n    offset &lt;- model.offset(mf)\n    mlm &lt;- is.matrix(y)\n    ny &lt;- if (mlm) \n        nrow(y)\n    else length(y)\n    if (!is.null(offset)) {\n        if (!mlm) \n            offset &lt;- as.vector(offset)\n        if (NROW(offset) != ny) \n            stop(gettextf(\"number of offsets is %d, should equal %d (number of observations)\", \n                NROW(offset), ny), domain = NA)\n    }\n    if (is.empty.model(mt)) {\n        x &lt;- NULL\n        z &lt;- list(coefficients = if (mlm) matrix(NA_real_, 0, \n            ncol(y)) else numeric(), residuals = y, fitted.values = 0 * \n            y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w != \n            0) else ny)\n        if (!is.null(offset)) {\n            z$fitted.values &lt;- offset\n            z$residuals &lt;- y - offset\n        }\n    }\n    else {\n        x &lt;- model.matrix(mt, mf, contrasts)\n        z &lt;- if (is.null(w)) \n            lm.fit(x, y, offset = offset, singular.ok = singular.ok, \n                ...)\n        else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok, \n            ...)\n    }\n    class(z) &lt;- c(if (mlm) \"mlm\", \"lm\")\n    z$na.action &lt;- attr(mf, \"na.action\")\n    z$offset &lt;- offset\n    z$contrasts &lt;- attr(x, \"contrasts\")\n    z$xlevels &lt;- .getXlevels(mt, mf)\n    z$call &lt;- cl\n    z$terms &lt;- mt\n    if (model) \n        z$model &lt;- mf\n    if (ret.x) \n        z$x &lt;- x\n    if (ret.y) \n        z$y &lt;- y\n    if (!qr) \n        z$qr &lt;- NULL\n    z\n}\n&lt;bytecode: 0x5590821aa638&gt;\n&lt;environment: namespace:stats&gt;",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#getting-help-about-a-function",
    "href": "units/intro.html#getting-help-about-a-function",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "To get information about a function you know exists, use help or ?, e.g., ?lm (results not shown).\n\nhelp(lm)\n?lm\n\n?log",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#how-to-be-lazy-aka-efficient",
    "href": "units/intro.html#how-to-be-lazy-aka-efficient",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "If you’re starting to type something you’ve typed before, or you are typing the long name of an R object or function, STOP! You likely don’t need to type all of that.\n\nTab completion: type a few letters of an object/function and hit Tab for autocompletion\nCommand history: recover and reuse/edit previous commands used with:\n\nup/down arrows\nCtrl-{up arrow} or Command-{up arrow}\n\nRStudio: select a line or block for execution via Ctrl-Enter\nFor keyboard shortcuts in RStudio see:\n\nTools -&gt; Keyboard Shortcuts Help or\nthis and this blog posts.\n\nOther tips for saving time in RStudio and R Markdown",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#managing-the-workspace",
    "href": "units/intro.html#managing-the-workspace",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "R has functions for learning about the collection of objects in your workspace. Some of this is built in to RStudio (see the Environment tab in upper right pane).\nLet’s first create a few objects.\n\nx &lt;- rnorm(5)\ny &lt;- c(5L, 2L, 7L)\nz &lt;- list(a = 3, b = c('sam', 'yang'))\n\nNow let’s see the objects in our workspace and delete one of them.\n\nls()  # search the user workspace (global environment)\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"x\"       \"y\"       \"years\"   \"z\"      \n\nrm(x)    # delete a variable\nls()\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"y\"       \"years\"   \"z\"      \n\nls.str() # list and describe variables\n\ncountry :  chr [1:12] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\ndevs :  num [1:5] 0.022 0.657 -2.377 -1.573 0.39\nletters :  chr [1:26] \"a\" \"β\" \"β\" \"β\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" ...\nmySeq :  int [1:6] 1 2 3 4 5 6\nnums :  num [1:3] 1.1 3 -5.7\nval :  num 3\nVal :  num 7\ny :  int [1:3] 5 2 7\nyears :  num [1:12] 1952 1957 1962 1967 1972 ...\nz : List of 2\n $ a: num 3\n $ b: chr [1:2] \"sam\" \"yang\"",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#saving-and-reloading-the-workspace",
    "href": "units/intro.html#saving-and-reloading-the-workspace",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "Finally we can save the objects in our R session in a compact, binary format for later use (or to give to someone else, even if they are on a different operating system):\n\nls()\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"y\"       \"years\"   \"z\"      \n\nsave.image('intro.Rda')\nrm(list = ls())\nls()\n\ncharacter(0)\n\nload('intro.Rda') \n# the result of this may not be quite right in the slide version\nls()\n\n [1] \"country\" \"devs\"    \"letters\" \"mySeq\"   \"nums\"    \"val\"     \"Val\"    \n [8] \"y\"       \"years\"   \"z\"",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#the-working-directory",
    "href": "units/intro.html#the-working-directory",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "To read and write from R, you need to have a firm grasp of where in the computer’s filesystem you are reading and writing from. Here’s some syntax (results not shown and will vary by machine).\n\n## What directory does R look for files in (working directory)?\ngetwd()\n\n## Changing the working directory (Linux/Mac specific)\nsetwd('~/Desktop') # change the working directory\nsetwd('/Users/paciorek/Desktop') # absolute path (here on MacOS)\ngetwd()\nsetwd('r-voleon-2025/units') # relative path\nsetwd('../tmp') # relative path, up and back down the tree\n\n## Changing the working directory (Windows specific)\n## Windows - use either \\\\ or / to indicate directories\n# setwd('C:\\\\Users\\\\Your_username\\\\Desktop\\\\r-voleon-2025')\n# setwd('..\\\\r-voleon-2025')\n\n## Changing the working directory (platform-agnostic)\nsetwd(file.path('~', 'Desktop', 'r-voleon-2025', 'modules')) # change the working directory\nsetwd(file.path('/', 'Users', 'paciorek', 'Desktop', 'r-voleon-2025', 'modules')) # absolute path\ngetwd()\nsetwd(file.path('..', 'data')) # relative path\n\nMany errors and much confusion result from you and R not being on the same page in terms of where in the directory structure you are.\nIn RStudio, you can use Session -&gt; Set Working Directory instead of setwd.",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#using-packages",
    "href": "units/intro.html#using-packages",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "Two steps (similar to Python and Julia):\n\nInstall the package on your machine\n\none-time only - the package will be a set of files in the filesystem\n\nLoad the package\n\nevery time you start R and need to use a given package - the package will be loaded into memory\n\n\nTo install a package, in RStudio, just do Packages-&gt;Install Packages.\nFrom the command line, you generally will just do\n\ninstall.packages('gapminder') \n\nIf you’re on a network and are not the administrator of the machine, you may need to explicitly tell R to install it in a directory you are able to write in:\n\ninstall.packages('gapminder', lib = file.path('~', 'R'))\n\nIf you’re using R directly installed on your laptop, now would be a good point to install the various packages we need for the bootcamp, which can be done easily with the following command:\n\ninstall.packages(c('chron','data.table','devtools','dplyr',\n                   'doFuture','dplyr','dtplyr','fields','foreach',\n                   'foreign','future','future.apply','gapminder',\n                   'ggplot2','gridExtra','microbenchmark',\n                   'patchwork', 'pryr', 'R6', 'Rcpp',\n                   'rbenchmark', 'RSQLite', 'stringr', 'tidyr'))\n\nNote that packages often are dependent on other packages so these dependencies may be installed and loaded automatically. E.g., fields depends on maps and on spam.",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#general-information-about-a-package",
    "href": "units/intro.html#general-information-about-a-package",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "You can use syntax as follows to get a list of the objects in a package and a brief description:\n\nlibrary(help = packageName)\n\nOn CRAN there often vignettes that are an overview and describe usage of a package if you click on a specific package. The reference manual is just a single document with the help files for all of the objects/functions in a package. That may be helpful, but often it’s hard to get the big picture view from that.",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#writing-functions",
    "href": "units/intro.html#writing-functions",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "Here’s an example of the syntax for writing our own function.\n\nadd_constant &lt;- function(x, constant = 0) {\n   result &lt;- x + constant\n   return(result)\n}\n\nadd_constant(7)\n\n[1] 7\n\nadd_constant(7, 5)\n\n[1] 12\n\nadd_constant(1:6, 5)\n\n[1]  6  7  8  9 10 11\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nNotice the lack of checking of the inputs to the function. The function works for vectors and related types of objects (e.g., matrices), but see what happens if you pass a string as the first argument. Where is the error trapped?",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#function-arguments",
    "href": "units/intro.html#function-arguments",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "R can match arguments by name (when provided) or by position (the fall-back). It also allows one to specify default values so that the user doesn’t have to explicitly provide all the arguments.\n\nlog(100)\n\n[1] 4.60517\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\nlog(base = 10, 100)  # This is a bit unusual and wouldn't work in Python.\n\n[1] 2\n\nlog(base = 10, x = 100)\n\n[1] 2",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#branching-if-then-else-syntax",
    "href": "units/intro.html#branching-if-then-else-syntax",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "Often we need our code to do different things depending on whether some condition is true or false.\nHere’s a simple example to illustrate the syntax. Note that the then is implicit.\n\nval &lt;- rnorm(1)\nval\n\n[1] -1.191488\n\nif (val &lt; 0) {\n  print(\"val is negative\")\n} else {\n  print(\"val is positive\")\n}\n\n[1] \"val is negative\"\n\n\nWe can chain together if statements as follows.\n\nval &lt;- rnorm(1)\nval\n\n[1] 0.4783144\n\nif (val &lt; -1) {\n  print(\"val is more than one standard deviation below the mean.\")\n} else if (abs(val) &lt;= 1) {\n  print(\"val is within one standard deviation of the mean.\")\n} else {\n  print(\"val is more than one standard deviation above the mean.\")\n}\n\n[1] \"val is within one standard deviation of the mean.\"\n\n\nIn general, the { brackets are only needed if you have multiple R expressions, but R will complain when an else starts a line of code, so generally using the { is good practice. That said, this works fine:\n\nif (val &lt; 0) print(\"val is negative\") else print(\"val is positive\")\n\n[1] \"val is positive\"",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#loops",
    "href": "units/intro.html#loops",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "In many languages, looping (for loops, while loops, etc.) is one of the main constructs used to carry out computation. Loops are not emphasized as much in R, both because they can be slow and because other syntax (vectorized calls, lapply, etc.) is often cleaner, as we’ll see in a later module.\nBut there are lots of times when using a loop does make sense.\nMost of you are probably familiar at least with the basic idea of iterating through a series of steps. A for loop iterates through a pre-determined number of iterations, while a while loop iterates until some condition is met. For loops are more common in R, but while loops can be handy particularly for things like optimization.\nHere’s some example syntax.\n\nx &lt;- rnorm(50)\ncnt_neg &lt;- 0\nfor(i in seq_along(x)) {\n    if(x[i] &lt; 0) {\n       x[i] &lt;- 0\n       cnt_neg &lt;- cnt_neg + 1\n    }\n}\ncat(\"Found \", cnt_neg, \" negative values.\\n\")\n\nFound  18  negative values.\n\n\nThat said, the canonical way to do that in R is via vectorized operation:\n\ncat(\"Found \", sum(x &lt; 0), \" negative values.\\n\")\n\nFound  0  negative values.\n\nx[x &lt; 0] &lt;- 0\nx\n\n [1] 0.00000000 0.00000000 1.51206089 0.44008252 0.81560229 0.44927093\n [7] 0.27764249 0.69777452 0.00000000 0.84979133 0.80686252 0.00250907\n[13] 0.00000000 0.00000000 0.52493531 0.96574371 0.82986385 1.74360026\n[19] 1.24273138 0.00000000 0.14013192 1.58774155 0.20794429 0.02076237\n[25] 0.00000000 0.78903654 1.69028009 0.25091998 2.97061665 1.25425290\n[31] 1.49386540 0.52139108 0.69164144 0.00000000 0.00000000 0.00000000\n[37] 1.98110415 0.03696292 0.00000000 0.63301009 0.00000000 0.00000000\n[43] 0.00000000 0.00000000 0.00000000 0.41574143 0.59076070 0.00000000\n[49] 0.71183258 0.00000000",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/intro.html#while-loop",
    "href": "units/intro.html#while-loop",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "It’s not a particularly interesting example, here’s the while loop syntax:\n\nvals &lt;- rnorm(100)\nfound &lt;- FALSE\ni &lt;- 1\nwhile(!found && i &lt;= length(vals)) {\n     if(vals[i] &gt; 2) {\n       print(vals[i])\n       found &lt;- TRUE\n     }\n     i &lt;- i+1\n}\n\n[1] 2.656553",
    "crumbs": [
      "Modules",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/data.html",
    "href": "units/data.html",
    "title": "Data Structures and Manipulations",
    "section": "",
    "text": "I encourage you to:\n\nTry out the code as we walk through it.\nKeep your eyes open! – We’ll illustrate a lot of syntax and concepts by example.\nTry to guess what the syntax means in cases we haven’t yet seen that syntax.\nPlay with it and try variations and try to break it and see what happens.\nAsk questions and comment if something interesting happens as you experiment.\n\nThis is a bootcamp. So there may be some pain involved! If you find yourself not following everything, that’s ok. You may miss some details, but try to follow the basics and the big picture.\nWhat about using a ChatBot?\n\nGreat for getting initial syntax (so we’ll focus on concepts)\nGreat for translating between languages\nCan hallucinate syntax\nHow much and what do we need to learn ourselves?\n\nFor now, knowledgeable humans still need to review, revise, debug. Right?",
    "crumbs": [
      "Modules",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#na-is-a-missing-value",
    "href": "units/data.html#na-is-a-missing-value",
    "title": "Data Structures and Manipulations",
    "section": "NA is a missing value",
    "text": "NA is a missing value\n\nvec &lt;- rnorm(12)\nvec[c(3, 5)] &lt;- NA\nvec\n\n [1] -0.3848068  0.2008003         NA  0.8924384         NA  0.9387817\n [7]  1.1936894 -0.4364204  0.3636581  1.4700999 -0.1274402  0.3295658\n\nlength(vec)\n\n[1] 12\n\nsum(vec)\n\n[1] NA\n\nsum(vec, na.rm = TRUE)\n\n[1] 4.440366\n\nhist(vec)\n\n\n\n\n\n\n\nis.na(vec)\n\n [1] FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nBe careful because many R functions won’t warn you that they are ignoring the missing values.",
    "crumbs": [
      "Modules",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#to-infinity-and-beyond",
    "href": "units/data.html#to-infinity-and-beyond",
    "title": "Data Structures and Manipulations",
    "section": "To infinity and beyond",
    "text": "To infinity and beyond\n\nbig &lt;- 1e500 \nbig\n\n[1] Inf\n\nbig + 7\n\n[1] Inf",
    "crumbs": [
      "Modules",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#nan-stands-for-not-a-number",
    "href": "units/data.html#nan-stands-for-not-a-number",
    "title": "Data Structures and Manipulations",
    "section": "NaN stands for Not a Number",
    "text": "NaN stands for Not a Number\n\nsqrt(-5)\n\nWarning in sqrt(-5): NaNs produced\n\n\n[1] NaN\n\nbig - big\n\n[1] NaN\n\n1/0\n\n[1] Inf",
    "crumbs": [
      "Modules",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#null",
    "href": "units/data.html#null",
    "title": "Data Structures and Manipulations",
    "section": "NULL",
    "text": "NULL\nNA can hold a place but NULL cannot. NULL is useful for having a function argument default to ‘nothing’. See help(crossprod), which can compute either \\(X^{\\top}X\\) or \\(X^{\\top}Y\\).\n\nc(3, NA, 7)\n\n[1]  3 NA  7\n\nc(3, NULL, 7)\n\n[1] 3 7\n\nmylist &lt;- list(3, 5, 7)\nmylist[[2]] &lt;- NULL\nmylist\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 7",
    "crumbs": [
      "Modules",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#by-direct-indexing",
    "href": "units/data.html#by-direct-indexing",
    "title": "Data Structures and Manipulations",
    "section": "1) by direct indexing",
    "text": "1) by direct indexing\n\nvec[c(3, 5, 12:14)]\n\n[1] 72.301 75.320 65.554 74.852 50.728\n\nvec[-c(3,5)]\n\n  [1] 43.828 76.423 42.731 81.235 79.829 75.635 64.062 79.441 56.728 65.554\n [11] 74.852 50.728 72.390 73.005 52.295 49.580 59.723 50.430 80.653 44.741\n [21] 50.651 78.553 72.961 72.889 65.152 46.462 55.322 78.782 48.328 75.748\n [31] 78.273 76.486 78.332 54.791 72.235 74.994 71.338 71.878 51.579 58.040\n [41] 52.947 79.313 80.657 56.735 59.448 79.406 60.022 79.483 70.259 56.007\n [51] 46.388 60.916 70.198 82.208 73.338 81.757 64.698 70.650 70.964 59.545\n [61] 78.885 80.745 80.546 72.567 82.603 72.535 54.110 67.297 78.623 77.588\n [71] 71.993 42.592 45.678 73.952 59.443 48.303 74.241 54.467 64.164 72.801\n [81] 76.195 66.803 74.543 71.164 42.082 62.069 52.906 63.785 79.762 80.204\n [91] 72.899 56.867 46.859 80.196 75.640 65.483 75.537 71.752 71.421 71.688\n[101] 75.563 78.098 78.746 76.442 72.476 46.242 65.528 72.777 63.062 74.002\n[111] 42.568 79.972 74.663 77.926 48.159 49.339 80.941 72.396 58.556 39.613\n[121] 80.884 81.701 74.143 78.400 52.517 70.616 58.420 69.819 73.923 71.777\n[131] 51.542 79.425 78.242 76.384 73.747 74.249 73.422 62.698 42.384 43.487\n\ngapminder[c(2,4), 5]\n\n[1] 30.332 34.020\n\ngapminder[c(2,4), 'lifeExp']\n\n[1] 30.332 34.020",
    "crumbs": [
      "Modules",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#by-a-vector-of-logicals",
    "href": "units/data.html#by-a-vector-of-logicals",
    "title": "Data Structures and Manipulations",
    "section": "2) by a vector of logicals",
    "text": "2) by a vector of logicals\n\nwealthy &lt;- gapminder$gdpPercap &gt; 50000\ngapminder$gdpPercap[wealthy]\n\n[1] 108382.35 113523.13  95458.11  80894.88 109347.87  59265.48\n\ngapminder[wealthy, ]\n\n    country year     pop continent lifeExp gdpPercap\n853  Kuwait 1952  160000      Asia  55.565 108382.35\n854  Kuwait 1957  212846      Asia  58.033 113523.13\n855  Kuwait 1962  358266      Asia  60.470  95458.11\n856  Kuwait 1967  575003      Asia  64.624  80894.88\n857  Kuwait 1972  841934      Asia  67.712 109347.87\n858  Kuwait 1977 1140357      Asia  69.343  59265.48\n\n\nWhat happened in the last subsetting operation?",
    "crumbs": [
      "Modules",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#by-a-vector-of-names",
    "href": "units/data.html#by-a-vector-of-names",
    "title": "Data Structures and Manipulations",
    "section": "3) by a vector of names",
    "text": "3) by a vector of names\n\nmat[c('a', 'd', 'a'), ]\n\n  [,1] [,2] [,3] [,4] [,5]\na    1    5    9   13   17\nd    4    8   12   16   20\na    1    5    9   13   17",
    "crumbs": [
      "Modules",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#using-dplyr-tools-such-as-filter-and-select-more-in-module-4",
    "href": "units/data.html#using-dplyr-tools-such-as-filter-and-select-more-in-module-4",
    "title": "Data Structures and Manipulations",
    "section": "4) using dplyr tools such as filter() and select() – more in Module 4",
    "text": "4) using dplyr tools such as filter() and select() – more in Module 4",
    "crumbs": [
      "Modules",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/programming.html",
    "href": "units/programming.html",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "Functions are one of the most important constructs in R (and many other languages). They allow you to modularize your code - encapsulating a set of repeatable operations as an individual function call.\n\nOperations are carried out with functions. Functions take objects as inputs and return objects as outputs.\nAn analysis can be considered a pipeline of function calls, with output from a function used later in a subsequent operation as input to another function.\nFunctions themselves are objects with a class and that you can manipulate:\n\n\nmedian\n\nfunction (x, na.rm = FALSE, ...) \nUseMethod(\"median\")\n&lt;bytecode: 0x5daf45104a20&gt;\n&lt;environment: namespace:stats&gt;\n\nargs(median)\n\nfunction (x, na.rm = FALSE, ...) \nNULL\n\nclass(median)\n\n[1] \"function\"\n\nmyfun &lt;- median\nlapply(list(c(2,4), c(2,6)), myfun)\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 4\n\n\n\n\n\nYou should rely heavily on functions rather than having long sets of expressions in R scripts.\nFunctions have many important advantages:\n\nThey reduce bugs by avoiding having multiple instances of the same functionality.\nThey reduce time involved in coding by eliminating redundancy.\nThey make for cleaner and more easily-readable code.\n\nA basic goal is writing functions is modularity.\nIn general, a function should\n\nbe fairly short,\nbe focused and specific in what it does,\nbe designed so that it can be used in combination with other functions to carry out more complicated operations,\ngenerally make use only of arguments to the function and internal variables.\n\n\n\n\nR can match arguments by name (when provided) or by position (the fall-back). It also allows one to specify default values so that the user doesn’t have to explicitly provide all the arguments.\n\nlog(100)\n\n[1] 4.60517\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\nlog(base = 10, 100)\n\n[1] 2\n\nlog(base = 10, x = 100)\n\n[1] 2\n\n\n\n\n\nThe ... construct allows a function to take an unspecified number of arguments, e.g.,\n\nc\n\nfunction (...)  .Primitive(\"c\")\n\nsum\n\nfunction (..., na.rm = FALSE)  .Primitive(\"sum\")\n\n\nUsing ... as one of the arguments to a function allows a function to pass along user-provided arguments without specifying explicitly what the user might provide.\nHere’s an example of tailoring some plotting specifications that I use a lot.\n\npplot &lt;- function(x, y, ...) {\n      plot(x, y, pch = 16, cex = 0.6, ...)\n}\n\npplot(gapminder$gdpPercap, gapminder$lifeExp,  xlab = 'gdpPercap (log $)',\n      ylab = 'life expectancy (years)', log = 'x')\n\n\n\n\n\n\n\n\n\n\n\nFunctions in R are (roughly) pass-by-value and not pass-by-reference. This means that if you modify an argument inside the function it will not change the original value outside the function.\n\nx &lt;- rnorm(3)\n\nmyfun &lt;- function(x) {\n      x[1] &lt;- 0\n      return(x)\n}      \n\nnew_x &lt;- myfun(x)\nprint(new_x)\n\n[1] 0.00000000 1.06492085 0.05606448\n\nprint(x)\n\n[1] 0.07406567 1.06492085 0.05606448\n\n\nThis protects you from a major potential source of side effects. (There are exceptions to this rule.)\n\n\n\nIn actuality, functions in R are call-by-value.\nThis behavior is equivalent to copy-on-modify discussed in Unit 2.\n\nlibrary(pryr)\nif(exists('y')) rm(y)\n\nf &lt;- function(x, print_mem = FALSE){\n    if(print_mem) print(mem_used())\n    cat(\"Address of x from `address()`:\\n\")\n    print(address(x))  # address() is wrong here!\n    cat(\"Address of x from `inspect()`:\\n\")\n    print(.Internal(inspect(x)))\n\n    x[1] &lt;- 7\n    if(print_mem) print(mem_used())\n    cat(\"Address of x after modification:\\n\")\n    return(x)\n}\n\nn &lt;- 10\ny &lt;- rnorm(n)\ny[1:3]\n\n[1] -0.7088104  1.7530076  0.7761180\n\ncat(\"Address of y:\\n\")\n\nAddress of y:\n\nprint(address(y))\n\n[1] \"0x5daf49655768\"\n\nz &lt;- f(y)\n\nAddress of x from `address()`:\n[1] \"0x5daf482d0e80\"\nAddress of x from `inspect()`:\n@5daf49655768 14 REALSXP g0c5 [REF(3)] (len=10, tl=0) -0.70881,1.75301,0.776118,-2.25057,1.89023,...\n [1] -0.70881042  1.75300763  0.77611795 -2.25056620  1.89023371 -1.32573446\n [7]  1.04454620 -1.54409837  1.09363992 -0.05574238\nAddress of x after modification:\n\nz[1:3]\n\n[1] 7.000000 1.753008 0.776118\n\ncat(\"Address of z:\\n\")\n\nAddress of z:\n\nprint(address(z))\n\n[1] \"0x5daf49659f48\"\n\n\nStrangely, address gives the wrong answer when used inside f above. I’m not sure what is going on, but using .Internal(inspect) or trying this with a large value of n and seeing that memory use does not increase confirms that copy-on-modify is working.\n\n\n\nIn general functions should not make use of variables from outside the function. (However, for quick-and-dirty work and in some other circumstances, one may do this.) This provides modularity and reduces bugs and surprises.\nIf R can’t find a variable that is used in a function based on the function arguments and variables defined locally in the function, it goes and looks elsewhere following a set of rules called lexical scoping.\n(This type of scoping has to do with R’s roots (and explains why R is very similar to other languages for functional programming) - we won’t go into details here but certainly worth looking into as you start using R more.)\nBasically this means that it looks for variables relative to where the function is defined (not relative to where the function is called).\nThis can get involved, but a couple brief examples illustrate the basic idea.\n\nx &lt;- 2\nf &lt;- function(y) {\n    return(x + y)\n}\nf(1)\n\n[1] 3\n\ng &lt;- function(y) {\n  x &lt;- 10\n  return(f(y))\n}\n\ng(1)\n\n[1] 3\n\ng &lt;- function(y) {\n  f &lt;- function(y) {\n     return(x + y)\n  }\n  x &lt;- 10\n  return(f(y))\n}\n\ng(1)\n\n[1] 11\n\n\nNote that x is used as a global variable here, which in general is bad practice.\n\n\n\nConsider the lm function. It uses lm.fit for its actual computation.\nSuppose scoping depended on where the function (lm in this case) is called from? What would happen now:\n\nx &lt;- rnorm(5)\ny &lt;- rnorm(5)\nlm(y ~ x)\n\nlm.fit &lt;- function(...) print('Better luck next time, sucker.')\n\nlm.fit()\nlm(y~x)\n\nR’s scoping, in combination with package namespaces (collections of variables associated with a package) protects against this kind of problem.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#r-is-a-functional-language",
    "href": "units/programming.html#r-is-a-functional-language",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "Functions are one of the most important constructs in R (and many other languages). They allow you to modularize your code - encapsulating a set of repeatable operations as an individual function call.\n\nOperations are carried out with functions. Functions take objects as inputs and return objects as outputs.\nAn analysis can be considered a pipeline of function calls, with output from a function used later in a subsequent operation as input to another function.\nFunctions themselves are objects with a class and that you can manipulate:\n\n\nmedian\n\nfunction (x, na.rm = FALSE, ...) \nUseMethod(\"median\")\n&lt;bytecode: 0x5daf45104a20&gt;\n&lt;environment: namespace:stats&gt;\n\nargs(median)\n\nfunction (x, na.rm = FALSE, ...) \nNULL\n\nclass(median)\n\n[1] \"function\"\n\nmyfun &lt;- median\nlapply(list(c(2,4), c(2,6)), myfun)\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 4",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#using-functions",
    "href": "units/programming.html#using-functions",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "You should rely heavily on functions rather than having long sets of expressions in R scripts.\nFunctions have many important advantages:\n\nThey reduce bugs by avoiding having multiple instances of the same functionality.\nThey reduce time involved in coding by eliminating redundancy.\nThey make for cleaner and more easily-readable code.\n\nA basic goal is writing functions is modularity.\nIn general, a function should\n\nbe fairly short,\nbe focused and specific in what it does,\nbe designed so that it can be used in combination with other functions to carry out more complicated operations,\ngenerally make use only of arguments to the function and internal variables.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#function-arguments",
    "href": "units/programming.html#function-arguments",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "R can match arguments by name (when provided) or by position (the fall-back). It also allows one to specify default values so that the user doesn’t have to explicitly provide all the arguments.\n\nlog(100)\n\n[1] 4.60517\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\nlog(base = 10, 100)\n\n[1] 2\n\nlog(base = 10, x = 100)\n\n[1] 2",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#what-is-the-argument-for",
    "href": "units/programming.html#what-is-the-argument-for",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "The ... construct allows a function to take an unspecified number of arguments, e.g.,\n\nc\n\nfunction (...)  .Primitive(\"c\")\n\nsum\n\nfunction (..., na.rm = FALSE)  .Primitive(\"sum\")\n\n\nUsing ... as one of the arguments to a function allows a function to pass along user-provided arguments without specifying explicitly what the user might provide.\nHere’s an example of tailoring some plotting specifications that I use a lot.\n\npplot &lt;- function(x, y, ...) {\n      plot(x, y, pch = 16, cex = 0.6, ...)\n}\n\npplot(gapminder$gdpPercap, gapminder$lifeExp,  xlab = 'gdpPercap (log $)',\n      ylab = 'life expectancy (years)', log = 'x')",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#pass-by-value",
    "href": "units/programming.html#pass-by-value",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "Functions in R are (roughly) pass-by-value and not pass-by-reference. This means that if you modify an argument inside the function it will not change the original value outside the function.\n\nx &lt;- rnorm(3)\n\nmyfun &lt;- function(x) {\n      x[1] &lt;- 0\n      return(x)\n}      \n\nnew_x &lt;- myfun(x)\nprint(new_x)\n\n[1] 0.00000000 1.06492085 0.05606448\n\nprint(x)\n\n[1] 0.07406567 1.06492085 0.05606448\n\n\nThis protects you from a major potential source of side effects. (There are exceptions to this rule.)",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#call-by-value",
    "href": "units/programming.html#call-by-value",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "In actuality, functions in R are call-by-value.\nThis behavior is equivalent to copy-on-modify discussed in Unit 2.\n\nlibrary(pryr)\nif(exists('y')) rm(y)\n\nf &lt;- function(x, print_mem = FALSE){\n    if(print_mem) print(mem_used())\n    cat(\"Address of x from `address()`:\\n\")\n    print(address(x))  # address() is wrong here!\n    cat(\"Address of x from `inspect()`:\\n\")\n    print(.Internal(inspect(x)))\n\n    x[1] &lt;- 7\n    if(print_mem) print(mem_used())\n    cat(\"Address of x after modification:\\n\")\n    return(x)\n}\n\nn &lt;- 10\ny &lt;- rnorm(n)\ny[1:3]\n\n[1] -0.7088104  1.7530076  0.7761180\n\ncat(\"Address of y:\\n\")\n\nAddress of y:\n\nprint(address(y))\n\n[1] \"0x5daf49655768\"\n\nz &lt;- f(y)\n\nAddress of x from `address()`:\n[1] \"0x5daf482d0e80\"\nAddress of x from `inspect()`:\n@5daf49655768 14 REALSXP g0c5 [REF(3)] (len=10, tl=0) -0.70881,1.75301,0.776118,-2.25057,1.89023,...\n [1] -0.70881042  1.75300763  0.77611795 -2.25056620  1.89023371 -1.32573446\n [7]  1.04454620 -1.54409837  1.09363992 -0.05574238\nAddress of x after modification:\n\nz[1:3]\n\n[1] 7.000000 1.753008 0.776118\n\ncat(\"Address of z:\\n\")\n\nAddress of z:\n\nprint(address(z))\n\n[1] \"0x5daf49659f48\"\n\n\nStrangely, address gives the wrong answer when used inside f above. I’m not sure what is going on, but using .Internal(inspect) or trying this with a large value of n and seeing that memory use does not increase confirms that copy-on-modify is working.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#variable-scope-and-global-variables",
    "href": "units/programming.html#variable-scope-and-global-variables",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "In general functions should not make use of variables from outside the function. (However, for quick-and-dirty work and in some other circumstances, one may do this.) This provides modularity and reduces bugs and surprises.\nIf R can’t find a variable that is used in a function based on the function arguments and variables defined locally in the function, it goes and looks elsewhere following a set of rules called lexical scoping.\n(This type of scoping has to do with R’s roots (and explains why R is very similar to other languages for functional programming) - we won’t go into details here but certainly worth looking into as you start using R more.)\nBasically this means that it looks for variables relative to where the function is defined (not relative to where the function is called).\nThis can get involved, but a couple brief examples illustrate the basic idea.\n\nx &lt;- 2\nf &lt;- function(y) {\n    return(x + y)\n}\nf(1)\n\n[1] 3\n\ng &lt;- function(y) {\n  x &lt;- 10\n  return(f(y))\n}\n\ng(1)\n\n[1] 3\n\ng &lt;- function(y) {\n  f &lt;- function(y) {\n     return(x + y)\n  }\n  x &lt;- 10\n  return(f(y))\n}\n\ng(1)\n\n[1] 11\n\n\nNote that x is used as a global variable here, which in general is bad practice.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#why-does-scoping-work-that-way",
    "href": "units/programming.html#why-does-scoping-work-that-way",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "Consider the lm function. It uses lm.fit for its actual computation.\nSuppose scoping depended on where the function (lm in this case) is called from? What would happen now:\n\nx &lt;- rnorm(5)\ny &lt;- rnorm(5)\nlm(y ~ x)\n\nlm.fit &lt;- function(...) print('Better luck next time, sucker.')\n\nlm.fit()\nlm(y~x)\n\nR’s scoping, in combination with package namespaces (collections of variables associated with a package) protects against this kind of problem.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#basics-of-object-oriented-programming-oop",
    "href": "units/programming.html#basics-of-object-oriented-programming-oop",
    "title": "Programming Concepts and Tools",
    "section": "Basics of object-oriented programming (OOP)",
    "text": "Basics of object-oriented programming (OOP)\nThe basic idea is that coding is structured around objects, which belong to a class, and methods that operate on objects in the class.\nObjects are like lists, but with methods that are specifically associated with particular classes.\nObjects have fields, analogous to the components of a list.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#working-with-s3-classes-and-methods",
    "href": "units/programming.html#working-with-s3-classes-and-methods",
    "title": "Programming Concepts and Tools",
    "section": "Working with S3 classes and methods",
    "text": "Working with S3 classes and methods\nS3 objects are generally built upon lists.\n\nmod &lt;- lm(gapminder$lifeExp ~ log(gapminder$gdpPercap))\nclass(mod)\n\n[1] \"lm\"\n\nis.list(mod)\n\n[1] TRUE\n\nnames(mod)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\nmod$coefficients\n\n             (Intercept) log(gapminder$gdpPercap) \n               -9.100889                 8.405085 \n\nmod[['coefficients']]\n\n             (Intercept) log(gapminder$gdpPercap) \n               -9.100889                 8.405085 \n\nmod[[1]]\n\n             (Intercept) log(gapminder$gdpPercap) \n               -9.100889                 8.405085 \n\n\nThe magic of R’s S3 OOP approach here is that ‘generic’ methods (i.e., functions) can be tailored to work specifically with specific kinds of objects. This has been called “functional OOP” because the generic methods look like regular functions. It’s basically how Julia works as well.\n\nsummary(gapminder$lifeExp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.60   48.20   60.71   59.47   70.85   82.60 \n\nsummary(mod)\n\n\nCall:\nlm(formula = gapminder$lifeExp ~ log(gapminder$gdpPercap))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.778  -4.204   1.212   4.658  19.285 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               -9.1009     1.2277  -7.413 1.93e-13 ***\nlog(gapminder$gdpPercap)   8.4051     0.1488  56.500  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.62 on 1702 degrees of freedom\nMultiple R-squared:  0.6522,    Adjusted R-squared:  0.652 \nF-statistic:  3192 on 1 and 1702 DF,  p-value: &lt; 2.2e-16\n\n\nQuestion: What do you think R is doing behind the scenes?\nConsider summary.lm.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#more-on-working-with-s3-classes-and-methods",
    "href": "units/programming.html#more-on-working-with-s3-classes-and-methods",
    "title": "Programming Concepts and Tools",
    "section": "More on working with S3 classes and methods",
    "text": "More on working with S3 classes and methods\n\nlibrary(methods)\nyb &lt;- gapminder$lifeExp &gt; 75\nyc &lt;- gapminder$lifeExp\nx &lt;- log(gapminder$gdpPercap)\nmod1 &lt;- lm(yc ~ x)\nmod2 &lt;- glm(yb ~ x, family = binomial)\nmod2$residuals[1:20] # access field with list-like syntax\n\n        1         2         3         4         5         6         7         8 \n-1.000026 -1.000031 -1.000035 -1.000033 -1.000022 -1.000027 -1.000054 -1.000035 \n        9        10        11        12        13        14        15        16 \n-1.000015 -1.000014 -1.000021 -1.000053 -1.000258 -1.000477 -1.000832 -1.001461 \n       17        18        19        20 \n-1.002613 -1.003204 -1.003496 -1.003838 \n\nclass(mod2)\n\n[1] \"glm\" \"lm\" \n\nis(mod2, \"lm\")\n\n[1] TRUE\n\nis.list(mod2)\n\n[1] TRUE\n\nnames(mod2)\n\n [1] \"coefficients\"      \"residuals\"         \"fitted.values\"    \n [4] \"effects\"           \"R\"                 \"rank\"             \n [7] \"qr\"                \"family\"            \"linear.predictors\"\n[10] \"deviance\"          \"aic\"               \"null.deviance\"    \n[13] \"iter\"              \"weights\"           \"prior.weights\"    \n[16] \"df.residual\"       \"df.null\"           \"y\"                \n[19] \"converged\"         \"boundary\"          \"model\"            \n[22] \"call\"              \"formula\"           \"terms\"            \n[25] \"data\"              \"offset\"            \"control\"          \n[28] \"method\"            \"contrasts\"         \"xlevels\"          \n\nmethods(class = \"glm\")\n\n [1] add1           anova          coerce         confint        cooks.distance\n [6] deviance       drop1          effects        extractAIC     family        \n[11] formula        influence      initialize     logLik         model.frame   \n[16] nobs           predict        print          profile        residuals     \n[21] rstandard      rstudent       show           sigma          slotsFromS3   \n[26] summary        vcov           weights       \nsee '?methods' for accessing help and source code\n\nmethods(predict)\n\n [1] predict.ar*                predict.Arima*            \n [3] predict.arima0*            predict.glm               \n [5] predict.HoltWinters*       predict.lm                \n [7] predict.loess*             predict.mlm*              \n [9] predict.nls*               predict.poly*             \n[11] predict.ppr*               predict.prcomp*           \n[13] predict.princomp*          predict.smooth.spline*    \n[15] predict.smooth.spline.fit* predict.StructTS*         \nsee '?methods' for accessing help and source code\n\npredict\n\nfunction (object, ...) \nUseMethod(\"predict\")\n&lt;bytecode: 0x5daf4516b028&gt;\n&lt;environment: namespace:stats&gt;\n\n# predict.glm\n\nWhen predict() is called on a GLM object, it first calls the generic predict(), which then recognizes that the first argument is of the class glm and immediately calls the right class-specific method, predict.glm() in this case.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#making-your-own-s3-classobjectmethod",
    "href": "units/programming.html#making-your-own-s3-classobjectmethod",
    "title": "Programming Concepts and Tools",
    "section": "Making your own S3 class/object/method",
    "text": "Making your own S3 class/object/method\nMaking an object and class-specific methods under S3 is simple.\n\nrboot2025 &lt;- list(month = 'August', year = 2025, \n  instructor = 'Paciorek', attendance = 100)\nclass(rboot2025) &lt;- \"workshop\"\n\nrboot2025\n\n$month\n[1] \"August\"\n\n$year\n[1] 2025\n\n$instructor\n[1] \"Paciorek\"\n\n$attendance\n[1] 100\n\nattr(,\"class\")\n[1] \"workshop\"\n\nis(rboot2025, \"workshop\")\n\n[1] TRUE\n\nrboot2025$instructor \n\n[1] \"Paciorek\"\n\nprint.workshop &lt;- function(x) {\n    with(x,\n       cat(\"A workshop held in \", month, \" \", year, \"; taught by \", instructor, \".\\nThe attendance was \", attendance, \".\\n\", sep = \"\"))\n    invisible(x)\n}\n\n# doesn't execute correctly in the slide creation, so comment out here:\n# rboot2025 \n\nNote that we rely on the generic print() already existing in R. Otherwise we’d need to create it.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#brief-introduction-to-r6-classes",
    "href": "units/programming.html#brief-introduction-to-r6-classes",
    "title": "Programming Concepts and Tools",
    "section": "Brief introduction to R6 Classes",
    "text": "Brief introduction to R6 Classes\nR6 classes are a somewhat-recent feature in R that provides object-oriented programming with behavior more like in other languages like Python and C++.\nHere’s an extended example that simulates random time series.\n\nlibrary(R6)\n\ntsSimClass &lt;- R6Class(\"tsSimClass\",\n    ## Class for holding time series simulators\n    public = list(\n        ## Public methods (and possibly fields) are the user-facing interface.\n        initialize = function(times, mean = 0, corParam = 1){\n            library(fields)\n            stopifnot(is.numeric(corParam), length(corParam) == 1)\n            stopifnot(is.numeric(times))\n            private$times &lt;- times\n            private$n &lt;- length(times)\n            private$mean &lt;- mean\n            private$corParam &lt;- corParam\n            private$currentU &lt;- FALSE\n            private$calcMats()\n        },\n\n        simulate = function() {\n            if(!private$currentU)\n                private$calcMats()\n            ## analogous to mu+sigma*z for generating N(mu, sigma^2)\n            return(private$mean + crossprod(private$U, rnorm(private$n)))\n        },\n        \n        changeTimes = function(newTimes){\n            # Modifies a private member field (i.e., a 'setter') and recalculates.\n            private$times &lt;- newTimes\n            private$calcMats()\n        },\n        \n        getTimes = function(){\n            # A 'getter' method\n            return(private$times)\n        },\n\n        print = function(){ # 'print' method\n            cat(\"R6 Object of class 'tsSimClass' with \",\n                private$n, \" time points.\\n\", sep = '')\n            invisible(self)\n        }\n    ),\n\n    ## Private methods and functions not accessible externally\n    private = list(\n        calcMats = function() {\n            ## Calculates correlation matrix and Cholesky factor.\n            ## Caches results of expensive computation.\n            lagMat &lt;- fields::rdist(private$times) # local variable\n            corMat &lt;- exp(-lagMat^2 / private$corParam^2)\n            private$U &lt;- chol(corMat) # square root matrix\n            cat(\"Done updating correlation matrix and Cholesky factor.\\n\")\n            private$currentU &lt;- TRUE\n            invisible(self)\n        },\n        # Internal (private) fields not directly accessible from outside the object\n        n = NULL, \n        times = NULL,\n        mean = NULL,\n        corParam = NULL,\n        U = NULL,\n        currentU = FALSE\n    )\n)   \n\nmy_ts &lt;- tsSimClass$new(1:100, 2, 1)\n\nLoading required package: spam\n\n\nSpam version 2.11-1 (2025-01-20) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAttaching package: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nLoading required package: viridisLite\n\n\n\nTry help(fields) to get started.\n\n\nDone updating correlation matrix and Cholesky factor.\n\nmy_ts\n\nR6 Object of class 'tsSimClass' with 100 time points.\n\nset.seed(1)\ny &lt;- my_ts$simulate()   # Generate a time series.\nplot(my_ts$getTimes(), y, type = 'l', xlab = 'time',\n      ylab = 'process values')\n## We can't directly access private fields or methods.\n## These will fail:\n# my_ts$times\n# my_ts$calcMats()\n\nmy_ts &lt;- tsSimClass$new(1:100, 2, 3)\n\nDone updating correlation matrix and Cholesky factor.\n\nset.seed(1)\ny &lt;- my_ts$simulate()   # generate a second time series\nlines(my_ts$getTimes(), y, col = 'red')",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#error-and-warning-messages",
    "href": "units/programming.html#error-and-warning-messages",
    "title": "Programming Concepts and Tools",
    "section": "Error and warning messages",
    "text": "Error and warning messages\nWhen you write your own functions, and particularly for distributing to others, it’s a good idea to:\n\nCheck for possible errors (particularly in the input arguments) and give the user an informative error message,\nWarn them if you’re detect or do something they might not have anticipated,\n\nWe can use stop() and warning() to do this. They’re the same functions that are being called when you see an error message or a warning in reaction to your own work in R.\n\nmysqrt &lt;- function(x) {\n  if(is.list(x)) {\n    warning(\"x is a list; converting to a vector\")\n    x &lt;- unlist(x)\n  }\n  if(!is.numeric(x)) {\n    stop(\"What is the square root of 'sarah'?\")\n  } else {\n      if(any(x &lt; 0)) {\n        warning(\"mysqrt: found negative values; proceeding anyway\")\n        x[x &gt;= 0] &lt;- (x[x &gt;= 0])^(1/2)\n        x[x &lt; 0] &lt;- NaN\n        return(x)\n      } else return(x^(1/2))\n  }\n}\n\nmysqrt(c(1, 2, 3))\n\n[1] 1.000000 1.414214 1.732051\n\nmysqrt(c(5, -7))\n\nWarning in mysqrt(c(5, -7)): mysqrt: found negative values; proceeding anyway\n\n\n[1] 2.236068      NaN\n\nmysqrt(c('asdf', 'sdf'))\n\nError in mysqrt(c(\"asdf\", \"sdf\")): What is the square root of 'sarah'?\n\nmysqrt(list(5, 3, 'ab'))\n\nWarning in mysqrt(list(5, 3, \"ab\")): x is a list; converting to a vector\n\n\nError in mysqrt(list(5, 3, \"ab\")): What is the square root of 'sarah'?\n\nsqrt(c(5, -7))\n\nWarning in sqrt(c(5, -7)): NaNs produced\n\n\n[1] 2.236068      NaN\n\nsqrt('asdf')\n\nError in sqrt(\"asdf\"): non-numeric argument to mathematical function\n\nsqrt(list(5, 3, 2))\n\nError in sqrt(list(5, 3, 2)): non-numeric argument to mathematical function\n\n\nSo we’ve done something similar to what sqrt() actually does in R.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#catching-errors",
    "href": "units/programming.html#catching-errors",
    "title": "Programming Concepts and Tools",
    "section": "‘Catching’ errors",
    "text": "‘Catching’ errors\nWhen you automate analyses, sometimes an R function call will fail. But you don’t want all of your analyses to grind to a halt because one failed. Rather, you want to catch the error, record that it failed, and move on.\nFor me this is most critical when I’m doing stratified analyses or sequential operations.\nThe try() function is a powerful tool here.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#why-we-need-to-try",
    "href": "units/programming.html#why-we-need-to-try",
    "title": "Programming Concepts and Tools",
    "section": "Why we need to try()",
    "text": "Why we need to try()\nSuppose we tried to do a stratified analysis of life expectancy on GDP within continents, for 2007. I’m going to do this as a for loop for pedagogical reasons, but it would be better to do this with dplyr/lapply type tools.\nFor the purpose of illustration, I’m going to monkey a bit with the data such that there is an error in fitting Oceania. This is artificial, but when you stratify data into smaller groups it’s not uncommon that the analysis can fail for one of the groups (often because of small sample size or missing data).\n\nmod &lt;- list()\nfakedat &lt;- gapminder[gapminder$year == 2007, ]\nfakedat$gdpPercap[fakedat$continent == 'Oceania'] &lt;- NA\n\nfor(cont in c('Asia', 'Oceania', 'Europe', 'Americas', 'Africa')) {\n      cat(\"Fitting model for continent \", cont, \".\\n\")\n      tmp &lt;- subset(fakedat, continent == cont)\n      mod[[cont]] &lt;- lm(lifeExp ~ log(gdpPercap), data = tmp)\n}\n\nFitting model for continent  Asia .\nFitting model for continent  Oceania .\n\n\nError in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...): 0 (non-NA) cases\n\n\nWhat happened?",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#how-we-can-try-harder",
    "href": "units/programming.html#how-we-can-try-harder",
    "title": "Programming Concepts and Tools",
    "section": "How we can try() harder",
    "text": "How we can try() harder\n\nmod &lt;- list()\nfakedat &lt;- gapminder[gapminder$year == 2007, ]\nfakedat$gdpPercap[fakedat$continent == 'Oceania'] &lt;- NA\n\nfor(cont in c('Asia', 'Oceania', 'Europe', 'Americas', 'Africa')) {\n       cat(\"Fitting model for continent \", cont, \".\\n\")\n       tmp &lt;- subset(fakedat, continent == cont)\n\n       # Run without error-ing out.\n       curMod &lt;- try(lm(lifeExp ~ log(gdpPercap), data = tmp))\n\n       # Catch the error.\n       if(is(curMod, \"try-error\")) mod[[cont]] &lt;- NA \n           else mod[[cont]] &lt;- curMod            \n}\n\nFitting model for continent  Asia .\nFitting model for continent  Oceania .\nError in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : \n  0 (non-NA) cases\nFitting model for continent  Europe .\nFitting model for continent  Americas .\nFitting model for continent  Africa .\n\nmod[[1]]\n\n\nCall:\nlm(formula = lifeExp ~ log(gdpPercap), data = tmp)\n\nCoefficients:\n   (Intercept)  log(gdpPercap)  \n        25.650           5.157  \n\nmod[[2]]\n\n[1] NA",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#debugging",
    "href": "units/programming.html#debugging",
    "title": "Programming Concepts and Tools",
    "section": "Debugging",
    "text": "Debugging\nAs a scripting language, R essentially has a debugger working automatically by virtue of you often being able to easily run code line by line.\nBut there is an official debugger and other tools that greatly help in figuring out problems, particularly for more complicated situations.\nLet’s briefly see these in action. I’ll demo this in a very basic way, but hopefully this will give you an idea of the power of these tools.\n\nbuggyFun &lt;- function(myDF) {\n   print(names(myDF))\n   myDF$id &lt;- seq_len(nrow(myDF))\n   sums &lt;- rowSums(myDF)\n   return(sums)\n}\n\nbuggyFun(gapminder)\n\n[1] \"country\"   \"continent\" \"year\"      \"lifeExp\"   \"pop\"       \"gdpPercap\"\n\n\nError in base::rowSums(x, na.rm = na.rm, dims = dims, ...): 'x' must be numeric\n\n## Here are the commands we'll use in the demo.\nif(FALSE) {\n  traceback()\n  debug(buggyFun)\n  buggyFun(gapminder)\n\n  undebug(buggyFun)\n  options(error = recover)\n  buggyFun(gapminder)\n}\n\n\nWe can use debug() to step through a function line by line\nAfter an error occurs, we can use traceback() to look at the call stack (the series of nested function calls) to determine the steps leading to the error. (Note that Python error message show the stack. R’s do not.)\nMore helpfully, if we set options(error = recover) before running code, we can go into the function call in which the error occurred\nWe can insert browser() inside a function to set breakpoints and R will stop there and allow us to proceed with debugging statements\nYou can temporarily insert code into a function (including built-in functions) with trace(fxnName, edit = TRUE)\n\nThese tools are integrated into RStudio as a visual debugger.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/programming.html#testing",
    "href": "units/programming.html#testing",
    "title": "Programming Concepts and Tools",
    "section": "Testing",
    "text": "Testing\nTesting should be performed on multiple levels and begun as early as possible in the development process. For programs that accept input either from a user or file, it is important that the code validates the input is what it expects to receive. Tests that ensure individual code elements (e.g., functions, classes, and class methods) behave correctly are called unit tests. Writing unit tests early in the process of implementing new functionality helps you think about what you want a piece of code to do, rather than just how it does it. This practice improves code quality by focusing your attention on use cases rather than getting lost in implementation details.\nThe testthat package is very helpful for setting up tests.\nFor automated testing (continuous integration), many developers use GitHub Actions to run a test suite automatically (e.g., for each pull request or each commit). Here’s an example from an R package that I am a developer of. One creates a configuration (yaml) file and then GitHub runs the action automatically, giving the results in the Actions tab.",
    "crumbs": [
      "Modules",
      "Programming"
    ]
  },
  {
    "objectID": "units/ggplot.html",
    "href": "units/ggplot.html",
    "title": "Graphics with ggplot",
    "section": "",
    "text": "Most users use either base R graphics or ggplot (in the ggplot2 package). We’ll focus on ggplot after a brief intro of base R graphics.\nAnd here’s some motivation - we can produce a plot like this with a few lines of code.\n(Compare to the famous gapminder plot.)\nIn 2018 or so, producing my version of the plot took me some time experimenting and Googling. I suspect one could do it with a ChatBot quite quickly now. But I’d be curious what errors there would be and how much debugging and knowledge of ggplot would be needed.",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#other-plot-types-in-base-graphics",
    "href": "units/ggplot.html#other-plot-types-in-base-graphics",
    "title": "Graphics with ggplot",
    "section": "Other plot types in base graphics",
    "text": "Other plot types in base graphics\nThese are a variety of other types of plots you can make in base graphics.\n\nboxplot(lifeExp ~ year, data = gapminder)\n\n\n\n\n\n\n\nhist(gapminder$lifeExp[gapminder$year == 2007])\n\n\n\n\n\n\n\nplot(density(gapminder$lifeExp[gapminder$year == 2007]))\n\n\n\n\n\n\n\nbarplot(gapChina$pop, width = 4, names.arg = gapChina$year, \n                               main = \"China population\")",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#object-oriented-plots",
    "href": "units/ggplot.html#object-oriented-plots",
    "title": "Graphics with ggplot",
    "section": "Object-oriented plots",
    "text": "Object-oriented plots\n\nBase graphics often recognizes the object type and will implement specific plot methods\nggplot generally doesn’t exhibit this sort of behavior\n\nHere are two examples:\n\ngap_lm &lt;- lm(lifeExp ~ log(gdpPercap) + year, data = gapminder)\n\n# Calls plotting method for class of the dataset (\"data.frame\")\nplot(gapminder[,c('pop','lifeExp','gdpPercap')])\n\n\n\n\n\n\n\n\n\n# Calls plotting method for class of gap_lm object (\"lm\"), print first two plots only\nplot(gap_lm, which=1:2)",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#proscons-of-base-graphics-vs.-ggplot",
    "href": "units/ggplot.html#proscons-of-base-graphics-vs.-ggplot",
    "title": "Graphics with ggplot",
    "section": "Pros/cons of base graphics vs. ggplot",
    "text": "Pros/cons of base graphics vs. ggplot\nBase graphics is:\n\ngood for exploratory data analysis and sanity checks\ninconsistent in syntax across functions: some take x,y while others take formulas\ndefault plotting parameters are ugly, and it can be difficult to customize\nthat said, one can do essentially anything in base graphics with some work\n\nggplot2 is:\n\ngenerally more elegant\nmore syntactically logical (and therefore simpler, once you learn it)\nbetter at grouping\nable to interface with maps\n\nWe’ll focus on ggplot2 as it is very powerful, very widely-used and allows one to produce very nice-looking graphics without a lot of coding.",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#basic-usage-ggplot2",
    "href": "units/ggplot.html#basic-usage-ggplot2",
    "title": "Graphics with ggplot",
    "section": "Basic usage: ggplot2",
    "text": "Basic usage: ggplot2\nThe general call for ggplot2 graphics looks something like this:\n\n# NOT run\nggplot(data = , aes(x = ,y = , [options])) + geom_xxxx() + ... + ... + ...\n\nNote that ggplot2 graphs in layers in a continuing call (hence the endless +…+…+…), which makes additional layers in the plot.\n\n... + geom_xxxx(data = , aes(x = , y = ,[options]), [options]) + ... + ... + ...\n\nYou can see the layering effect by comparing the same graph with different colors for each layer\n\np &lt;- ggplot(data = gapChina, aes(x = year, y = lifeExp)) +\n                 geom_point(color = \"red\")\np\n\n\n\n\n\n\n\np + geom_point(aes(x = year, y = lifeExp), color = \"gray\") + ylab(\"life expectancy\") +\n    theme_minimal()",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#grammar-of-graphics",
    "href": "units/ggplot.html#grammar-of-graphics",
    "title": "Graphics with ggplot",
    "section": "Grammar of graphics",
    "text": "Grammar of graphics\nggplot2 syntax is very different from base R graphics. It’s built on the grammar of graphics. The basic idea is that the visualization of all data requires four items:\n\nOne or more statistics conveying information about the data (identities, means, medians, etc.)\nA coordinate system that characterizes the intersections of statistics (at most two for ggplot, three for lattice)\nGeometries that differentiate between off-coordinate variation in kind\nScales that differentiate between off-coordinate variation in degree\n\nggplot2 allows the user to manipulate all four of these items through the stat_*, coord_*, geom_*, and scale_* functions.\nAll of these are important to becoming a ggplot expert, but today we are going to focus on the most important to basic users and their data layers: ggplot’s geometries.",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#some-examples",
    "href": "units/ggplot.html#some-examples",
    "title": "Graphics with ggplot",
    "section": "Some Examples",
    "text": "Some Examples\n\n## Scatterplot\nggplot(gapChina, aes(x = year, y = lifeExp)) + geom_point() +\n                          ggtitle(\"China's life expectancy\")\n\n\n\n\n\n\n\n## Line (time series) plot\nggplot(gapChina, aes(x = year, y = lifeExp)) + geom_line() +\n                          ggtitle(\"China's life expectancy\")\n\n\n\n\n\n\n\n## Boxplot\nggplot(gapminder, aes(x = factor(year), y = lifeExp)) + geom_boxplot() +\n                          ggtitle(\"World's life expectancy\")\n\n\n\n\n\n\n\n## Histogram\ngapminder2007 &lt;- gapminder %&gt;% filter(year == 2007)\nggplot(gapminder2007, aes(x = lifeExp)) + geom_histogram(binwidth = 5) +\n                          ggtitle(\"World's life expectancy\")",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#ggplot-and-tidy-data",
    "href": "units/ggplot.html#ggplot-and-tidy-data",
    "title": "Graphics with ggplot",
    "section": "ggplot and tidy data",
    "text": "ggplot and tidy data\nggplot2 plays nicely with dplyr and pipes. If you want to manipulate your data specifically for one plot but not save the new dataset, you can call your dplyr chain and pipe it directly into a ggplot call.\n\n# This combines the subsetting and plotting into one step\ngapminder %&gt;% filter(year == 2007) %&gt;% \n        ggplot(aes(x = lifeExp)) + geom_histogram(binwidth = 5) +\n                          ggtitle(\"World's life expectancy\")\n\n\n\n\n\n\n\n\nBase graphics and ggplot have a big difference: ggplot requires your data to be in tidy format. For base graphics, it can actually be helpful not to have your data in tidy format in some cases.",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#features-of-ggplot",
    "href": "units/ggplot.html#features-of-ggplot",
    "title": "Graphics with ggplot",
    "section": "Features of ggplot",
    "text": "Features of ggplot\n\nAllows you to add features in “layers”\nAutomatically adjusts spacing and sizing as you add more layers\nRequires data to be in tidy format\nSyntax is different from base R – there is a learning curve\nPlots are actually objects. You can assign them to a variable and do things with it (more on this later)",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#an-overview-of-syntax-for-various-ggplot2-geoms",
    "href": "units/ggplot.html#an-overview-of-syntax-for-various-ggplot2-geoms",
    "title": "Graphics with ggplot",
    "section": "An overview of syntax for various ggplot2 geoms",
    "text": "An overview of syntax for various ggplot2 geoms\nWe’ve already seen these initial ones.\nThese are provided for reference – we won’t spend time on each one.\nX-Y scatter plots: geom_point()\n\nggplot(gapChina, aes(x = year, y = lifeExp)) + geom_point() +\n                          ggtitle(\"China's life expectancy\")\n\n\n\n\n\n\n\n\nX-Y line plots: geom_line() or geom_path()\n\nggplot(gapChina, aes(x = year, y = lifeExp)) + geom_line() +\n                          ggtitle(\"China's life expectancy\")\n\n\n\n\n\n\n\n\nHistograms: geom_histogram(), geom_col(), or geom_bar()\n\ngapminder2007 &lt;- gapminder %&gt;% filter(year == 2007)\nggplot(gapminder2007, aes(x = lifeExp)) + geom_histogram(binwidth = 5) +\n                          ggtitle(\"World's life expectancy\")\n\n\n\n\n\n\n\n\nDensities: geom_density(), geom_density2d()\n\nggplot(gapminder2007, aes(x = lifeExp)) + geom_density() + \n                          ggtitle(\"World's life expectancy\")\n\n\n\n\n\n\n\n\nBoxplots: geom_boxplot()\n\n# Notice that here, you must explicitly convert numeric years to factors\nggplot(data = gapminder, aes(x = factor(year), y = lifeExp)) +\n            geom_boxplot() \n\n\n\n\n\n\n\n\nContour plots: geom_contour()\n\ndata(volcano) # Load volcano contour data\nvolcano[1:10, 1:10] # Examine volcano dataset (first 10 rows and columns)\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]  100  100  101  101  101  101  101  100  100   100\n [2,]  101  101  102  102  102  102  102  101  101   101\n [3,]  102  102  103  103  103  103  103  102  102   102\n [4,]  103  103  104  104  104  104  104  103  103   103\n [5,]  104  104  105  105  105  105  105  104  104   103\n [6,]  105  105  105  106  106  106  106  105  105   104\n [7,]  105  106  106  107  107  107  107  106  106   105\n [8,]  106  107  107  108  108  108  108  107  107   106\n [9,]  107  108  108  109  109  109  109  108  108   107\n[10,]  108  109  109  110  110  110  110  109  109   108\n\nvolcano3d &lt;- melt(volcano) # Use reshape2 package to melt the data into tidy form\nhead(volcano3d) # Examine volcano3d dataset (head)\n\n  Var1 Var2 value\n1    1    1   100\n2    2    1   101\n3    3    1   102\n4    4    1   103\n5    5    1   104\n6    6    1   105\n\nnames(volcano3d) &lt;- c(\"xvar\", \"yvar\", \"zvar\") # Rename volcano3d columns\n\nggplot(data = volcano3d, aes(x = xvar, y = yvar, z = zvar)) +\n            geom_contour() \n\n\n\n\n\n\n\n\ntile/image/level plots, heatmaps: geom_tile(), geom_rect(), geom_raster()\n\nggplot(data = volcano3d, aes(x = xvar, y = yvar, z = zvar)) +\n            geom_tile(aes(fill = zvar))",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#trellis-plots",
    "href": "units/ggplot.html#trellis-plots",
    "title": "Graphics with ggplot",
    "section": "“Trellis” plots",
    "text": "“Trellis” plots\nTrellis plots allow you to stratify by a variable, with one panel per categorical value. One uses either facet_grid() or facet_wrap():\n\nggplot(data = gapminder, aes(x = lifeExp)) + geom_histogram(binwidth = 5) +\n            facet_wrap(~year)\n\n\n\n\n\n\n\n\nThis can be quite powerful. It gives you the ability to take account of an additional variable.",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#anatomy-of-aes",
    "href": "units/ggplot.html#anatomy-of-aes",
    "title": "Graphics with ggplot",
    "section": "Anatomy of aes()",
    "text": "Anatomy of aes()\n\n# NOT run\nggplot(data = , aes(x = , y = , color = , linetype = , shape = , size = ))\n\nThese four aesthetic parameters (color, linetype, shape, size) can be used to show variation in kind (categories) and variation in degree (numeric).\nParameters passed into aes should be variables in your dataset.\nParameters passed to geom_xxx outside of aes should not be related to your dataset – they apply to the whole figure.\n\nggplot(data = gapminder, aes(x = year, y = lifeExp)) +\n            geom_line(aes(color = country), show.legend = FALSE)\n\n\n\n\n\n\n\n\nNote what happens when we specify the color parameter outside of the aesthetic operator. ggplot views these specifications as invalid graphical parameters.\n\nggplot(data = gapminder, aes(x = year, y = lifeExp)) +\n            geom_line(color = country)\n\nError: object 'country' not found\n\nggplot(data = gapminder, aes(x = year, y = lifeExp)) +\n            geom_line(color = \"country\")\n\nError in `geom_line()`:\n! Problem while converting geom to grob.\nℹ Error occurred in the 1st layer.\nCaused by error:\n! Unknown colour name: country\n\n## This 'works' syntactically but not substantively.\nggplot(data = gapminder, aes(x = year, y = lifeExp)) +\n            geom_line(color = \"red\")\n\n\n\n\n\n\n\n\nNote: Aesthetics automatically show up in your legend. Parameters (those not mapped to a variable in your data frame) do not!",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#using-aesthetics-to-highlight-features",
    "href": "units/ggplot.html#using-aesthetics-to-highlight-features",
    "title": "Graphics with ggplot",
    "section": "Using aesthetics to highlight features",
    "text": "Using aesthetics to highlight features\n\nDifferences in kind\n\n## color as the aesthetic to differentiate by continent\nggplot(data = gapminder2007, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(aes(color = continent)) + scale_x_log10()\n\n## point shape as the aesthetic to differentiate by continent\nggplot(data = gapminder2007, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(aes(shape = continent)) + scale_x_log10()\n\n## line type as the aesthetic to differentiate by country\ngapOceania &lt;- gapminder %&gt;% filter(continent %in% 'Oceania')\nggplot(data = gapOceania, aes(x = year, y = lifeExp)) +\n            geom_line(aes(linetype = country)) + scale_x_log10()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifferences in degree\n\n## point size as the aesthetic to differentiate by population\nggplot(data = gapminder2007, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(aes(size = pop)) + scale_x_log10()\n\n## color as the aesthetic to differentiate by population\nggplot(data = gapminder2007, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(aes(color = pop)) + scale_x_log10() +\n            scale_color_gradient(low = 'lightgray', high = 'black')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple non-coordinate aesthetics (differences in kind using color, degree using point size)\n\nggplot(data = gapminder2007, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(aes(size = pop, color = continent)) + scale_x_log10()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow many variables have we represented? If we used a trellis plot we could represent yet another variable!",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#using-aesthetics-quick-quiz",
    "href": "units/ggplot.html#using-aesthetics-quick-quiz",
    "title": "Graphics with ggplot",
    "section": "Using aesthetics: quick quiz",
    "text": "Using aesthetics: quick quiz\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of these ggplot2 calls will work (in the sense of not giving an error, not in the sense of being a useful plot)?\n\ngapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) %&gt;% geom_point()\ngapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp))\ngapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point()\ngapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, shape = ‘a’)) + geom_point()\ngapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(shape = country), show.legend = FALSE)\ngapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(shape = ‘a’, show.legend = FALSE)\ngapminder %&gt;% ggplot() + geom_point(aes(x = gdpPercap, y = lifeExp, shape = country), show.legend = FALSE)",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#where-do-i-put-aes-optional",
    "href": "units/ggplot.html#where-do-i-put-aes-optional",
    "title": "Graphics with ggplot",
    "section": "Where do I put aes()? (optional)",
    "text": "Where do I put aes()? (optional)\nAs seen in the code snippets in the quick quiz, one can put aes() in the original ggplot() call or in latter geom_x() calls. What’s the difference?\n\nIf one puts aes() in ggplot(), it affects all subsequent calls that are part of the same ggplot expression.\nIf one puts aes() in a geom_x(), it affects only that particular component of the plotting.\n\nSo where you put it affects the “scope” of what it affects.\n\ngapminder %&gt;% filter(continent == \"Oceania\") %&gt;%\n          ggplot(aes(x = year, y = gdpPercap, color = country)) +\n          geom_line() + geom_point()\n\n\n\n\n\n\n\ngapminder %&gt;% filter(continent == \"Oceania\") %&gt;%\n          ggplot(aes(x = year, y = gdpPercap)) +\n          geom_line(aes(color = country)) + geom_point()\n\n\n\n\n\n\n\n# Yikes, this doesn't work right:\ngapminder %&gt;% filter(continent == \"Oceania\") %&gt;%\n          ggplot(aes(x = year, y = gdpPercap)) +\n          geom_point(aes(color = country)) + geom_line()",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#scaling-aesthetics",
    "href": "units/ggplot.html#scaling-aesthetics",
    "title": "Graphics with ggplot",
    "section": "Scaling Aesthetics",
    "text": "Scaling Aesthetics\nAesthetics are handled by their very own scale functions which allow you to set the limits, breaks, tranformations, and any palletes that might determine how you want your data plotted. ggplot includes a number of helpful default scale functions. For example:\n\nscale_x_log10 that can transform your data on the fly\nscale_color_viridis uses palettes from the viridis package specifically designed to “make plots that are pretty, better represent your data, easier to read by those with colorblindness, and print well in grey scale.”\n\nFor example, our data might be better represented using a log10 transformation of per capita GDP:\n\nggplot(gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(aes(color = continent)) +\n  scale_x_log10()\n\n\n\n\n\n\n\n\nAnd perhaps we want colors that are a little different:\n\nggplot(gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(aes(color = continent)) +\n  scale_x_log10() +\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nOr perhaps we want to set your palettes and breaks or labels manually:\n\nggplot(gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(aes(color = continent)) +\n  scale_x_log10(labels = scales::dollar) +\n  scale_color_manual(\"The continents\", \n                     values = c(\"red\", \"blue\", \"green\", \"yellow\", \"#800080\")) # hex codes work!\n\n\n\n\n\n\n\n\nFor more info about setting scales in ggplot and for more helper functions consider diving into the scales package which is the backend to much of the scales functionality in ggplot",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#fine-tuning-your-plot",
    "href": "units/ggplot.html#fine-tuning-your-plot",
    "title": "Graphics with ggplot",
    "section": "Fine tuning your plot",
    "text": "Fine tuning your plot\nggplot handles many plot options as additional layers.\n\nLabels\n\nggplot(data = gapminder2007, aes(x = gdpPercap, y = lifeExp)) + geom_point() +\n  xlab(label = \"GDP per capita\") +\n  ylab(label = \"Life expectancy\") +\n  ggtitle(label = \"Gapminder\") \n\n\n\n\n\n\n\n\nOr even more simply use the labs() function\n\nggplot(data = gapminder2007, aes(x = gdpPercap, y = lifeExp)) + geom_point() +\n  labs(x = \"GDP per capita\", y = \"Life expectancy\", title = \"Gapminder\")\n\n\n\nAxis and point scales\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point() \nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(size=3) \nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(size=1) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColors\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(color = colors()[11]) \nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(color = \"red\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoint Styles and Widths (optional)\n\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(shape = 3) \nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(shape = \"w\") \nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n            geom_point(shape = \"$\", size=5) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLine Styles and Widths (optional)\n\nggplot(data = gapChina, aes(x = year, y = lifeExp)) +\n            geom_line(linetype = 1) \nggplot(data = gapChina, aes(x = year, y = lifeExp)) +\n            geom_line(linetype = 2) \nggplot(data = gapChina, aes(x = year, y = lifeExp)) +\n            geom_line(linetype = 5, size = 2)",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#themes-with-ggplot2-optional",
    "href": "units/ggplot.html#themes-with-ggplot2-optional",
    "title": "Graphics with ggplot",
    "section": "Themes with ggplot2 (optional)",
    "text": "Themes with ggplot2 (optional)\nElements of the plot not associated with geometries can be adjusted using ggplot themes.\nThere are some “complete” themes already included with the package:\n\ntheme_gray() (the default)\ntheme_minimal()\ntheme_bw()\ntheme_light()\ntheme_dark()\ntheme_classic()\n\nBut in additional to these, you can tweak just about any element of your plot’s appearance using the theme() function.\nFor instance, perhaps you want to move the legend from the left to the bottom of your plot, this would be part of the plot theme. Note how you can add options to a complete theme already in the plot:\n\ngapminder %&gt;%\n  filter(country %in% c(\"China\", \"Turkey\", \"Italy\")) %&gt;%\n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_line(aes(color = country)) +\n  theme_minimal() + \n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#combining-multiple-plots",
    "href": "units/ggplot.html#combining-multiple-plots",
    "title": "Graphics with ggplot",
    "section": "Combining Multiple Plots",
    "text": "Combining Multiple Plots\n\nggplot graphs can be combined using the grid.arrange() function in the gridExtra package\n\n\nlibrary(gridExtra)\n\n# Create 3 plots to combine in a table\nplot1 &lt;- ggplot(data = gapminder2007, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() + scale_x_log10() + annotate('text', 150, 80, label = '(a)')\nplot2 &lt;- ggplot(data = gapminder2007, aes(x = pop, y = lifeExp)) +\n  geom_point() + scale_x_log10() + annotate('text', 1.8e5, 80, label = '(b)')\nplot3 &lt;- ggplot(data = gapminder, aes(x = year, y = lifeExp)) +\n      geom_line(aes(color = country), show.legend = FALSE) +\n      annotate('text', 1951, 80, label = '(c)')\n\n\n# Call grid.arrange\ngrid.arrange(plot1, plot2, plot3, nrow=3, ncol = 1)",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#patchwork-combining-multiple-ggplot-plots-optional",
    "href": "units/ggplot.html#patchwork-combining-multiple-ggplot-plots-optional",
    "title": "Graphics with ggplot",
    "section": "patchwork: Combining Multiple ggplot plots (optional)",
    "text": "patchwork: Combining Multiple ggplot plots (optional)\n\nThe patchwork package may be used to combine multiple ggplot plots using a small set of operators similar to the pipe.\nThis requires less syntax than using gridExtra and allows complex arrangements to be built nearly effortlessly.\n\n\nlibrary(patchwork)\n\n# use the patchwork operators\n# stack plots horizontally\nplot1 + plot2 + plot3\n\n\n\n\n\n\n\n\n\n# stack plots vertically\nplot1 / plot2 / plot3\n\n\n\n\n\n\n\n\n\n# side-by-side plots with third plot below\n(plot1 | plot2) / plot3\n\n\n\n\n\n\n\n\n\n# side-by-side plots with a space in between, and a third plot below\n(plot1 | plot_spacer() | plot2) / plot3\n\n\n\n\n\n\n\n\n\n# stack plots vertically and alter with a single \"gg_theme\"\n(plot1 / plot2 / plot3) & theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot extensions\n\n\n\npatchwork is an example of a ggplot2 extension package of which there are many! One of the benefits to learning and using ggplot is that there is a huge community of developers that build separate graphics packages that generally use the same syntax to extend the ggplot2 functionality into things like animation and 3D plotting! Check them out here.",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#rasterbitmap-.png-.jpeg",
    "href": "units/ggplot.html#rasterbitmap-.png-.jpeg",
    "title": "Graphics with ggplot",
    "section": "Raster/Bitmap (.png, .jpeg)",
    "text": "Raster/Bitmap (.png, .jpeg)\nEvery pixel of a plot contains its own separate coding:\n\nsensible for gridded/raster output\nbad if you want to resize the image\nfile size depends on pixel resolution\n\n\njpeg(filename = \"example.jpg\", width = , height =)\nplot(x,y)\ndev.off()",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#vector-.pdf-.ps",
    "href": "units/ggplot.html#vector-.pdf-.ps",
    "title": "Graphics with ggplot",
    "section": "Vector (.pdf, .ps)",
    "text": "Vector (.pdf, .ps)\nEvery element of a plot is encoded as a representation of its shape\n\ngreat for resizing\nimage files with many elements can be very large.\n\n\npdf(file = \"example.pdf\", width = , height =)\nplot(x,y)\ndev.off()",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/ggplot.html#exporting-with-ggplot",
    "href": "units/ggplot.html#exporting-with-ggplot",
    "title": "Graphics with ggplot",
    "section": "Exporting with ggplot",
    "text": "Exporting with ggplot\n\n# Assume we saved our plot as an object called `plot1`.\n\nggsave(filename = \"example.pdf\", plot = plot1, scale = , width = , height = )",
    "crumbs": [
      "Modules",
      "Plotting (ggplot)"
    ]
  },
  {
    "objectID": "units/speed.html",
    "href": "units/speed.html",
    "title": "Parallelization and Rcpp",
    "section": "",
    "text": "Note to participants: It can be troublesome to use parallelization in RStudio, so we’ll just run the demo code in this module in a command line R session. You can open the basic R GUI for Mac or Windows, or, on a Mac, start R in a terminal window.\n\nModern computers have multiple processors and clusters/supercomputers have multiple networked machines, each with multiple processors.\nThe key to increasing computational efficiency in these contexts is breaking up the work amongst the processors.\nProcessors on a single machine (or ‘node’) share memory and don’t need to carry out explicit communication (shared memory computation)\nProcessors on separate machines need to pass data across a network, often using the MPI protocol (distributed memory computation)\n\nWe’ll focus on shared memory computation here.\n\n\n\n\nLinux - count the processors listed in /proc/cpuinfo or use nproc\nMac - in a terminal: system_profiler | grep -i 'Cores'\nWindows - count the number of graphs shown for CPU Usage (or CPU Usage History) under “Task Manager-&gt;Performance”, or try this program\n\nTo see if multiple cores are being used by your job, you can do:\n\nMac/Linux - use top or ps\nWindows - see the “Task Manager-&gt;Performance-&gt;CPU Usage”\n\n\n\n\nSome basic approaches are:\n\nUse a linear algebra package that distributes computations across ‘threads’\nSpread independent calculations (embarrassingly parallel problems) across multiple cores\n\nfor loops with independent calculations\nparallelizing lapply() and its variants\n\n\n\n\n\nR comes with a default BLAS (basic linear algebra subroutines) and LAPACK (linear algebra package) that carry out the core linear algebra computations. However, you can generally improve performance (sometimes by an order of magnitude) by using a different BLAS. Furthermore a threaded BLAS will allow you to use multiple cores.\nA ‘thread’ is a lightweight process, and the operating system sees multiple threads as part of a single process.\n\nFor Linux, openBLAS and Intel’s MKL are both fast and threaded.\nFor Mac, Apple’s vecLib is fast and threaded.\nFor Windows, you may be out of luck.\n\nWe’ll show by demonstration that my desktop in my office is using multiple cores for linear algebra operations.\n\n# note to CJP: don't run on laptop with slow BLAS\nn &lt;- 5000\nx &lt;- matrix(rnorm(n^2), n)\nU &lt;- chol(crossprod(x))\n\nYou should see that your R process is using more than 100% of CPU. Inconceivable!\n\n\n\nYou can talk with your systems administrator about linking R to a fast BLAS or you can look into it yourself for your personal machine; see the R Installation and Administration manual.\nNote that in some cases, in particular for small matrix operations, using multiple threads may actually slow down computation, so you may want to experiment, particularly with Linux. You can force the linear algebra to use only a single core by doing (assuming you’re using the bash shell) export OMP_NUM_THREADS=1 in the terminal window before starting R in the same terminal. Or see the RhpcBLASctl package to do it from within R.\nFinally, note that threaded BLAS and either foreach or parallel versions of apply() can conflict and cause R to hang, so you’re likely to want to set the number of threads to 1 as above if you’re doing explicit parallelization.\n\n\n\nAn EP problem is one that can be solved by doing independent computations as separate processes without communication between the processes. You can get the answer by doing separate tasks and then collecting the results.\nExamples in statistics / data science / machine learning include\n\nstratified analyses\ncross-validation\nsimulations with many independent replicates\nbootstrapping\nrandom forest models\n\nSome things that are not EP (at least not in a basic formulation):\n\noptimization\nMarkov chain Monte Carlo for fitting Bayesian models",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#computer-architecture",
    "href": "units/speed.html#computer-architecture",
    "title": "Parallelization and Rcpp",
    "section": "",
    "text": "Note to participants: It can be troublesome to use parallelization in RStudio, so we’ll just run the demo code in this module in a command line R session. You can open the basic R GUI for Mac or Windows, or, on a Mac, start R in a terminal window.\n\nModern computers have multiple processors and clusters/supercomputers have multiple networked machines, each with multiple processors.\nThe key to increasing computational efficiency in these contexts is breaking up the work amongst the processors.\nProcessors on a single machine (or ‘node’) share memory and don’t need to carry out explicit communication (shared memory computation)\nProcessors on separate machines need to pass data across a network, often using the MPI protocol (distributed memory computation)\n\nWe’ll focus on shared memory computation here.",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#how-do-i-know-how-many-cores-a-computer-has",
    "href": "units/speed.html#how-do-i-know-how-many-cores-a-computer-has",
    "title": "Parallelization and Rcpp",
    "section": "",
    "text": "Linux - count the processors listed in /proc/cpuinfo or use nproc\nMac - in a terminal: system_profiler | grep -i 'Cores'\nWindows - count the number of graphs shown for CPU Usage (or CPU Usage History) under “Task Manager-&gt;Performance”, or try this program\n\nTo see if multiple cores are being used by your job, you can do:\n\nMac/Linux - use top or ps\nWindows - see the “Task Manager-&gt;Performance-&gt;CPU Usage”",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#how-can-we-make-use-of-multiple-cores",
    "href": "units/speed.html#how-can-we-make-use-of-multiple-cores",
    "title": "Parallelization and Rcpp",
    "section": "",
    "text": "Some basic approaches are:\n\nUse a linear algebra package that distributes computations across ‘threads’\nSpread independent calculations (embarrassingly parallel problems) across multiple cores\n\nfor loops with independent calculations\nparallelizing lapply() and its variants",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#threaded-linear-algebra",
    "href": "units/speed.html#threaded-linear-algebra",
    "title": "Parallelization and Rcpp",
    "section": "",
    "text": "R comes with a default BLAS (basic linear algebra subroutines) and LAPACK (linear algebra package) that carry out the core linear algebra computations. However, you can generally improve performance (sometimes by an order of magnitude) by using a different BLAS. Furthermore a threaded BLAS will allow you to use multiple cores.\nA ‘thread’ is a lightweight process, and the operating system sees multiple threads as part of a single process.\n\nFor Linux, openBLAS and Intel’s MKL are both fast and threaded.\nFor Mac, Apple’s vecLib is fast and threaded.\nFor Windows, you may be out of luck.\n\nWe’ll show by demonstration that my desktop in my office is using multiple cores for linear algebra operations.\n\n# note to CJP: don't run on laptop with slow BLAS\nn &lt;- 5000\nx &lt;- matrix(rnorm(n^2), n)\nU &lt;- chol(crossprod(x))\n\nYou should see that your R process is using more than 100% of CPU. Inconceivable!",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#more-details-on-the-blas-optional",
    "href": "units/speed.html#more-details-on-the-blas-optional",
    "title": "Parallelization and Rcpp",
    "section": "",
    "text": "You can talk with your systems administrator about linking R to a fast BLAS or you can look into it yourself for your personal machine; see the R Installation and Administration manual.\nNote that in some cases, in particular for small matrix operations, using multiple threads may actually slow down computation, so you may want to experiment, particularly with Linux. You can force the linear algebra to use only a single core by doing (assuming you’re using the bash shell) export OMP_NUM_THREADS=1 in the terminal window before starting R in the same terminal. Or see the RhpcBLASctl package to do it from within R.\nFinally, note that threaded BLAS and either foreach or parallel versions of apply() can conflict and cause R to hang, so you’re likely to want to set the number of threads to 1 as above if you’re doing explicit parallelization.",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#what-is-an-embarrassingly-parallel-ep-problem",
    "href": "units/speed.html#what-is-an-embarrassingly-parallel-ep-problem",
    "title": "Parallelization and Rcpp",
    "section": "",
    "text": "An EP problem is one that can be solved by doing independent computations as separate processes without communication between the processes. You can get the answer by doing separate tasks and then collecting the results.\nExamples in statistics / data science / machine learning include\n\nstratified analyses\ncross-validation\nsimulations with many independent replicates\nbootstrapping\nrandom forest models\n\nSome things that are not EP (at least not in a basic formulation):\n\noptimization\nMarkov chain Monte Carlo for fitting Bayesian models",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#using-multiple-cores-for-ep-problems-parallel-apply-using-future",
    "href": "units/speed.html#using-multiple-cores-for-ep-problems-parallel-apply-using-future",
    "title": "Parallelization and Rcpp",
    "section": "Using multiple cores for EP problems: parallel apply using future",
    "text": "Using multiple cores for EP problems: parallel apply using future\nThe future package provides a lot of nice features for parallelization. We’ll just scratch the surface here to parallelize operations over the elements of a list (note that this is essentially equivalent to parLapply and mclapply).\nFirst, make sure your computations on the elements are independent of each other and don’t involve sequential calculations!\nWe’ll use the airline departure dataset, with timing informatin for all flights from SFO over a period of several years. We’ll do a stratified analysis, fitting a GAM (see Unit 6) for each of the destination airports.\n\nair &lt;- read.csv(file.path('..', 'data', 'airline.csv'))\n\nfitFun &lt;- function(curDest) {\n            library(mgcv)\n            tmp &lt;- subset(air, Dest == curDest)\n            ## It would better to do this with date-time functionality:\n            tmp$Hour &lt;- tmp$CRSDepTime %/% 100\n            \n            curMod &lt;- try(gam(DepDelay ~ Year + s(Month) + s(Hour) + \n                 as.factor(DayOfWeek), data = tmp))\n            if(is(tmp, \"try-error\")) curMod &lt;- NA \n            return(curMod)\n}\n\n\nlibrary(future.apply)\n\nLoading required package: future\n\nnCores &lt;- 4\nplan(multisession, workers = nCores)  \nout &lt;- future_lapply(unique(air$Dest), fitFun)\n\nLoading required package: nlme\n\n\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\n\nLoading required package: nlme\n\n\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\n\nLoading required package: nlme\n\n\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\n\nLoading required package: nlme\n\n\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\nout[[1]]\n\n\nCall:  gam(formula = DepDelay ~ Year + s(Month) + s(Hour) + as.factor(DayOfWeek), \n    data = tmp)\n\nCoefficients:\n          (Intercept)                   Year  as.factor(DayOfWeek)2  \n           -3497.3037                 1.7490                -2.1810  \nas.factor(DayOfWeek)3  as.factor(DayOfWeek)4  as.factor(DayOfWeek)5  \n              -3.6045                -1.6800                 2.9982  \nas.factor(DayOfWeek)6  as.factor(DayOfWeek)7             s(Month).1  \n              -2.4173                 0.7169                -8.6549  \n           s(Month).2             s(Month).3             s(Month).4  \n              32.1570                12.0161                10.7049  \n           s(Month).5             s(Month).6             s(Month).7  \n               8.2426                13.9619                -4.9777  \n           s(Month).8             s(Month).9              s(Hour).1  \n             -46.2121                14.8763                 5.6931  \n            s(Hour).2              s(Hour).3              s(Hour).4  \n               4.5111                 9.9465                 8.5980  \n            s(Hour).5              s(Hour).6              s(Hour).7  \n               1.9587                 6.1938                -0.2061  \n            s(Hour).8              s(Hour).9  \n              -7.0151                 2.2963  \n\nDegrees of Freedom: 15782 Total (i.e. Null);  15760 Residual\n  (142 observations deleted due to missingness)\nNull Deviance:      17480000 \nResidual Deviance: 16550000     AIC: 154600\n\nout[[81]]\n\n[1] \"Error in smooth.construct.tp.smooth.spec(object, dk$data, dk$knots) : \\n  A term has fewer unique covariate combinations than specified maximum degrees of freedom\\n\"\nattr(,\"class\")\n[1] \"try-error\"\nattr(,\"condition\")\n&lt;simpleError in smooth.construct.tp.smooth.spec(object, dk$data, dk$knots): A term has fewer unique covariate combinations than specified maximum degrees of freedom&gt;\n\n\nNote that the plan statement determines how the parallelization is done behind the scenes. As shown here, it will start up workers locally on your computer, but if you have access to a cluster, you can modify the plan to make use of multiple compute nodes in a cluster.\nOne thing to keep in mind is whether the different tasks all take about the same amount of time or widely different times. In the latter case, one wants to sequentially dispatch tasks as earlier tasks finish, rather than dispatching a block of tasks to each core. See the future.scheduling argument for user control over how the allocation is done.",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#using-multiple-cores-for-ep-problems-foreach",
    "href": "units/speed.html#using-multiple-cores-for-ep-problems-foreach",
    "title": "Parallelization and Rcpp",
    "section": "Using multiple cores for EP problems: foreach",
    "text": "Using multiple cores for EP problems: foreach\nFirst, make sure your iterations are independent and don’t involve sequential calculations!\nThe foreach package provides a way to do a for loop using multiple cores. It can use a variety of ‘back-ends’ that handle the nitty-gritty of the parallelization. Happily it integrates with the future package nicely.\n\nlibrary(parallel)\nlibrary(doFuture)\nlibrary(foreach)\n\nnCores &lt;- 4  # actually only 2 on my laptop, but appears hyperthreaded\nregisterDoFuture()\nplan(multisession, workers = nCores)  \n\nout &lt;- foreach(dest = unique(air$Dest)) %dopar% {\n    cat(\"Starting job for \", dest, \".\\n\", sep = \"\")\n    outSub &lt;- fitFun(dest)\n    cat(\"Finishing job for \", dest, \".\\n\", sep = \"\")\n    outSub # this will become part of the out objec\n}\n\nStarting job for SLC.\nFinishing job for SLC.\nStarting job for PDX.\nFinishing job for PDX.\nStarting job for SNA.\nFinishing job for SNA.\nStarting job for DEN.\nFinishing job for DEN.\nStarting job for ORD.\nFinishing job for ORD.\nStarting job for RNO.\nFinishing job for RNO.\nStarting job for SAN.\nFinishing job for SAN.\nStarting job for IAH.\nFinishing job for IAH.\nStarting job for SEA.\nFinishing job for SEA.\nStarting job for IAD.\nFinishing job for IAD.\nStarting job for LAX.\nFinishing job for LAX.\nStarting job for EWR.\nFinishing job for EWR.\nStarting job for JFK.\nFinishing job for JFK.\nStarting job for OGG.\nFinishing job for OGG.\nStarting job for KOA.\nFinishing job for KOA.\nStarting job for BUR.\nFinishing job for BUR.\nStarting job for LAS.\nFinishing job for LAS.\nStarting job for PHX.\nFinishing job for PHX.\nStarting job for CLT.\nFinishing job for CLT.\nStarting job for PHL.\nFinishing job for PHL.\nStarting job for PIT.\nFinishing job for PIT.\n\n\nLoading required package: nlme\n\n\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\n\nStarting job for MEM.\nFinishing job for MEM.\nStarting job for CIC.\nFinishing job for CIC.\nStarting job for MFR.\nFinishing job for MFR.\nStarting job for ACV.\nFinishing job for ACV.\nStarting job for BFL.\nFinishing job for BFL.\nStarting job for SBA.\nFinishing job for SBA.\nStarting job for FAT.\nFinishing job for FAT.\nStarting job for MOD.\nFinishing job for MOD.\nStarting job for MRY.\nFinishing job for MRY.\nStarting job for CEC.\nFinishing job for CEC.\nStarting job for RDD.\nFinishing job for RDD.\nStarting job for RDM.\nFinishing job for RDM.\nStarting job for SBP.\nFinishing job for SBP.\nStarting job for SMF.\nFinishing job for SMF.\nStarting job for BOI.\nFinishing job for BOI.\nStarting job for EUG.\nFinishing job for EUG.\nStarting job for AUS.\nFinishing job for AUS.\nStarting job for TWF.\nFinishing job for TWF.\nStarting job for IDA.\nFinishing job for IDA.\nStarting job for PSC.\nFinishing job for PSC.\n\n\nLoading required package: nlme\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\n\nStarting job for MDW.\nFinishing job for MDW.\nStarting job for IND.\nFinishing job for IND.\nStarting job for HNL.\nFinishing job for HNL.\nStarting job for LIH.\nFinishing job for LIH.\nStarting job for BOS.\nFinishing job for BOS.\nStarting job for ATL.\nFinishing job for ATL.\nStarting job for MCO.\nFinishing job for MCO.\nStarting job for BWI.\nFinishing job for BWI.\nStarting job for MSY.\nFinishing job for MSY.\nStarting job for DFW.\nFinishing job for DFW.\nStarting job for CVG.\nFinishing job for CVG.\nStarting job for DTW.\nFinishing job for DTW.\nStarting job for MSP.\nFinishing job for MSP.\nStarting job for MIA.\nFinishing job for MIA.\nStarting job for STL.\nFinishing job for STL.\nStarting job for PSP.\nFinishing job for PSP.\nStarting job for CLE.\nFinishing job for CLE.\nStarting job for COS.\nFinishing job for COS.\nStarting job for SAT.\nFinishing job for SAT.\nStarting job for ABQ.\nFinishing job for ABQ.\n\n\nLoading required package: nlme\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\n\nStarting job for ANC.\nFinishing job for ANC.\nStarting job for SMX.\nFinishing job for SMX.\nStarting job for DRO.\nFinishing job for DRO.\nStarting job for PIH.\nFinishing job for PIH.\nStarting job for SJC.\nFinishing job for SJC.\nStarting job for ONT.\nFinishing job for ONT.\nStarting job for TUS.\nFinishing job for TUS.\nStarting job for EGE.\nFinishing job for EGE.\nStarting job for GJT.\nFinishing job for GJT.\nStarting job for ASE.\nFinishing job for ASE.\nStarting job for ELP.\nFinishing job for ELP.\nStarting job for PMD.\nFinishing job for PMD.\nStarting job for BZN.\nFinishing job for BZN.\nStarting job for BIL.\nFinishing job for BIL.\nStarting job for OAK.\nFinishing job for OAK.\nStarting job for MKE.\nFinishing job for MKE.\nStarting job for MSO.\nFinishing job for MSO.\nStarting job for FCA.\nFinishing job for FCA.\nStarting job for LMT.\nFinishing job for LMT.\nStarting job for OTH.\nFinishing job for OTH.\nStarting job for LGB.\nFinishing job for LGB.\n\n\nLoading required package: nlme\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\nout[1:2]\n\n[[1]]\n\nCall:  gam(formula = DepDelay ~ Year + s(Month) + s(Hour) + as.factor(DayOfWeek), \n    data = tmp)\n\nCoefficients:\n          (Intercept)                   Year  as.factor(DayOfWeek)2  \n           -3497.3037                 1.7490                -2.1810  \nas.factor(DayOfWeek)3  as.factor(DayOfWeek)4  as.factor(DayOfWeek)5  \n              -3.6045                -1.6800                 2.9982  \nas.factor(DayOfWeek)6  as.factor(DayOfWeek)7             s(Month).1  \n              -2.4173                 0.7169                -8.6549  \n           s(Month).2             s(Month).3             s(Month).4  \n              32.1570                12.0161                10.7049  \n           s(Month).5             s(Month).6             s(Month).7  \n               8.2426                13.9619                -4.9777  \n           s(Month).8             s(Month).9              s(Hour).1  \n             -46.2121                14.8763                 5.6931  \n            s(Hour).2              s(Hour).3              s(Hour).4  \n               4.5111                 9.9465                 8.5980  \n            s(Hour).5              s(Hour).6              s(Hour).7  \n               1.9587                 6.1938                -0.2061  \n            s(Hour).8              s(Hour).9  \n              -7.0151                 2.2963  \n\nDegrees of Freedom: 15782 Total (i.e. Null);  15760 Residual\n  (142 observations deleted due to missingness)\nNull Deviance:      17480000 \nResidual Deviance: 16550000     AIC: 154600\n\n[[2]]\n\nCall:  gam(formula = DepDelay ~ Year + s(Month) + s(Hour) + as.factor(DayOfWeek), \n    data = tmp)\n\nCoefficients:\n          (Intercept)                   Year  as.factor(DayOfWeek)2  \n           -3034.4822                 1.5192                -1.4358  \nas.factor(DayOfWeek)3  as.factor(DayOfWeek)4  as.factor(DayOfWeek)5  \n              -1.3253                 1.1991                 2.8585  \nas.factor(DayOfWeek)6  as.factor(DayOfWeek)7             s(Month).1  \n              -3.4711                -0.6099               -11.5023  \n           s(Month).2             s(Month).3             s(Month).4  \n              29.9072                 7.8150                 3.4659  \n           s(Month).5             s(Month).6             s(Month).7  \n               3.9015                13.5777                -4.5265  \n           s(Month).8             s(Month).9              s(Hour).1  \n             -33.3586                14.2591               -14.9909  \n            s(Hour).2              s(Hour).3              s(Hour).4  \n              26.8251                 7.7860                11.7260  \n            s(Hour).5              s(Hour).6              s(Hour).7  \n              -8.2813                11.2469                 7.4184  \n            s(Hour).8              s(Hour).9  \n              42.5227               -41.9673  \n\nDegrees of Freedom: 12564 Total (i.e. Null);  12540.9 Residual\n  (142 observations deleted due to missingness)\nNull Deviance:      17310000 \nResidual Deviance: 16590000     AIC: 126000\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat do you think are the advantages and disadvantages of having many small tasks vs. a few large tasks?",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#other-plans",
    "href": "units/speed.html#other-plans",
    "title": "Parallelization and Rcpp",
    "section": "Other “plans”",
    "text": "Other “plans”\n\nmultisession: multiple R sessions on a single machine\nmulticore: multiple forked R sessions on a single machine (less copying)\ncluster: multiple R sessions on one or more machines",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#parallelization-and-random-number-generation",
    "href": "units/speed.html#parallelization-and-random-number-generation",
    "title": "Parallelization and Rcpp",
    "section": "Parallelization and Random Number Generation",
    "text": "Parallelization and Random Number Generation\nA tale of the good, the bad, and the ugly\nRandom numbers on a computer are not truly random but are generated as a sequence of pseudo-random numbers. The sequence is finite (but very, very, very, very long) and eventally repeats itself.\nA random number seed determines where in the sequence one starts when generating random numbers.\n\nThe ugly: Make sure you do not use the same seed for each task\n\n\nset.seed(1)\nrnorm(5)\n\n[1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078\n\nset.seed(1)\nrnorm(5)\n\n[1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078\n\n\n\nThe (not so) bad: Use a different seed for each task or each process. It’s possible the subsequences will overlap but quite unlikely.\nThe good: Use the L’Ecuyer algorithm to ensure distinct subsequences in each worker, which future makes easy:\n\nwith future.apply, use future.seed = TRUE.\nwith foreach and %dofuture%, include .options.future = list(seed = TRUE).",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#rcpp-compilation",
    "href": "units/speed.html#rcpp-compilation",
    "title": "Parallelization and Rcpp",
    "section": "Rcpp: compilation",
    "text": "Rcpp: compilation\nBehind the scenes, the first step in using a C++ function is that the C++ code is compiled to machine (binary) code that can be called from R.\nTo use Rcpp, you’ll need a C++ compiler:\n\nfor Windows: install rtools\nfor MacOS: install xcode\n\nHere’s a test that your compiler works from R:\n\nlibrary(\"Rcpp\")\nevalCpp(\"2 + 2\")\n\n[1] 4",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#basic-example",
    "href": "units/speed.html#basic-example",
    "title": "Parallelization and Rcpp",
    "section": "Basic example",
    "text": "Basic example\nHere’s a basic example of using C++ code via Rcpp from the Advanced R book.\n\ncppFunction('int add3(int x, int y, int z) {\n  int sum = x + y + z;\n  return sum;\n}')\n\n## The pause is because the C++ code has to be compiled.\n\nadd3\n\nfunction (x, y, z) \n.Call(&lt;pointer: 0x7cea8877c2a0&gt;, x, y, z)\n\nadd3(1,3,5)\n\n[1] 9\n\n\nNote that some casting/coercing of types must be happening:\n\nadd3(1,2,3)\n\n[1] 6\n\nadd3(1L, 2L, 3L)\n\n[1] 6\n\nadd3(1,2,3.7)\n\n[1] 6\n\n\nNotice we need to include the types of variables, since C++ is statically typed (in large part this is why it is much faster than R).",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#a-short-but-rich-example-loop-fusion",
    "href": "units/speed.html#a-short-but-rich-example-loop-fusion",
    "title": "Parallelization and Rcpp",
    "section": "A short but rich example: loop fusion",
    "text": "A short but rich example: loop fusion\nConsider this vectorized code.\n\nx &lt;- exp(x) + 3 * sin(x)\n\nBecause it’s vectorized, it avoids the R overhead involved in looping, with the individual calculations (exp, +, *, and sin) done in for loops in compiled C code.\nHowever, it has a subtle disadvantage compared to this for loop version:\n\nn &lt;- length(x)\nfor(i in 1:n)\n   x[i] &lt;- exp(x[i]) + 3 * sin(x[i])\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat has to happen in the vectorized code that doesn’t happen in the for loop?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe individual operations are done as separate vectorized calls to compiled C code.\nTemporary vectors must be allocated and filled to carry out exp, sin, * and +.\n\nExtra memory needed.\nTime for allocation and moving values.\n\nThe result x and the input x both need to exist at one time, briefly.\n\n\n\n\nNone of that needs to happen with the loop version.",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#loop-fusion-using-rcpp",
    "href": "units/speed.html#loop-fusion-using-rcpp",
    "title": "Parallelization and Rcpp",
    "section": "Loop fusion using Rcpp",
    "text": "Loop fusion using Rcpp\nWe can write up the for loop version using Rcpp to get the benefits of loop fusion.\n\ncppFunction('void fuse(NumericVector x) {\n  int n = x.size();\n  Rcpp::Rcout &lt;&lt; \"Working with a vector of length \" &lt;&lt; n &lt;&lt; \".\" &lt;&lt; std::endl;\n  for(int i = 0; i &lt; n; ++i) {\n    x[i] = exp(x[i]) + 3 * sin(x[i]);\n  }\n}')\n\nn &lt;- 1e7\nx &lt;- rnorm(n)\ny &lt;- x\n\nrbenchmark::benchmark(\n x &lt;- exp(x) + 3*sin(x),\n fuse(y),\n replications = 1,  # 'x' could explode on repeated calls\n columns = c('test', 'replications', 'elapsed'))\n\nWorking with a vector of length 10000000.\nWorking with a vector of length 10000000.\n\n\n                      test replications elapsed\n2                  fuse(y)            1   0.268\n1 x &lt;- exp(x) + 3 * sin(x)            1   0.346\n\n\nWe could also have created a version that doesn’t overwrite the input.\n\ncppFunction('NumericVector fuse(NumericVector x) {\n  int n = x.size();\n  NumericVector result(n);\n  for(int i = 0; i &lt; n; ++i) {\n    result[i] = exp(x[i]) + 3 * sin(x[i]);\n  }\n  return result;\n}')",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#rcpp-source-code-files",
    "href": "units/speed.html#rcpp-source-code-files",
    "title": "Parallelization and Rcpp",
    "section": "Rcpp source code files",
    "text": "Rcpp source code files\nExcept for quick-and-dirty work, we’d generally want the Rcpp C++ code in a code file that can be recognized by editors as C++ code rather than in quotations in R. This will also help with debugging.\nSee fuse.cpp for the code for the version that does not overwrite the input.\n\nsourceCpp('fuse.cpp')\n\nx &lt;- rnorm(10)\ny &lt;- fuse(x)",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#using-r-classes-in-c",
    "href": "units/speed.html#using-r-classes-in-c",
    "title": "Parallelization and Rcpp",
    "section": "Using R classes in C++",
    "text": "Using R classes in C++\nRcpp provides classes that correspond to most R data structures/classes. We’ve already seen the use of NumericVector for R’s numeric vector.\nHere’s an example (from the Advanced R book) of working with a list (an S3 object) and manipulating its components in C++. We need to cast the vector components as NumericVectors\n#include &lt;Rcpp.h&gt;\nusing namespace Rcpp;\n\n// [[Rcpp::export]]\ndouble mpe(List mod) {\n  if (!mod.inherits(\"lm\")) stop(\"Input must be a linear model\");\n\n  NumericVector resid = as&lt;NumericVector&gt;(mod[\"residuals\"]);\n  NumericVector fitted = as&lt;NumericVector&gt;(mod[\"fitted.values\"]);\n\n  int n = resid.size();\n  double err = 0;\n  for(int i = 0; i &lt; n; ++i) {\n    err += resid[i] / (fitted[i] + resid[i]);\n  }\n  return err / n;\n}",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "units/speed.html#rcpp-sugar",
    "href": "units/speed.html#rcpp-sugar",
    "title": "Parallelization and Rcpp",
    "section": "Rcpp “sugar”",
    "text": "Rcpp “sugar”\nRcpp Sugar provides additional functionality to make it easier to write C++ code in an R-like way.\nThis includes:\n\nCalling functions from R’s C math library, e.g., Rcpp::rnorm(10, 3, 0.5)\nVarious functions that mimic standard R functions (e.g., all, is_na)\nUsing R’s random number generation\nVectorized calls (for code clarity, not for speed!)",
    "crumbs": [
      "Modules",
      "Parallelization/Rcpp"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Overview",
    "section": "",
    "text": "The workshop will focus on skills related to computation, code development, and statistics/data science workflows, including,\n\nopen science workflows and literate programming;\nintroduction to version control, Git and GitHub;\ncode style;\ndebugging;\ntesting;\ncollaboration with Git and GitHub;\nnumerical analysis (random number generation and floating point precision);\npackaging and reproducible environments; and\nautomated workflows.\n\n\n\n\nGoal 1: Emphasize good computational and code development practices (scripting, version control, testing, modularity, defensive programming, documentation, commenting, numerical analysis issues).\nGoal 2: Emphasize good practices for workflows, including reproducibility, automation, isolated environments.\nGoal 3: Provide practice with and introduce key tools for version control, testing, documentation, literate programming (documents with runnable code)."
  },
  {
    "objectID": "syllabus.html#about-the-computational-skills-workshop",
    "href": "syllabus.html#about-the-computational-skills-workshop",
    "title": "Overview",
    "section": "",
    "text": "The workshop will focus on skills related to computation, code development, and statistics/data science workflows, including,\n\nopen science workflows and literate programming;\nintroduction to version control, Git and GitHub;\ncode style;\ndebugging;\ntesting;\ncollaboration with Git and GitHub;\nnumerical analysis (random number generation and floating point precision);\npackaging and reproducible environments; and\nautomated workflows.\n\n\n\n\nGoal 1: Emphasize good computational and code development practices (scripting, version control, testing, modularity, defensive programming, documentation, commenting, numerical analysis issues).\nGoal 2: Emphasize good practices for workflows, including reproducibility, automation, isolated environments.\nGoal 3: Provide practice with and introduce key tools for version control, testing, documentation, literate programming (documents with runnable code)."
  },
  {
    "objectID": "syllabus.html#optional-introduction-to-computing-and-python",
    "href": "syllabus.html#optional-introduction-to-computing-and-python",
    "title": "Overview",
    "section": "(Optional) Introduction to Computing and Python",
    "text": "(Optional) Introduction to Computing and Python\nThe optional additional sessions (held Tuesday-Wednesday, August 20-21) provide a basic introduction to computing concepts (e.g., parts of a computer, ideas related to parallelization, introduction to the the shell/command line/terminal) and an introduction to Python.\nThese are intended for those with little experience (or wishing a refresher) with working in a command line context or with using Python, and are particularly important for those taking Statistics 243, which assumes basic knowledge of Python.\nThe introduction to Python will borrow heavily from this Software Carpentry Python lesson, with some additional topics added."
  }
]