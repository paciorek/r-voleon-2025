[
  {
    "objectID": "units/tidyverse.html",
    "href": "units/tidyverse.html",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "",
    "text": "A lot of analysis time in many cases is spent on manipulating tabular data. The tidyverse provides a nice suite of packages for doing this.\nThe tidyverse is a suite of packages designed specifically to help with both these steps; some of which we will be introducing in this module. These are by no means the only packages out there for data wrangling but they are popular for their readable, straightforward syntax and sensible default behaviors.\nAn alternative for working quickly with very large datasets is the data.table package. It’s fast and a good choice. While the core syntax is not as nice, one can also use dplyr syntax with data.table objects.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#selecting-columns-dplyrselect",
    "href": "units/tidyverse.html#selecting-columns-dplyrselect",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Selecting columns: dplyr::select",
    "text": "Selecting columns: dplyr::select\nImagine that we just received the gapminder dataset, but are only interested in a few variables in it. The select() function can help us to keep only the columns corresponding to variables we select.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nyear_country_gdp_dplyr &lt;- select(gapminder, year, country, gdpPercap)\nhead(year_country_gdp_dplyr)\n\n# A tibble: 6 × 3\n   year country     gdpPercap\n  &lt;int&gt; &lt;fct&gt;           &lt;dbl&gt;\n1  1952 Afghanistan      779.\n2  1957 Afghanistan      821.\n3  1962 Afghanistan      853.\n4  1967 Afghanistan      836.\n5  1972 Afghanistan      740.\n6  1977 Afghanistan      786.\n\n\n\nWe see the new dataframe only contains the year, country and gdpPercap. This is equivalent to the base R subsetting operator:\n\nyear_country_gdp_base &lt;- gapminder[ , c(\"year\", \"country\", \"gdpPercap\")]\nhead(year_country_gdp_base)\n\n# A tibble: 6 × 3\n   year country     gdpPercap\n  &lt;int&gt; &lt;fct&gt;           &lt;dbl&gt;\n1  1952 Afghanistan      779.\n2  1957 Afghanistan      821.\n3  1962 Afghanistan      853.\n4  1967 Afghanistan      836.\n5  1972 Afghanistan      740.\n6  1977 Afghanistan      786.\n\n\nBut, as we will see, dplyr makes for much more readable, efficient code because of its pipe operator.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#piping-with-dplyr",
    "href": "units/tidyverse.html#piping-with-dplyr",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Piping with dplyr",
    "text": "Piping with dplyr\nAbove, we used what’s called “normal” grammar, but the strengths of dplyr lie in combining several functions using pipes.\nIn typical base R code, a simple operation might be written like:\n\n# NOT run\ncupcakes &lt;- bake(pour(mix(ingredients)))\n\nA computer has no trouble understanding this and your cupcakes will be made just fine but a person has to read right to left to understand the order of operations - the opposite of how most western languages are read - making it harder to understand what is being done!\nTo be more readable without pipes, we might break up this code into intermediate objects…\n\n# NOT run\nbatter &lt;- mix(ingredients)\nmuffin_tin &lt;- pour(batter)\ncupcakes &lt;- bake(muffin_tin)\n\nbut this can clutter our environment with a lot of variables that aren’t very useful to us, and often are named very similar things (e.g. step, step1, step2…) which can lead to confusion and bugs.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#enter-the-pipe",
    "href": "units/tidyverse.html#enter-the-pipe",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Enter the pipe…",
    "text": "Enter the pipe…\nThe pipe makes it easier to read code because it lays out the operations left to right so each line can be read like a line of a recipe for the perfect data frame!\nPipes take the input on the left side of the |&gt; symbol and pass it in as the first argument to the function on the right side.\nWith pipes, our cupcake example might be written like:\n\ncupcakes &lt;- ingredients |&gt; \n  mix() |&gt; \n  pour() |&gt; \n  bake()",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#pipe-example",
    "href": "units/tidyverse.html#pipe-example",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Pipe example",
    "text": "Pipe example\nLet’s repeat what we did above with the gapminder dataset using pipes:\n\nyear_country_gdp &lt;- gapminder |&gt; select(year, country, gdpPercap)\n\nFirst, we summon the gapminder data frame and pass it on to the next step using the pipe symbol |&gt;. The second step is the select() function. In this case we don’t specify which data object we use in the call to select() since we’ve piped it in.\nNote that lack of quotations around the column names. This is called “non-standard evaluation” and is used a lot in the tidyverse (including in ggplot).",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#filtering-rows-dplyrfilter",
    "href": "units/tidyverse.html#filtering-rows-dplyrfilter",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Filtering rows: dplyr::filter",
    "text": "Filtering rows: dplyr::filter\nNow let’s say we’re only interested in African countries. We can combine select and filter to select only the observations where continent is Africa.\n\nyear_country_gdp_africa &lt;- gapminder |&gt;\n    filter(continent == \"Africa\") |&gt;\n    select(year,country,gdpPercap)\n\nAs with last time, first we pass the gapminder data frame to the filter() function, then we pass the filtered version of the gapminder data frame to the select() function.\nNote: The order of operations is important in this case. If we used ‘select’ first, filter would not be able to find the variable continent since we would have removed it in the previous step.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#dplyr-calculations-across-groups-split-apply-combine",
    "href": "units/tidyverse.html#dplyr-calculations-across-groups-split-apply-combine",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "dplyr calculations across groups: split-apply-combine",
    "text": "dplyr calculations across groups: split-apply-combine\nA common task you’ll encounter when working with data is running calculations on different groups within the data. For instance, what if we wanted to calculate the mean GDP per capita for each continent?\nThis general task is known as “split-apply-combine”:\n\nWe want to split our data into groups (in this case continents), apply some calculations on each group, then combine the results together afterwards.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#stratifying-dplyrgroup_by",
    "href": "units/tidyverse.html#stratifying-dplyrgroup_by",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Stratifying: dplyr::group_by",
    "text": "Stratifying: dplyr::group_by\nWe’ve already seen how filter() can help us select observations that meet certain criteria (in the above: continent == \"Europe\"). More helpful, however, is the group_by() function, which will essentially use every unique criteria that we could have used in filter().\nA grouped_df can be thought of as a list where each item in the list is a data.frame which contains only the rows that correspond to a particular value of one or more grouping variables (continent in our example).",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#reduction-operations-dplyrsummarize",
    "href": "units/tidyverse.html#reduction-operations-dplyrsummarize",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Reduction operations: dplyr::summarize",
    "text": "Reduction operations: dplyr::summarize\ngroup_by() on its own is not particularly interesting; instead it’s generally used with summarize().\nThis will allow use to create new variable(s) by applying transformations to variables in each of the continent-specific data frames.\nIn other words, using the group_by() function, we split our original data frame into multiple pieces, which we then apply summary functions to (e.g., mean() or sd()) within summarize(). The output is a new data frame reduced in size, with one row per group.\n\ngdp_bycontinents &lt;- gapminder |&gt;\n    group_by(continent) |&gt;\n    summarize(mean_gdpPercap = mean(gdpPercap))\nhead(gdp_bycontinents)\n\n# A tibble: 5 × 2\n  continent mean_gdpPercap\n  &lt;fct&gt;              &lt;dbl&gt;\n1 Africa             2194.\n2 Americas           7136.\n3 Asia               7902.\n4 Europe            14469.\n5 Oceania           18622.\n\n\n\nThat allowed us to calculate the mean gdpPercap for each continent. But it gets even better – the function group_by() allows us to group by multiple variables. Let’s group by year and continent.\n\ngdp_bycontinents_byyear &lt;- gapminder |&gt;\n    group_by(continent, year) |&gt;\n    summarize(mean_gdpPercap = mean(gdpPercap))\n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\nhead(gdp_bycontinents_byyear)\n\n# A tibble: 6 × 3\n# Groups:   continent [1]\n  continent  year mean_gdpPercap\n  &lt;fct&gt;     &lt;int&gt;          &lt;dbl&gt;\n1 Africa     1952          1253.\n2 Africa     1957          1385.\n3 Africa     1962          1598.\n4 Africa     1967          2050.\n5 Africa     1972          2340.\n6 Africa     1977          2586.\n\n\nYou’re not limited to defining one new variable in summarize().\n\ngdp_pop_bycontinents_byyear &lt;- gapminder |&gt;\n    group_by(continent, year) |&gt;\n    summarize(mean_gdpPercap = mean(gdpPercap),\n              sd_gdpPercap = sd(gdpPercap),\n              mean_pop = mean(pop),\n              sd_pop = sd(pop))\n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\nhead(gdp_pop_bycontinents_byyear)\n\n# A tibble: 6 × 6\n# Groups:   continent [1]\n  continent  year mean_gdpPercap sd_gdpPercap mean_pop    sd_pop\n  &lt;fct&gt;     &lt;int&gt;          &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Africa     1952          1253.         983. 4570010.  6317450.\n2 Africa     1957          1385.        1135. 5093033.  7076042.\n3 Africa     1962          1598.        1462. 5702247.  7957545.\n4 Africa     1967          2050.        2848. 6447875.  8985505.\n5 Africa     1972          2340.        3287. 7305376. 10130833.\n6 Africa     1977          2586.        4142. 8328097. 11585184.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#adding-columns-dplyrmutate",
    "href": "units/tidyverse.html#adding-columns-dplyrmutate",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Adding columns: dplyr::mutate",
    "text": "Adding columns: dplyr::mutate\nWhat if we wanted to add these values to our original data frame instead of creating a new object? For this, we can use the mutate() function, which is similar to summarize() except it creates new variables in the same data frame that you pass into it.\n\ngap_with_extra_vars &lt;- gapminder |&gt;\n    group_by(continent, year) |&gt;\n    mutate(mean_gdpPercap = mean(gdpPercap),\n              sd_gdpPercap = sd(gdpPercap),\n              mean_pop = mean(pop),\n              sd_pop = sd(pop))\nhead(gap_with_extra_vars)\n\n# A tibble: 6 × 10\n# Groups:   continent, year [6]\n  country   continent  year lifeExp    pop gdpPercap mean_gdpPercap sd_gdpPercap\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;     &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1 Afghanis… Asia       1952    28.8 8.43e6      779.          5195.       18635.\n2 Afghanis… Asia       1957    30.3 9.24e6      821.          5788.       19507.\n3 Afghanis… Asia       1962    32.0 1.03e7      853.          5729.       16416.\n4 Afghanis… Asia       1967    34.0 1.15e7      836.          5971.       14063.\n5 Afghanis… Asia       1972    36.1 1.31e7      740.          8187.       19088.\n6 Afghanis… Asia       1977    38.4 1.49e7      786.          7791.       11816.\n# ℹ 2 more variables: mean_pop &lt;dbl&gt;, sd_pop &lt;dbl&gt;\n\n\nWe can use also use mutate() to create new variables prior to (or even after) summarizing information. Note that mutate() does not need to operate on grouped data and it can do element-wise transformations.\n\ngdp_pop_bycontinents_byyear &lt;- gapminder |&gt;\n    mutate(gdp_billion = gdpPercap*pop/10^9) |&gt;\n    group_by(continent, year) |&gt;\n    summarize(mean_gdpPercap = mean(gdpPercap),\n              sd_gdpPercap = sd(gdpPercap),\n              mean_pop = mean(pop),\n              sd_pop = sd(pop),\n              mean_gdp_billion = mean(gdp_billion),\n              sd_gdp_billion = sd(gdp_billion))\n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\nhead(gdp_pop_bycontinents_byyear)\n\n# A tibble: 6 × 8\n# Groups:   continent [1]\n  continent  year mean_gdpPercap sd_gdpPercap mean_pop   sd_pop mean_gdp_billion\n  &lt;fct&gt;     &lt;int&gt;          &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;\n1 Africa     1952          1253.         983. 4570010.   6.32e6             5.99\n2 Africa     1957          1385.        1135. 5093033.   7.08e6             7.36\n3 Africa     1962          1598.        1462. 5702247.   7.96e6             8.78\n4 Africa     1967          2050.        2848. 6447875.   8.99e6            11.4 \n5 Africa     1972          2340.        3287. 7305376.   1.01e7            15.1 \n6 Africa     1977          2586.        4142. 8328097.   1.16e7            18.7 \n# ℹ 1 more variable: sd_gdp_billion &lt;dbl&gt;",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#mutate-vs.-summarize",
    "href": "units/tidyverse.html#mutate-vs.-summarize",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "mutate vs. summarize",
    "text": "mutate vs. summarize\nIt can be confusing to decide whether to use mutate or summarize. The key distinction is whether you want the output to have one row for each group or one row for each row in the original data frame:\n\nmutate: creates new columns with as many rows as the original data frame\nsummarize: creates a data frame with as many rows as groups\n\nNote that if you use an aggregation function such as mean() within mutate() without using groupby(), you’ll simply do the summary over all the rows of the input data frame.\nAnd if you use an aggregation function such as mean() within summarize() without using groupby(), you’ll simply create an output data frame with one row (i.e., the whole input data frame is a single group).",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#sorting-dplyrarrange",
    "href": "units/tidyverse.html#sorting-dplyrarrange",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Sorting: dplyr::arrange",
    "text": "Sorting: dplyr::arrange\nAs a last step, let’s say we want to sort the rows in our data frame according to values in a certain column. We can use the arrange() function to do this. For instance, let’s organize our rows by year (recent first), and then by continent.\n\ngap_with_extra_vars &lt;- gapminder |&gt;\n    group_by(continent, year) |&gt;\n    mutate(mean_gdpPercap = mean(gdpPercap),\n              sd_gdpPercap = sd(gdpPercap),\n              mean_pop = mean(pop),\n              sd_pop = sd(pop)) |&gt;\n    arrange(desc(year), continent) # `desc()` = descending order\nhead(gap_with_extra_vars)\n\n# A tibble: 6 × 10\n# Groups:   continent, year [1]\n  country   continent  year lifeExp    pop gdpPercap mean_gdpPercap sd_gdpPercap\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;     &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1 Algeria   Africa     2007    72.3 3.33e7     6223.          3089.        3618.\n2 Angola    Africa     2007    42.7 1.24e7     4797.          3089.        3618.\n3 Benin     Africa     2007    56.7 8.08e6     1441.          3089.        3618.\n4 Botswana  Africa     2007    50.7 1.64e6    12570.          3089.        3618.\n5 Burkina … Africa     2007    52.3 1.43e7     1217.          3089.        3618.\n6 Burundi   Africa     2007    49.6 8.39e6      430.          3089.        3618.\n# ℹ 2 more variables: mean_pop &lt;dbl&gt;, sd_pop &lt;dbl&gt;",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#dplyr-take-aways",
    "href": "units/tidyverse.html#dplyr-take-aways",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "dplyr take-aways",
    "text": "dplyr take-aways\n\nHuman readable: the function names describe the action being done\nPiping: chain functions in a step-by-step way, rather than nesting",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#dplyr-and-non-standard-evaluation",
    "href": "units/tidyverse.html#dplyr-and-non-standard-evaluation",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "dplyr and “non-standard evaluation”",
    "text": "dplyr and “non-standard evaluation”\nYou may run across the term “non-standard evaluation”. The use of data frame variables without quotes around them is an example of this.\nWhy is this strange?\n\ngapminder |&gt; select(continent, year) |&gt; tail()\n\nCompare it to:\n\ngapminder[ , c('continent', 'year')]\ngapminder[ , 'continent']\n\nBecause continent and year are not variables our current environment! dplyr does some manipulation of language objects behind the scenes to save us from typing the quotes.\nThis is fine if you have a data analysis workflow but if you want to write a function that, for example, selects an arbitrary set of columns, you’ll run into trouble.\n\n## here's a helper function that computes the mean of a variable, stratifying by a grouping variable\ngrouped_mean &lt;- function(data, group_var, summary_var) {\n  data |&gt;\n    group_by(group_var) |&gt;\n    summarise(mean = mean(summary_var))\n}\ngapminder |&gt; grouped_mean(continent, lifeExp)\ngapminder |&gt; grouped_mean('continent', 'lifeExp')\n\nSee the rlang (or wrapr) package for how one can deal with this problem in this context of using functions.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#wide-vs.-long-formats",
    "href": "units/tidyverse.html#wide-vs.-long-formats",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Wide vs. long formats",
    "text": "Wide vs. long formats\nTabular datasets can be arranged in many ways. For instance, consider the data below. Each data set displays information on heart rate observed in individuals across 3 different time periods. But the data are organized differently in each table.\n\nwide &lt;- data.frame(\n  name = c(\"Wilbur\", \"Petunia\", \"Gregory\"),\n  time1 = c(67, 80, 64),\n  time2 = c(56, 90, 50),\n  time3 = c(70, 67, 101)\n)\nwide\n\n     name time1 time2 time3\n1  Wilbur    67    56    70\n2 Petunia    80    90    67\n3 Gregory    64    50   101\n\nlong &lt;- data.frame(\n  name = c(\"Wilbur\", \"Petunia\", \"Gregory\", \"Wilbur\", \"Petunia\", \"Gregory\", \"Wilbur\", \"Petunia\", \"Gregory\"),\n  time = c(1, 1, 1, 2, 2, 2, 3, 3, 3),\n  heartrate = c(67, 80, 64, 56, 90, 50, 70, 67, 10)\n)\nlong\n\n     name time heartrate\n1  Wilbur    1        67\n2 Petunia    1        80\n3 Gregory    1        64\n4  Wilbur    2        56\n5 Petunia    2        90\n6 Gregory    2        50\n7  Wilbur    3        70\n8 Petunia    3        67\n9 Gregory    3        10\n\n\nWe often refer to these different structures as “long” vs. “wide” formats. In the “long” format, you usually have 1 column for the observed variable and the other columns are ID variables.\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of the ‘wide’ and ‘long’ objects do you prefer in terms of how the heartrate ‘data’ are formatted?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe first data frame (the “wide” one) would not be considered tidy because values (i.e., heartrate) are spread across multiple columns.\n\n\n\nFor the “wide” format each row is often a site/subject/patient and you have multiple observation variables containing the same type of data. These can be either repeated observations over time, or observation of multiple variables (or a mix of both). In the above case, we had the same kind of data (heart rate) entered across 3 different columns, corresponding to three different time periods.\n\nYou may find data input may be simpler and some programs/functions may prefer the “wide” format. However, many of R’s functions (particularly in the tidyverse) have been designed assuming you have “long” format data.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#tidying-the-gapminder-data",
    "href": "units/tidyverse.html#tidying-the-gapminder-data",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Tidying the Gapminder data",
    "text": "Tidying the Gapminder data\nLets look at the structure of our original gapminder data frame:\n\nhead(gapminder)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\n\nQuestion: Is this data frame wide or long?\nAnswer: This data frame is somewhere in between the purely ‘long’ and ‘wide’ formats. We have 3 “ID variables” (continent, country, year) and 3 “Observation variables” (pop, lifeExp, gdpPercap).\nDespite not having ALL observations in 1 column, this intermediate format makes sense given that all 3 observation variables have different units. As we have seen, many of the functions in R are often vector based, and you usually do not want to do mathematical operations on values with different units.\nOn the other hand, there are some instances in which a purely long or wide format is ideal (e.g. plotting). Likewise, sometimes you’ll get data on your desk that is poorly organized, and you’ll need to reshape it.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#converting-to-long-format-tidyrpivot_longer",
    "href": "units/tidyverse.html#converting-to-long-format-tidyrpivot_longer",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Converting to long format: tidyr::pivot_longer",
    "text": "Converting to long format: tidyr::pivot_longer\nThe tidyr package will help you efficiently transform your data regardless of original format.\nUntil now, we’ve been using the nicely formatted original gapminder data set. This data set is not quite wide and not quite long – it’s something in the middle, but “real” data (i.e., our own research data) will never be so well organized. Here let’s start with the wide format version of the gapminder data set.\n\ngap_wide &lt;- read.csv(file.path(\"..\", \"data\", \"gapminder_wide.csv\"))\nhead(gap_wide)\n\n  continent      country gdpPercap_1952 gdpPercap_1957 gdpPercap_1962\n1    Africa      Algeria      2449.0082      3013.9760      2550.8169\n2    Africa       Angola      3520.6103      3827.9405      4269.2767\n3    Africa        Benin      1062.7522       959.6011       949.4991\n4    Africa     Botswana       851.2411       918.2325       983.6540\n5    Africa Burkina Faso       543.2552       617.1835       722.5120\n6    Africa      Burundi       339.2965       379.5646       355.2032\n  gdpPercap_1967 gdpPercap_1972 gdpPercap_1977 gdpPercap_1982 gdpPercap_1987\n1      3246.9918      4182.6638      4910.4168      5745.1602      5681.3585\n2      5522.7764      5473.2880      3008.6474      2756.9537      2430.2083\n3      1035.8314      1085.7969      1029.1613      1277.8976      1225.8560\n4      1214.7093      2263.6111      3214.8578      4551.1421      6205.8839\n5       794.8266       854.7360       743.3870       807.1986       912.0631\n6       412.9775       464.0995       556.1033       559.6032       621.8188\n  gdpPercap_1992 gdpPercap_1997 gdpPercap_2002 gdpPercap_2007 lifeExp_1952\n1      5023.2166      4797.2951      5288.0404      6223.3675       43.077\n2      2627.8457      2277.1409      2773.2873      4797.2313       30.015\n3      1191.2077      1232.9753      1372.8779      1441.2849       38.223\n4      7954.1116      8647.1423     11003.6051     12569.8518       47.622\n5       931.7528       946.2950      1037.6452      1217.0330       31.975\n6       631.6999       463.1151       446.4035       430.0707       39.031\n  lifeExp_1957 lifeExp_1962 lifeExp_1967 lifeExp_1972 lifeExp_1977 lifeExp_1982\n1       45.685       48.303       51.407       54.518       58.014       61.368\n2       31.999       34.000       35.985       37.928       39.483       39.942\n3       40.358       42.618       44.885       47.014       49.190       50.904\n4       49.618       51.520       53.298       56.024       59.319       61.484\n5       34.906       37.814       40.697       43.591       46.137       48.122\n6       40.533       42.045       43.548       44.057       45.910       47.471\n  lifeExp_1987 lifeExp_1992 lifeExp_1997 lifeExp_2002 lifeExp_2007 pop_1952\n1       65.799       67.744       69.152       70.994       72.301  9279525\n2       39.906       40.647       40.963       41.003       42.731  4232095\n3       52.337       53.919       54.777       54.406       56.728  1738315\n4       63.622       62.745       52.556       46.634       50.728   442308\n5       49.557       50.260       50.324       50.650       52.295  4469979\n6       48.211       44.736       45.326       47.360       49.580  2445618\n  pop_1957 pop_1962 pop_1967 pop_1972 pop_1977 pop_1982 pop_1987 pop_1992\n1 10270856 11000948 12760499 14760787 17152804 20033753 23254956 26298373\n2  4561361  4826015  5247469  5894858  6162675  7016384  7874230  8735988\n3  1925173  2151895  2427334  2761407  3168267  3641603  4243788  4981671\n4   474639   512764   553541   619351   781472   970347  1151184  1342614\n5  4713416  4919632  5127935  5433886  5889574  6634596  7586551  8878303\n6  2667518  2961915  3330989  3529983  3834415  4580410  5126023  5809236\n  pop_1997 pop_2002 pop_2007\n1 29072015 31287142 33333216\n2  9875024 10866106 12420476\n3  6066080  7026113  8078314\n4  1536536  1630347  1639131\n5 10352843 12251209 14326203\n6  6121610  7021078  8390505\n\n\nThe first step towards getting our nice intermediate data format is to first convert from the wide to the long format. The function pivot_longer() will ‘gather’ the observation variables into a single variable. This is sometimes called “melting” your data, because it melts the table from wide to long. Those data will be melted into two variables: one for the variable names, and the other for the variable values.\n\nlibrary(tidyr)\ngap_long &lt;- gap_wide |&gt; pivot_longer(gdpPercap_1952:pop_2007)\nhead(gap_long)\n\n# A tibble: 6 × 4\n  continent country name           value\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 Africa    Algeria gdpPercap_1952 2449.\n2 Africa    Algeria gdpPercap_1957 3014.\n3 Africa    Algeria gdpPercap_1962 2551.\n4 Africa    Algeria gdpPercap_1967 3247.\n5 Africa    Algeria gdpPercap_1972 4183.\n6 Africa    Algeria gdpPercap_1977 4910.\n\n\nFormerly one used the function gather to do this, but many people found it not to be intuitive to use.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#specifying-column-names-tidyrselect",
    "href": "units/tidyverse.html#specifying-column-names-tidyrselect",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Specifying column names: tidyr::select",
    "text": "Specifying column names: tidyr::select\nIf there are a lot of columns or they’re named in a consistent pattern, we might not want to select them using the column numbers. It’d be easier to use some information contained in the names themselves. We can select variables using:\n\nvariable indices\nvariable names (without quotes)\nx:z to select all variables between x and z\n-y to exclude y\nstarts_with(x, ignore.case = TRUE): all names that starts with x\nends_with(x, ignore.case = TRUE): all names that ends with x\ncontains(x, ignore.case = TRUE): all names that contain x\n\nSee the select() function in dplyr for more options.\nFor instance, here we do the same gather operation with (1) the starts_with function, and (2) the - operator:\n\n# with the starts_with() function\ngap_long &lt;- gap_wide |&gt;\n    pivot_longer(c(starts_with('pop'), starts_with('lifeExp'), starts_with('gdpPercap')))\nhead(gap_long)\n\n# A tibble: 6 × 4\n  continent country name        value\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;\n1 Africa    Algeria pop_1952  9279525\n2 Africa    Algeria pop_1957 10270856\n3 Africa    Algeria pop_1962 11000948\n4 Africa    Algeria pop_1967 12760499\n5 Africa    Algeria pop_1972 14760787\n6 Africa    Algeria pop_1977 17152804\n\n# with the - operator\ngap_long &lt;- gap_wide |&gt;\n  pivot_longer(c(-continent, -country))\nhead(gap_long)\n\n# A tibble: 6 × 4\n  continent country name           value\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 Africa    Algeria gdpPercap_1952 2449.\n2 Africa    Algeria gdpPercap_1957 3014.\n3 Africa    Algeria gdpPercap_1962 2551.\n4 Africa    Algeria gdpPercap_1967 3247.\n5 Africa    Algeria gdpPercap_1972 4183.\n6 Africa    Algeria gdpPercap_1977 4910.\n\n\nHowever you choose to do it, notice that the output collapses all of the measure variables into two columns: one containing new ID variable, the other containing the observation value for that row.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#cleaning-column-names-tidyrseparate",
    "href": "units/tidyverse.html#cleaning-column-names-tidyrseparate",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Cleaning column names: tidyr::separate",
    "text": "Cleaning column names: tidyr::separate\nYou’ll notice that in our long dataset, name actually contains 2 pieces of information, the observation type (pop, lifeExp, or gdpPercap) and the year.\nWe can use the separate() function to split the character strings into multiple variables:\n\ngap_long_sep &lt;- gap_long |&gt;\n  separate(name, into = c('obs_type','year'), sep = \"_\") |&gt;\n  mutate(year = as.integer(year))\nhead(gap_long_sep)\n\n# A tibble: 6 × 5\n  continent country obs_type   year value\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt;\n1 Africa    Algeria gdpPercap  1952 2449.\n2 Africa    Algeria gdpPercap  1957 3014.\n3 Africa    Algeria gdpPercap  1962 2551.\n4 Africa    Algeria gdpPercap  1967 3247.\n5 Africa    Algeria gdpPercap  1972 4183.\n6 Africa    Algeria gdpPercap  1977 4910.\n\n\nIf you didn’t use tidyr to do this, you’d have to use the strsplit function and use multiple lines of code to replace the column in gap_long with two new columns. This solution is much cleaner.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#converting-to-wide-format-tidyrpivot_wider",
    "href": "units/tidyverse.html#converting-to-wide-format-tidyrpivot_wider",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Converting to wide format: tidyr::pivot_wider",
    "text": "Converting to wide format: tidyr::pivot_wider\nThe opposite of pivot_longer() is pivot_wider(). It spreads our observation variables back out to make a wider table. We can use this function to spread our gap_long() to the original “medium” format.\n\ngap_medium &lt;- gap_long_sep |&gt;\n  pivot_wider(names_from = obs_type, values_from = value)\nhead(gap_medium)\n\n# A tibble: 6 × 6\n  continent country  year gdpPercap lifeExp      pop\n  &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 Africa    Algeria  1952     2449.    43.1  9279525\n2 Africa    Algeria  1957     3014.    45.7 10270856\n3 Africa    Algeria  1962     2551.    48.3 11000948\n4 Africa    Algeria  1967     3247.    51.4 12760499\n5 Africa    Algeria  1972     4183.    54.5 14760787\n6 Africa    Algeria  1977     4910.    58.0 17152804\n\n\nFormerly one used the function spread to do this, but many people found it not to be intuitive to use.\nAll we need is some quick fixes to make this dataset identical to the original gapminder dataset:\n\nhead(gapminder)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\n# rearrange columns\ngap_medium &lt;- gap_medium[,names(gapminder)]\nhead(gap_medium)\n\n# A tibble: 6 × 6\n  country continent  year lifeExp      pop gdpPercap\n  &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Algeria Africa     1952    43.1  9279525     2449.\n2 Algeria Africa     1957    45.7 10270856     3014.\n3 Algeria Africa     1962    48.3 11000948     2551.\n4 Algeria Africa     1967    51.4 12760499     3247.\n5 Algeria Africa     1972    54.5 14760787     4183.\n6 Algeria Africa     1977    58.0 17152804     4910.\n\n# arrange by country, continent, and year\ngap_medium &lt;- gap_medium |&gt;\n  arrange(country, continent, year)\nhead(gap_medium)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;chr&gt;       &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#extra-resources",
    "href": "units/tidyverse.html#extra-resources",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Extra Resources",
    "text": "Extra Resources\ndplyr and tidyr have many more functions to help you wrangle and manipulate your data. See the Data Wrangling Cheat Sheet for more.\nHere are some additional functions/verbs for use with dplyr:\nThere are some other useful packages in the tidyverse:\n\nggplot2 for plotting (We’ll cover this in Unit 5)\nreadr and haven for reading in data\npurrr for working with lists and operations similar to the lapply family introduced in Module 4.\nstringr, lubridate, forcats for manipulating strings, dates, and factors, respectively\nmany many more! Take a peak at the tidyverse github page…",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#data.table-syntax",
    "href": "units/tidyverse.html#data.table-syntax",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "data.table syntax",
    "text": "data.table syntax\nHere’s some syntax examples:\n\n# Filter rows:\nair[Dest == \"BOS\" & DepDelay &gt; 100]\n# Select columns:\nair[ , c(\"Dest\", \"DepDelay\")]\n# Mutate (create new columns):\nair[ , DepDelayHr := DepDelay / 60]\n# Summarize\nair[ , .(meanDelayByDest = mean(DepDelay, na.rm = TRUE)), by = Dest]\n# Chaining operations (ugly!):\nair[ , DepDelayHr := DepDelay / 60][ , .(meanDelayByDest = mean(DepDelayHr, na.rm = TRUE)), by = Dest]\n# Join:\nair[another_dt, on = \"keycolumn\"]\n# Sort:\nair[order(Dest, -DepDelay)]\n\nAn important area for efficiency is to use an index, which can improve lookup speed dramatically. For this small dataset, everyting is fast already, so it’s not a good example.\n\nair &lt;- fread(file.path('..', 'data', 'airline.csv'))\n## Subset without an index\nsystem.time(sub &lt;- air[Dest == \"BOS\"])  \n\n   user  system elapsed \n  0.024   0.000   0.013 \n\n## Now set index and subset\nsystem.time(setindex(air, Dest))\n\n   user  system elapsed \n  0.010   0.000   0.003 \n\nsystem.time(sub2 &lt;- air[Dest == \"BOS\"]) # essentially instantaneous\n\n   user  system elapsed \n  0.003   0.000   0.003 \n\n\ndata.table has a lot of functionality and can be used to do a variety of sophisticated queries and manipulations (including aggregation operations), but it has its own somewhat involved syntax and concepts. The above just scratches the surface of what you can do with it.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#using-dplyr-syntax-with-data.table",
    "href": "units/tidyverse.html#using-dplyr-syntax-with-data.table",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Using dplyr syntax with data.table",
    "text": "Using dplyr syntax with data.table\nRather than learning the data.table syntax, one can also use dplyr syntax with data.table objects.\nWe can use dplyr syntax directly with data table objects, but the efficiency may not be what you want.\n\nair &lt;- fread(file.path('..', 'data', 'airline.csv'))\n\nsystem.time(result &lt;- air[ , .(meanDelayByDest = mean(DepDelay, na.rm = TRUE)), by = Dest])  # 0.008 sec.\n\n   user  system elapsed \n  0.032   0.000   0.010 \n\nsystem.time(result &lt;- air |&gt; group_by(Dest) |&gt; summarize(meanDepDelay = mean(DepDelay)))   # 0.019 sec.\n\n   user  system elapsed \n  0.013   0.000   0.013 \n\n\nInstead, one can also use dtplyr to set use a data table as a back end for dplyr manipulations. Using lazy_dt allows dtplyr to do some optimization as it generates the translation from dplyr syntax to data table syntax, though this simple example doesn’t illustrate the usefulness of that (and using system.time for fine differentiation of timing is not generally a good idea).\n\nlibrary(dtplyr)\nlazy_air &lt;- lazy_dt(air)\nsystem.time(result &lt;- lazy_air |&gt; group_by(Dest) |&gt; summarize(meanDepDelay = mean(DepDelay))) # 0.007\n\n   user  system elapsed \n  0.005   0.000   0.005 \n\n\nFinally the tidytable package (not shown) also allows you to use dplyr syntax as well as other tidyverse syntax, such as tidyr functions.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/tidyverse.html#working-with-data-on-disk",
    "href": "units/tidyverse.html#working-with-data-on-disk",
    "title": "Data Wrangling (Tidyverse and data.table)",
    "section": "Working with data on disk",
    "text": "Working with data on disk\nIn some cases you may not have enough memory to use tools that bring all the data into memory in R.\nSome alternatives include:\n\nDuckDB (or SQLite) databases, accessed from R\nUsing Apache Arrow via the arrow package\n\nOr you may need to move to another language, such as using Dask in Python, or database/data lake functionality provided by clould providers.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "units/calculation.html",
    "href": "units/calculation.html",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "At the core of R is the idea of doing calculations on entire vectors.\n\n## Vectorized arithmetic\ngdpTotal &lt;- gapminder$gdpPercap * gapminder$pop\n\ngapminder2007 &lt;- gapminder[gapminder$year == 2007, ]\n\n## Vectorized comparisons\nwealthy &lt;- gapminder2007$gdpPercap &gt;= 30000\n\npoorOrWealthy &lt;- gapminder2007$gdpPercap &gt;= 100000 | gapminder2007$gdpPercap &lt; 1000\nasiaWealthy &lt;- gapminder2007$gdpPercap &gt;= 100000 &  gapminder$continent == \"Asia\"\n\nvec1 &lt;- rnorm(5)\nvec2 &lt;- rnorm(5)\nvec1 &gt; vec2\n\n[1] FALSE  TRUE FALSE FALSE  TRUE\n\n## Vectorized boolean operations\nvec1 == vec2\n\n[1] FALSE FALSE FALSE FALSE FALSE\n\nvec1 != vec2\n\n[1] TRUE TRUE TRUE TRUE TRUE\n\n## careful: \nvec1 = vec2\nidentical(vec1, vec2)\n\n[1] TRUE\n\n\n\n\n\nAn important related concept is that of recycling\n\nvec10 &lt;- sample(1:10, 10, replace = TRUE)\nvec3 &lt;- sample(1:10, 3, replace = TRUE)\nvec5 &lt;- sample(1:10, 5, replace = TRUE)\nvec10\n\n [1]  4  7  4  8  7  2  3  8  7 10\n\nvec3\n\n[1]  2  3 10\n\nvec5\n\n[1] 7 1 3 3 7\n\nvec10 + vec5\n\n [1] 11  8  7 11 14  9  4 11 10 17\n\nvec10 + vec3\n\nWarning in vec10 + vec3: longer object length is not a multiple of shorter\nobject length\n\n\n [1]  6 10 14 10 10 12  5 11 17 12\n\n\nWhat choices were made by the R developers?\n\n\n\nImagine how this code would look if written using a loop, or three separate loops.\n\nvals &lt;- rnorm(1000)\nchi2vals &lt;- vals^2\nchi2_df1000 &lt;- sum(chi2vals)\n\nAdvantages:\n\nmuch faster than looping\neasier to code\neasier to read and understand the code\n\nVectorized code is generally fast because the underlying loop is executed in compiled C code rather than by the R interpreter.\nWe’ve already seen that lots of functions (and operators) in R are vectorized (i.e., they can take a single value or a vector as an input argument).\n\n\n\nRecall that +, -,*, / do vectorized calculations:\n\nA &lt;- matrix(1:9, 3)\nB &lt;- matrix(seq(4,36, by = 4), 3)\n\nA*7\n\n     [,1] [,2] [,3]\n[1,]    7   28   49\n[2,]   14   35   56\n[3,]   21   42   63\n\nA + B\n\n     [,1] [,2] [,3]\n[1,]    5   20   35\n[2,]   10   25   40\n[3,]   15   30   45\n\nA + B[ , 1]\n\n     [,1] [,2] [,3]\n[1,]    5    8   11\n[2,]   10   13   16\n[3,]   15   18   21\n\nA * B\n\n     [,1] [,2] [,3]\n[1,]    4   64  196\n[2,]   16  100  256\n[3,]   36  144  324\n\nA * B[ , 1]\n\n     [,1] [,2] [,3]\n[1,]    4   16   28\n[2,]   16   40   64\n[3,]   36   72  108\n\n\n\n\n\n\nA %*% B[ , 1]\n\n     [,1]\n[1,]  120\n[2,]  144\n[3,]  168\n\nA %*% B\n\n     [,1] [,2] [,3]\n[1,]  120  264  408\n[2,]  144  324  504\n[3,]  168  384  600\n\nidentical(t(A)%*%A, crossprod(A))\n\n[1] TRUE\n\n\nNow let’s do a bit of manipulation and see if you can infer how R represents matrices internally.\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nConsider our matrix ‘mat’:\n\nmat &lt;- matrix(1:16, nrow = 4, ncol = 4)\n\nSuppose I run this code: mat[4].\nWhat do you think will be returned?\n\n13\n4\n13, 14, 15, 16\n4, 8, 12, 16\nan error\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMatrices are stored column-major\n\nmat[4]\nattributes(mat) &lt;- NULL\nmat\nis.matrix(mat)\n\nThis is like Fortran, MATLAB and Julia but not like C or Python(numpy).\n\n\n\n\n\n\nR can do essentially any linear algebra you need. It uses system-level packages called BLAS (basic linear algebra subroutines) and LAPACK (linear algebra package). Note that these calculations will be essentially as fast as if you wrote C code because R just calls C and Fortran routines to do the calculations.\nThe BLAS that comes with R is fairly slow. It’s possible to use a faster BLAS, as well as one that uses multiple cores automatically. This can in some cases give you an order of magnitude speedup if your work involves a lot of matrix manipulations/linear algebra.\n\n\n\nHere are some examples of common matrix decompositions: Cholesky decomposition, eigenvalues/eigenvectors, and SVD. These all use BLAS+LAPACK.\n\n## next 3 lines generate a positive definite matrix\nlibrary(fields)\n\nLoading required package: spam\n\n\nSpam version 2.11-1 (2025-01-20) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAttaching package: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nLoading required package: viridisLite\n\n\n\nTry help(fields) to get started.\n\ntimes &lt;- seq(0, 1, length = 100)\nR &lt;- exp(-rdist(times) / 0.2) # a correlation matrix\n######################################################\ne &lt;- eigen(R)\nrange(e$values)\n\n[1]  0.02525338 32.85537225\n\ne$vectors[ , 1]\n\n  [1] 0.05195413 0.05448567 0.05698864 0.05946173 0.06190363 0.06431308\n  [7] 0.06668879 0.06902954 0.07133409 0.07360123 0.07582978 0.07801856\n [13] 0.08016643 0.08227226 0.08433494 0.08635341 0.08832659 0.09025345\n [19] 0.09213298 0.09396420 0.09574615 0.09747789 0.09915851 0.10078713\n [25] 0.10236291 0.10388500 0.10535262 0.10676499 0.10812137 0.10942106\n [31] 0.11066337 0.11184765 0.11297327 0.11403965 0.11504623 0.11599249\n [37] 0.11687791 0.11770205 0.11846447 0.11916476 0.11980256 0.12037754\n [43] 0.12088940 0.12133786 0.12172270 0.12204370 0.12230071 0.12249358\n [49] 0.12262222 0.12268655 0.12268655 0.12262222 0.12249358 0.12230071\n [55] 0.12204370 0.12172270 0.12133786 0.12088940 0.12037754 0.11980256\n [61] 0.11916476 0.11846447 0.11770205 0.11687791 0.11599249 0.11504623\n [67] 0.11403965 0.11297327 0.11184765 0.11066337 0.10942106 0.10812137\n [73] 0.10676499 0.10535262 0.10388500 0.10236291 0.10078713 0.09915851\n [79] 0.09747789 0.09574615 0.09396420 0.09213298 0.09025345 0.08832659\n [85] 0.08635341 0.08433494 0.08227226 0.08016643 0.07801856 0.07582978\n [91] 0.07360123 0.07133409 0.06902954 0.06668879 0.06431308 0.06190363\n [97] 0.05946173 0.05698864 0.05448567 0.05195413\n\nsv &lt;- svd(R)\nU &lt;- chol(R)\n\ndevs &lt;- rnorm(100)\nRinvb &lt;- solve(R, devs)  # R^{-1} b\nRinv &lt;- solve(R) # R^{-1} -- try to avoid this (slower and less numerically stable)",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#vectorized-calculations-and-comparisons",
    "href": "units/calculation.html#vectorized-calculations-and-comparisons",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "At the core of R is the idea of doing calculations on entire vectors.\n\n## Vectorized arithmetic\ngdpTotal &lt;- gapminder$gdpPercap * gapminder$pop\n\ngapminder2007 &lt;- gapminder[gapminder$year == 2007, ]\n\n## Vectorized comparisons\nwealthy &lt;- gapminder2007$gdpPercap &gt;= 30000\n\npoorOrWealthy &lt;- gapminder2007$gdpPercap &gt;= 100000 | gapminder2007$gdpPercap &lt; 1000\nasiaWealthy &lt;- gapminder2007$gdpPercap &gt;= 100000 &  gapminder$continent == \"Asia\"\n\nvec1 &lt;- rnorm(5)\nvec2 &lt;- rnorm(5)\nvec1 &gt; vec2\n\n[1] FALSE  TRUE FALSE FALSE  TRUE\n\n## Vectorized boolean operations\nvec1 == vec2\n\n[1] FALSE FALSE FALSE FALSE FALSE\n\nvec1 != vec2\n\n[1] TRUE TRUE TRUE TRUE TRUE\n\n## careful: \nvec1 = vec2\nidentical(vec1, vec2)\n\n[1] TRUE",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#recycling",
    "href": "units/calculation.html#recycling",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "An important related concept is that of recycling\n\nvec10 &lt;- sample(1:10, 10, replace = TRUE)\nvec3 &lt;- sample(1:10, 3, replace = TRUE)\nvec5 &lt;- sample(1:10, 5, replace = TRUE)\nvec10\n\n [1]  4  7  4  8  7  2  3  8  7 10\n\nvec3\n\n[1]  2  3 10\n\nvec5\n\n[1] 7 1 3 3 7\n\nvec10 + vec5\n\n [1] 11  8  7 11 14  9  4 11 10 17\n\nvec10 + vec3\n\nWarning in vec10 + vec3: longer object length is not a multiple of shorter\nobject length\n\n\n [1]  6 10 14 10 10 12  5 11 17 12\n\n\nWhat choices were made by the R developers?",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#why-vectorize",
    "href": "units/calculation.html#why-vectorize",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "Imagine how this code would look if written using a loop, or three separate loops.\n\nvals &lt;- rnorm(1000)\nchi2vals &lt;- vals^2\nchi2_df1000 &lt;- sum(chi2vals)\n\nAdvantages:\n\nmuch faster than looping\neasier to code\neasier to read and understand the code\n\nVectorized code is generally fast because the underlying loop is executed in compiled C code rather than by the R interpreter.\nWe’ve already seen that lots of functions (and operators) in R are vectorized (i.e., they can take a single value or a vector as an input argument).",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#vectorization-with-matrices",
    "href": "units/calculation.html#vectorization-with-matrices",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "Recall that +, -,*, / do vectorized calculations:\n\nA &lt;- matrix(1:9, 3)\nB &lt;- matrix(seq(4,36, by = 4), 3)\n\nA*7\n\n     [,1] [,2] [,3]\n[1,]    7   28   49\n[2,]   14   35   56\n[3,]   21   42   63\n\nA + B\n\n     [,1] [,2] [,3]\n[1,]    5   20   35\n[2,]   10   25   40\n[3,]   15   30   45\n\nA + B[ , 1]\n\n     [,1] [,2] [,3]\n[1,]    5    8   11\n[2,]   10   13   16\n[3,]   15   18   21\n\nA * B\n\n     [,1] [,2] [,3]\n[1,]    4   64  196\n[2,]   16  100  256\n[3,]   36  144  324\n\nA * B[ , 1]\n\n     [,1] [,2] [,3]\n[1,]    4   16   28\n[2,]   16   40   64\n[3,]   36   72  108",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#linear-algebra-matrixvector-multiplication",
    "href": "units/calculation.html#linear-algebra-matrixvector-multiplication",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "A %*% B[ , 1]\n\n     [,1]\n[1,]  120\n[2,]  144\n[3,]  168\n\nA %*% B\n\n     [,1] [,2] [,3]\n[1,]  120  264  408\n[2,]  144  324  504\n[3,]  168  384  600\n\nidentical(t(A)%*%A, crossprod(A))\n\n[1] TRUE\n\n\nNow let’s do a bit of manipulation and see if you can infer how R represents matrices internally.",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#matrix-and-array-internals",
    "href": "units/calculation.html#matrix-and-array-internals",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "Question\n\n\n\nConsider our matrix ‘mat’:\n\nmat &lt;- matrix(1:16, nrow = 4, ncol = 4)\n\nSuppose I run this code: mat[4].\nWhat do you think will be returned?\n\n13\n4\n13, 14, 15, 16\n4, 8, 12, 16\nan error\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMatrices are stored column-major\n\nmat[4]\nattributes(mat) &lt;- NULL\nmat\nis.matrix(mat)\n\nThis is like Fortran, MATLAB and Julia but not like C or Python(numpy).",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#linear-algebra",
    "href": "units/calculation.html#linear-algebra",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "R can do essentially any linear algebra you need. It uses system-level packages called BLAS (basic linear algebra subroutines) and LAPACK (linear algebra package). Note that these calculations will be essentially as fast as if you wrote C code because R just calls C and Fortran routines to do the calculations.\nThe BLAS that comes with R is fairly slow. It’s possible to use a faster BLAS, as well as one that uses multiple cores automatically. This can in some cases give you an order of magnitude speedup if your work involves a lot of matrix manipulations/linear algebra.",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#matrix-decompositions",
    "href": "units/calculation.html#matrix-decompositions",
    "title": "Calculations and Efficiency",
    "section": "",
    "text": "Here are some examples of common matrix decompositions: Cholesky decomposition, eigenvalues/eigenvectors, and SVD. These all use BLAS+LAPACK.\n\n## next 3 lines generate a positive definite matrix\nlibrary(fields)\n\nLoading required package: spam\n\n\nSpam version 2.11-1 (2025-01-20) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAttaching package: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nLoading required package: viridisLite\n\n\n\nTry help(fields) to get started.\n\ntimes &lt;- seq(0, 1, length = 100)\nR &lt;- exp(-rdist(times) / 0.2) # a correlation matrix\n######################################################\ne &lt;- eigen(R)\nrange(e$values)\n\n[1]  0.02525338 32.85537225\n\ne$vectors[ , 1]\n\n  [1] 0.05195413 0.05448567 0.05698864 0.05946173 0.06190363 0.06431308\n  [7] 0.06668879 0.06902954 0.07133409 0.07360123 0.07582978 0.07801856\n [13] 0.08016643 0.08227226 0.08433494 0.08635341 0.08832659 0.09025345\n [19] 0.09213298 0.09396420 0.09574615 0.09747789 0.09915851 0.10078713\n [25] 0.10236291 0.10388500 0.10535262 0.10676499 0.10812137 0.10942106\n [31] 0.11066337 0.11184765 0.11297327 0.11403965 0.11504623 0.11599249\n [37] 0.11687791 0.11770205 0.11846447 0.11916476 0.11980256 0.12037754\n [43] 0.12088940 0.12133786 0.12172270 0.12204370 0.12230071 0.12249358\n [49] 0.12262222 0.12268655 0.12268655 0.12262222 0.12249358 0.12230071\n [55] 0.12204370 0.12172270 0.12133786 0.12088940 0.12037754 0.11980256\n [61] 0.11916476 0.11846447 0.11770205 0.11687791 0.11599249 0.11504623\n [67] 0.11403965 0.11297327 0.11184765 0.11066337 0.10942106 0.10812137\n [73] 0.10676499 0.10535262 0.10388500 0.10236291 0.10078713 0.09915851\n [79] 0.09747789 0.09574615 0.09396420 0.09213298 0.09025345 0.08832659\n [85] 0.08635341 0.08433494 0.08227226 0.08016643 0.07801856 0.07582978\n [91] 0.07360123 0.07133409 0.06902954 0.06668879 0.06431308 0.06190363\n [97] 0.05946173 0.05698864 0.05448567 0.05195413\n\nsv &lt;- svd(R)\nU &lt;- chol(R)\n\ndevs &lt;- rnorm(100)\nRinvb &lt;- solve(R, devs)  # R^{-1} b\nRinv &lt;- solve(R) # R^{-1} -- try to avoid this (slower and less numerically stable)",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#pre-allocation",
    "href": "units/calculation.html#pre-allocation",
    "title": "Calculations and Efficiency",
    "section": "Pre-allocation",
    "text": "Pre-allocation\nThis is slow.\n\nvals &lt;- 0\nn &lt;- 50000\nsystem.time({\nfor(i in 1:n)\n      vals &lt;- c(vals, i)\n})\n\n   user  system elapsed \n  2.952   0.037   2.989 \n\n\nThe same holds for using rbind(), cbind(), or adding to a list, one element at a time.\nQuestion: Thoughts on why this are so slow? Think about what R might be doing behind the scenes in terms of storage in memory.\nNote: This is one area where Python and some other languages handle the situation in a more sophisticated way.",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#the-answer-is-to-pre-allocate-memory",
    "href": "units/calculation.html#the-answer-is-to-pre-allocate-memory",
    "title": "Calculations and Efficiency",
    "section": "The answer is to pre-allocate memory",
    "text": "The answer is to pre-allocate memory\nThis is not so slow. (Please ignore the fact that this is a silly way to do this in R.)\n\nn &lt;- 50000\nsystem.time({\nvals &lt;- rep(0, n)\nfor(i in 1:n)\n      vals[i] &lt;- i\n})\n\n   user  system elapsed \n  0.004   0.000   0.004",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#apply",
    "href": "units/calculation.html#apply",
    "title": "Calculations and Efficiency",
    "section": "apply",
    "text": "apply\nSome functions aren’t vectorized, or you may want to use a function on every row or column of a matrix/data frame, every element of a list, etc.\nFor this we use the apply() family of functions to make our code more readable.\n\nmat &lt;- matrix(rnorm(100*1000), nr = 100)\nrow_min &lt;- apply(mat, MARGIN = 1, FUN = min)\ncol_max &lt;- apply(mat, MARGIN = 2, FUN = max)\n\nThere are actually some even faster specialized functions:\n\nrow_mean &lt;- rowMeans(mat)\ncol_sum &lt;- colSums(mat)",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#lapply-and-sapply",
    "href": "units/calculation.html#lapply-and-sapply",
    "title": "Calculations and Efficiency",
    "section": "lapply() and sapply()",
    "text": "lapply() and sapply()\nThese are “map” operations that apply a function to each element of a list.\n\nmyList &lt;- list(rnorm(3), rnorm(3), rnorm(5))\nlapply(myList, min)\n\n[[1]]\n[1] -1.408063\n\n[[2]]\n[1] 1.44249\n\n[[3]]\n[1] -1.739095\n\nsapply(myList, min)\n\n[1] -1.408063  1.442490 -1.739095\n\n\n\n\n\n\n\n\nWhy use lapply and sapply?\n\n\n\nThe *array functions won’t generally be faster than loops. Rather, they’re generally used in order to have cleaner, more readable code.\n\n\nNote that we don’t generally want to use apply() on a data frame.",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#lapply-and-sapply-with-vectors",
    "href": "units/calculation.html#lapply-and-sapply-with-vectors",
    "title": "Calculations and Efficiency",
    "section": "lapply() and sapply() with vectors",
    "text": "lapply() and sapply() with vectors\nYou can use lapply() and sapply() on regular vectors, such as vectors of indices, which can come in handy. This is a bit silly but it illustrates the idea:\n\nmyfun &lt;- function(i) {\n   max(rnorm(100))\n}   \n\nout &lt;- lapply(1:6, myfun)\nout\n\n[[1]]\n[1] 2.73752\n\n[[2]]\n[1] 2.011486\n\n[[3]]\n[1] 2.770487\n\n[[4]]\n[1] 1.914722\n\n[[5]]\n[1] 2.199235\n\n[[6]]\n[1] 1.924321\n\n## Or, 'in-line' the function:\n\nout &lt;- sapply(1:10, function(x) x^2)\nout\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of these give exactly this result: pi, 2*pi, 3*pi, …?\n\n(1:n)*pi\nout &lt;- rep(0, n); for(x in 1:n) out &lt;- x*pi\nsapply(1:n, function(x) x*pi)\nout &lt;- rep(0, n); for(x in 1:n) out[i] &lt;- x*pi\nlapply(1:n, function(x) x*pi)\nsapply(1:n, “*“, pi)\n1:n*pi",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#whenwhy-are-loops-in-r-slow",
    "href": "units/calculation.html#whenwhy-are-loops-in-r-slow",
    "title": "Calculations and Efficiency",
    "section": "When/why are loops in R slow?",
    "text": "When/why are loops in R slow?\nConsider this code:\n\nx &lt;- 3\nx*7\nx &lt;- 'hi'\nx*7\n\n￼ Because of dynamic typing, when the interpreter sees x*7 it needs to check if x is something that can be multiplied by 7, including dealing with the fact that x could be a vector with many numbers in it. In addition it needs to (using scoping rules) look up the value of x. (Consider that x might not even exist at the point that x*7 is called.) Only then can the multiplication happen.\nLet’s consider writing a loop:\n\nfor(i in 1:10) {\n  if(runif(1) &gt; 0) x &lt;- 'hi'\n  if(runif(1) &gt; 0.5) rm(x)\n  x[i] &lt;- exp(x[i])\n}  \n\n￼ Because of the dynamic typing and lack of compilation, the interpreter needs to check if x exists, if it is a vector of sufficient length, if it contains numeric values, and it needs to go retrieve the required value, EVERY TIME the exp() is executed.\nThe R interpreter is a C program, so in some sense everything that happens is running as compiled code, but there are lots more things being done to accomplish a given task using interpreted code than if the task had been written directly in code that is compiled. By analogy, consider talking directly to a person in a language you both know compared to talking to a person via an interpreter who has to translate between two languages. Ultimately, the same information gets communicated (hopefully!) but the number of words spoken and time involved is much greater.",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#when-are-loops-not-slow",
    "href": "units/calculation.html#when-are-loops-not-slow",
    "title": "Calculations and Efficiency",
    "section": "When are loops not slow?",
    "text": "When are loops not slow?\nWhen the bulk of the time in the loop involves actual computation rather than checking, e.g., a loop that fits a separate machine learning model at each iteration.\nConclusions: use vectorization when you can, especially when the individual calculations are fast, but don’t obsess when the individual calculations are intensive (and often will call out to C directly).",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#some-efficiency-tips-not-r-specific",
    "href": "units/calculation.html#some-efficiency-tips-not-r-specific",
    "title": "Calculations and Efficiency",
    "section": "Some efficiency tips (not R-specific)",
    "text": "Some efficiency tips (not R-specific)\n\nConsider the order of operations:\n\nn &lt;- 3000\nA &lt;- matrix(rnorm(n^2),n)\nB &lt;- matrix(rnorm(n^2),n)\nx &lt;- rnorm(n)\nsystem.time(A %*% B %*% x)\n\n   user  system elapsed \n  3.099   1.094   0.751 \n\nsystem.time(A %*% (B %*% x))\n\n   user  system elapsed \n  0.074   0.037   0.026 \n\n\nAvoid duplicated computation\n\nDon’t duplicate operations within iterations of a loop unnecessarily (precompute them)\n\nTry to work with adjacent elements (in memory) of large vectors/matrices/arrays to efficiently use the CPU cache.\n\nIn R, generally work column-wise rather than row-wise with matrices\n\nIn R, look up elements by numerical index rather than by name for O(1) computation",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#timing-your-code",
    "href": "units/calculation.html#timing-your-code",
    "title": "Calculations and Efficiency",
    "section": "Timing your code",
    "text": "Timing your code\nFirst, a cautionary note…\n\npremature optimization is the root of all evil\n— Donald Knuth, 1974\n\nThere are a few tools in R for timing your code.\n\nsystem.time(mean(rnorm(1e7)))\n\n   user  system elapsed \n  0.601   0.022   0.623 \n\nlibrary(rbenchmark)\nn &lt;- 1000\nx &lt;- matrix(rnorm(n^2), n)\nbenchmark(t(x) %*% x,\n          crossprod(x),\n          replications = 5,\n          columns = c('test', 'replications', 'elapsed'))\n\n          test replications elapsed\n2 crossprod(x)            5   0.144\n1   t(x) %*% x            5   0.216\n\n\nConsider why the automatic crossproduct may be faster than the manual version. Note that crossprod calls out directly to a linear algebra system routine.",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#microbenchmark",
    "href": "units/calculation.html#microbenchmark",
    "title": "Calculations and Efficiency",
    "section": "Microbenchmark",
    "text": "Microbenchmark\nTo time code that runs very quickly, you should use the microbenchmark package. Of course one would generally only care about accurately timing quick calculations if a larger operation does the quick calculation very many times. Here’s a comparison of different ways of accessing an element of a dataframe.\n\nlibrary(microbenchmark)\ndf &lt;- data.frame(vals = 1:3, labs = c('a','b','c'))\nvec &lt;- c(\"a\"=5, \"b\" = 7, \"c\" = 9)\nmicrobenchmark(\n  df[2,1],\n  df$vals[2],\n  df[2, 'vals'],\n  vec[2],\n  vec[\"b\"]\n)\n\nUnit: nanoseconds\n          expr  min     lq     mean median      uq    max neval cld\n      df[2, 1] 8560 9333.0 15469.86 9781.0 10374.0 174751   100  a \n    df$vals[2]  647  891.5  1486.92 1016.5  1329.0  13394   100   b\n df[2, \"vals\"] 8746 9304.0 13052.53 9733.5 10208.0  48658   100  a \n        vec[2]  267  346.0   524.01  397.5   484.5   5854   100   b\n      vec[\"b\"]  307  393.0   571.58  451.5   551.5   2763   100   b",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#memory-use",
    "href": "units/calculation.html#memory-use",
    "title": "Calculations and Efficiency",
    "section": "Memory use",
    "text": "Memory use\nYou should know how much memory (RAM) the computer you are using has and keep in mind how big your objects are and how much memory you code might use. All objects in R are stored in RAM unlike a database or certain tools for working with big data (e.g., Python’s Dask package and certain R packages).\nIf in total, the jobs on a machine approach the physical RAM, the machine may (depending on how it is set up) start to use the hard disk as ‘virtual memory’. This is called paging or swapping, and once this happens you’re often toast (i.e., your code may take essentially forever to finish). And if paging doesn’t happen, your job will die with an out-of-memory (OOM) error.\nYou can assess memory use with top or ps or free in Linux/Mac or the Task Manager in Windows.\nOften it’s a good idea to roughly estimate how much memory an object will take up even before creating it in R. You can do this with some simple arithmetic.\n\nx &lt;- matrix(rnorm(1e6*10), 1e6)\nobject.size(x)\n\n80000216 bytes\n\n1e6 * 10 *8/ 1e6  # direct calculation of Mb\n\n[1] 80\n\nprint(object.size(x), units = 'auto')\n\n76.3 Mb",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#garbage-collection",
    "href": "units/calculation.html#garbage-collection",
    "title": "Calculations and Efficiency",
    "section": "Garbage collection",
    "text": "Garbage collection\nA variable is just a name that references a location (object) in memory. When a name is used for a different object, the memory for the old object is freed to be used again.\n\nlibrary(pryr)\nx &lt;- rnorm(1e8)\nobject.size(x)\n\n800000048 bytes\n\nmem_used()\n\n1.09 GB\n\nx &lt;- \"hello\"\nmem_used()\n\n292 MB",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#copy-on-modify",
    "href": "units/calculation.html#copy-on-modify",
    "title": "Calculations and Efficiency",
    "section": "Copy-on-modify",
    "text": "Copy-on-modify\nThe semantics of R say that &lt;- creates a new copy of an object.\nThe implementation in the R interpreter is that copies are only made when needed.\n\nlibrary(pryr)\nsystem.time(x &lt;- rnorm(1e8))\n\n   user  system elapsed \n  6.014   0.249   6.264 \n\nobject.size(x)\n\n800000048 bytes\n\nmem_used()\n\n1.09 GB\n\nsystem.time(y &lt;- x)\n\n   user  system elapsed \n      0       0       0 \n\nmem_used()\n\n1.09 GB\n\naddress(x)\n\n[1] \"0x7f3328318010\"\n\naddress(y)\n\n[1] \"0x7f3328318010\"\n\nsystem.time(x[1] &lt;- 3)  # Clearly more time than just modifying one element!\n\n   user  system elapsed \n  0.155   0.203   0.358 \n\nmem_used()\n\n1.89 GB\n\naddress(x)\n\n[1] \"0x7f32f8827010\"\n\naddress(y)\n\n[1] \"0x7f3328318010\"\n\n\nInternally R manages this by keeping track of how many variables (references) there are to a given object in memory.",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/calculation.html#memory-and-lists",
    "href": "units/calculation.html#memory-and-lists",
    "title": "Calculations and Efficiency",
    "section": "Memory and lists",
    "text": "Memory and lists\nR plays various games with lists and character strings (essentially copy-on-change) to avoid redundant copies of identical data. We won’t go into details.",
    "crumbs": [
      "Modules (a partial set)",
      "Calculation"
    ]
  },
  {
    "objectID": "units/intro.html",
    "href": "units/intro.html",
    "title": "Basic Introduction to R Syntax",
    "section": "",
    "text": "R as a calculator\nThe syntax for doing interactive calculations in R is similar to other languages such as Python, MATLAB, and Julia, though some of the operators differ.\nHere are some examples that you should be able to replicate yourself in a plain R session or in the console/command window of RStudio. The console window will by default be the left (or perhaps lower left) window pane when you start RStudio.\n\n2 + 2 # add numbers\n\n[1] 4\n\n2 * pi # multiply by a constant\n\n[1] 6.283185\n\n7 + runif(1) # add a random number\n\n[1] 7.680809\n\n3^4 # powers\n\n[1] 81\n\nsqrt(4^4) # functions\n\n[1] 16\n\nlog(10)\n\n[1] 2.302585\n\nlog(100, base = 10)\n\n[1] 2\n\n23 %/% 2 \n\n[1] 11\n\n23 %% 2\n\n[1] 1\n\n# scientific notation\n5000000000 * 1000\n\n[1] 5e+12\n\n5e9 * 1e3\n\n[1] 5e+12\n\n\nThink of a mathematical operation you need - can you guess how to do it in R?\nSide note to presenter: turn off R Notebook inline view via RStudio -&gt; Preferences -&gt; R Markdown -&gt; Show output inline …\n\n\n\n\n\n\nQuestion\n\n\n\nHow do I calculate the cosine of 2 pi?\n\ncosine(2pi)\ncosine(2*pi)\ncos(2 * pi)\ncos(2 x pi)\ncos(2*pi)\ncos(2 * 3.14159)\ncos[2*pi]\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe function name is cos not cosine.\nA function call specifies the arguments in parentheses (), not brackets [].\nSpaces don’t generally matter (there are exceptions).\npi is an object in the R language.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat happens if you do this?\n\ncos(2*pi\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSince we didn’t enter the closing parenthesis, R is waiting for additional input with the “continuation” prompt of +.\nYou can either enter the missing syntax or hit Ctrl-C or esc to kill the partial syntax and return to the usual prompt.\n\n\n\n\n\nAssigning values to R objects\nA key action in R (similar to other languages) is to store values in the form of R objects, and to examine the value of R objects.\n\nval &lt;- 3\nval\n\n[1] 3\n\nprint(val)\n\n[1] 3\n\nVal &lt;- 7 # case-sensitive!\nprint(val)\n\n[1] 3\n\nprint(Val)\n\n[1] 7\n\n\nHere is some other syntax to create objects.\n\nmySeq &lt;- 1:6\nmySeq\n\n[1] 1 2 3 4 5 6\n\nyears &lt;- seq(1952, 2007, by = 5)\nyears\n\n [1] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 2002 2007\n\nlength(years)\n\n[1] 12\n\n## This is a comment: here is an example of non-numeric data\ncountry &lt;- rep(\"Afghanistan\", 12)\ncountry \n\n [1] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\"\n [6] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\"\n[11] \"Afghanistan\" \"Afghanistan\"\n\n\nR gives us a lot of flexibility (within certain rules) for assigning to (parts of) objects from (parts of) other objects. We’ll see this through the bootcamp.\n\n\nVectors in R\nThe most basic form of an R object is a vector (i.e., a 1-dimensional array). The various objects mySeq, years, country are all vectors.\nIn fact, individual (scalar) values are vectors of length one, so val and Val from above are also vectors.\nWe can concatenate values into a vector with c().\n\n## numeric vector\nnums &lt;- c(1.1, 3, -5.7)\ndevs &lt;- rnorm(5)   # Five random normal values.\ndevs\n\n[1]  0.2955179 -0.1775973  0.1176457 -0.5821415 -0.2111586\n\n\nThis is not valid syntax in R. Let’s try it and see what happens.\n\nnums &lt;- (1.1, 3, -5.7)\nnums &lt;- [1.1, 3, -5.7]\n\n\n\nWorking with indices and subsets\nWe can subset (aka “slice”) using a variety of approaches.\n\nvals &lt;- 1:12\n\nvals[3]\n\n[1] 3\n\nvals[3:5]\n\n[1] 3 4 5\n\nvals[c(1, 3, 6)]\n\n[1] 1 3 6\n\nvals[-c(1, 3, 6)]\n\n[1]  2  4  5  7  8  9 10 11 12\n\nvals[c(rep(TRUE, 3), rep(FALSE, 2), TRUE, rep(FALSE, 6))]\n\n[1] 1 2 3 6\n\n\nWe can substitute values into vectors:\n\nvals[4] &lt;- 822.9711\nvals[3:4] &lt;- c(7.5, 2.4)\nvals[2:4] &lt;- 0  # Recycling\n\nThe last substutition uses “recycling” to match the left-hand-side extent (3 elements) with the right-hand-side extent (1 element)\n\n\n\n\n\n\nQuestion\n\n\n\nSuppose you have a vetor, such as created like this: vals &lt;- rnorm(4). Which of these will work to extract a subset of a vector?\n\nvals[3]\nvals[2,3]\nvals[c(2,3)]\nvals(2,3)\nvals[c(FALSE, TRUE, TRUE, FALSE)]\nvals[c(f,t,t,f)]\nvals(3)\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nSubsetting uses square brackets so (4) and (7) don’t work.\nTo create a set of indices to use in subsetting/slicing, you need to use c(), so (3) and (5) work.\nBooleans in R use the canonical syntax of TRUE and FALSE, so (5) works but not (6).\n\n\n\n\n\n\nUsing functions in R\n\nFunctions generally take arguments, some of which are often optional:\n\n\nlog(10)\n\n[1] 2.302585\n\nlog(10, base = 10)\n\n[1] 1\n\n\n\nWe can embed function calls:\n\n\nhist(rnorm(1000))\n\n\n\n\nA histogram\n\n\n\n\n\nWe can (usually) see the code of a function:\n\n\nlm\n\nfunction (formula, data, subset, weights, na.action, method = \"qr\", \n    model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, \n    contrasts = NULL, offset, ...) \n{\n    ret.x &lt;- x\n    ret.y &lt;- y\n    cl &lt;- match.call()\n    mf &lt;- match.call(expand.dots = FALSE)\n    m &lt;- match(c(\"formula\", \"data\", \"subset\", \"weights\", \"na.action\", \n        \"offset\"), names(mf), 0L)\n    mf &lt;- mf[c(1L, m)]\n    mf$drop.unused.levels &lt;- TRUE\n    mf[[1L]] &lt;- quote(stats::model.frame)\n    mf &lt;- eval(mf, parent.frame())\n    if (method == \"model.frame\") \n        return(mf)\n    else if (method != \"qr\") \n        warning(gettextf(\"method = '%s' is not supported. Using 'qr'\", \n            method), domain = NA)\n    mt &lt;- attr(mf, \"terms\")\n    y &lt;- model.response(mf, \"numeric\")\n    w &lt;- as.vector(model.weights(mf))\n    if (!is.null(w) && !is.numeric(w)) \n        stop(\"'weights' must be a numeric vector\")\n    offset &lt;- model.offset(mf)\n    mlm &lt;- is.matrix(y)\n    ny &lt;- if (mlm) \n        nrow(y)\n    else length(y)\n    if (!is.null(offset)) {\n        if (!mlm) \n            offset &lt;- as.vector(offset)\n        if (NROW(offset) != ny) \n            stop(gettextf(\"number of offsets is %d, should equal %d (number of observations)\", \n                NROW(offset), ny), domain = NA)\n    }\n    if (is.empty.model(mt)) {\n        x &lt;- NULL\n        z &lt;- list(coefficients = if (mlm) matrix(NA_real_, 0, \n            ncol(y)) else numeric(), residuals = y, fitted.values = 0 * \n            y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w != \n            0) else ny)\n        if (!is.null(offset)) {\n            z$fitted.values &lt;- offset\n            z$residuals &lt;- y - offset\n        }\n    }\n    else {\n        x &lt;- model.matrix(mt, mf, contrasts)\n        z &lt;- if (is.null(w)) \n            lm.fit(x, y, offset = offset, singular.ok = singular.ok, \n                ...)\n        else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok, \n            ...)\n    }\n    class(z) &lt;- c(if (mlm) \"mlm\", \"lm\")\n    z$na.action &lt;- attr(mf, \"na.action\")\n    z$offset &lt;- offset\n    z$contrasts &lt;- attr(x, \"contrasts\")\n    z$xlevels &lt;- .getXlevels(mt, mf)\n    z$call &lt;- cl\n    z$terms &lt;- mt\n    if (model) \n        z$model &lt;- mf\n    if (ret.x) \n        z$x &lt;- x\n    if (ret.y) \n        z$y &lt;- y\n    if (!qr) \n        z$qr &lt;- NULL\n    z\n}\n&lt;bytecode: 0x5945151f7a68&gt;\n&lt;environment: namespace:stats&gt;\n\n\n\n\nGetting help about a function\nTo get information about a function you know exists, use help or ?, e.g., ?lm.\n\nhelp(lm)\n?lm\n\n?log\n\n\n\nHow to be lazy\nIf you’re starting to type something you’ve typed before, or the long name of an R object or function, STOP! You likely don’t need to type all of that.\n\nTab completion\nCommand history\n\nup/down arrows\nCtrl-{up arrow} or Command-{up arrow}\n\nRStudio: select a line or block for execution\nFor keyboard shortcuts in RStudio see:\n\nTools -&gt; Keyboard Shortcuts Help or\nthis and this blog posts.\n\nOther tips for saving time in RStudio and R Markdown\n\n\n\nManaging the workspace\nR has functions for learning about the collection of objects in your workspace. Some of this is built in to RStudio (see the Enviornment tab in upper right pane).\n\n## Let's first create a few objects\nx &lt;- rnorm(5)\ny &lt;- c(5L, 2L, 7L)\nz &lt;- list(a = 3, b = c('sam', 'yang'))\nls()  # search the user workspace (global environment)\n\n [1] \"country\"       \"denslines\"     \"densplot\"      \"devs\"         \n [5] \"dim2\"          \"f.dplot\"       \"f.ess\"         \"f.ess.old\"    \n [9] \"f.flushplot\"   \"f.gm\"          \"f.grstat\"      \"f.identity\"   \n[13] \"f.invlogit\"    \"f.logit\"       \"f.lonlat2eucl\" \"f.merge\"      \n[17] \"f.sort\"        \"f.sort2\"       \"f.trimat\"      \"f.vecrep\"     \n[21] \"format_bytes\"  \"getNcdf\"       \"im\"            \"indices\"      \n[25] \"ln\"            \"lnm\"           \"ls_sizes\"      \"makePoly\"     \n[29] \"mySeq\"         \"nums\"          \"pmap\"          \"pmap2\"        \n[33] \"pointsInPoly\"  \"pplot\"         \"print.quitter\" \"q\"            \n[37] \"R2\"            \"rcsv\"          \"temp.colors\"   \"thresh\"       \n[41] \"time_chol\"     \"tplot\"         \"tsplot\"        \"val\"          \n[45] \"Val\"           \"vals\"          \"wcsv\"          \"x\"            \n[49] \"y\"             \"years\"         \"z\"            \n\nrm(x)    # delete a variable\nls()\n\n [1] \"country\"       \"denslines\"     \"densplot\"      \"devs\"         \n [5] \"dim2\"          \"f.dplot\"       \"f.ess\"         \"f.ess.old\"    \n [9] \"f.flushplot\"   \"f.gm\"          \"f.grstat\"      \"f.identity\"   \n[13] \"f.invlogit\"    \"f.logit\"       \"f.lonlat2eucl\" \"f.merge\"      \n[17] \"f.sort\"        \"f.sort2\"       \"f.trimat\"      \"f.vecrep\"     \n[21] \"format_bytes\"  \"getNcdf\"       \"im\"            \"indices\"      \n[25] \"ln\"            \"lnm\"           \"ls_sizes\"      \"makePoly\"     \n[29] \"mySeq\"         \"nums\"          \"pmap\"          \"pmap2\"        \n[33] \"pointsInPoly\"  \"pplot\"         \"print.quitter\" \"q\"            \n[37] \"R2\"            \"rcsv\"          \"temp.colors\"   \"thresh\"       \n[41] \"time_chol\"     \"tplot\"         \"tsplot\"        \"val\"          \n[45] \"Val\"           \"vals\"          \"wcsv\"          \"y\"            \n[49] \"years\"         \"z\"            \n\nls.str() # list and describe variables\n\ncountry :  chr [1:12] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\ndenslines : function (psi, const = 1.06, minval = -Inf, ...)  \ndensplot : function (psi, const = 1.06, xlab = \"\", ylim = NULL, yax = \"auto\", ...)  \ndevs :  num [1:5] 0.296 -0.178 0.118 -0.582 -0.211\ndim2 : function (x)  \nf.dplot : function (psi, xlab = \"\", normal = FALSE, const = 1.06, yax = \"auto\", quantiles = TRUE, \n    ...)  \nf.ess : function (vec)  \nf.ess.old : function (vec, lmax, threshold = 0.05)  \nf.flushplot : function (x, y, xlab = \"\", ylab = \"\", type = \"l\", ...)  \nf.gm : function (vec)  \nf.grstat : function (mat)  \nf.identity : function (vals)  \nf.invlogit : function (vals)  \nf.logit : function (vals)  \nf.lonlat2eucl : function (lonlat, ctr = NULL, miles = FALSE)  \nf.merge : function (x, y, ...)  \nf.sort : function (dataframe, sortby = 1, decreasing = FALSE)  \nf.sort2 : function (data.frame, ...)  \nf.trimat : function (size, offdiag, diags)  \nf.vecrep : function (vec, numreps = 1)  \nformat_bytes : function (x)  \ngetNcdf : function (fileName, varid = \"pr\")  \nim : function (g, nr)  \nindices : function (trueVec)  \nln : function (end = \"dev\")  \nlnm : function (end = \"dev\")  \nls_sizes : function (name = parent.frame(), pretty = T, top = 10, ...)  \nmakePoly : function ()  \nmySeq :  int [1:6] 1 2 3 4 5 6\nnums :  num [1:3] 1.1 3 -5.7\npmap : function (y, x, nr = 80, nc = 80, xlab = \"\", ylab = \"\", col = tim.colors(32), \n    ...)  \npmap2 : function (y, x, xlab = \"\", ylab = \"\", col = tim.colors(32), zlim = NULL, \n    shrink = 0.9, cex = 0.7, pch = 19, min = NULL, max = NULL, ...)  \npointsInPoly : function (point.coords, vertices)  \npplot : function (x, y, ..., transparency = FALSE)  \nprint.quitter : function (x)  \nq :  list()\nR2 : function (vals, preds)  \nrcsv : function (file, header = T)  \ntemp.colors : function (n = 25)  \nthresh : function (vec, up = NULL, lo = NULL)  \ntime_chol : function (n)  \ntplot : function (objName, which = NULL, col = NULL)  \ntsplot : function (vec, ...)  \nval :  num 3\nVal :  num 7\nvals :  num [1:12] 1 0 0 0 5 6 7 8 9 10 ...\nwcsv : function (obj, file, header = T)  \ny :  int [1:3] 5 2 7\nyears :  num [1:12] 1952 1957 1962 1967 1972 ...\nz : List of 2\n $ a: num 3\n $ b: chr [1:2] \"sam\" \"yang\"\n\n\n\n\nSaving and reloading the workspace\nFinally we can save the objects in our R session for later use (or to give to someone else):\n\nls()\n\n [1] \"country\"       \"denslines\"     \"densplot\"      \"devs\"         \n [5] \"dim2\"          \"f.dplot\"       \"f.ess\"         \"f.ess.old\"    \n [9] \"f.flushplot\"   \"f.gm\"          \"f.grstat\"      \"f.identity\"   \n[13] \"f.invlogit\"    \"f.logit\"       \"f.lonlat2eucl\" \"f.merge\"      \n[17] \"f.sort\"        \"f.sort2\"       \"f.trimat\"      \"f.vecrep\"     \n[21] \"format_bytes\"  \"getNcdf\"       \"im\"            \"indices\"      \n[25] \"ln\"            \"lnm\"           \"ls_sizes\"      \"makePoly\"     \n[29] \"mySeq\"         \"nums\"          \"pmap\"          \"pmap2\"        \n[33] \"pointsInPoly\"  \"pplot\"         \"print.quitter\" \"q\"            \n[37] \"R2\"            \"rcsv\"          \"temp.colors\"   \"thresh\"       \n[41] \"time_chol\"     \"tplot\"         \"tsplot\"        \"val\"          \n[45] \"Val\"           \"vals\"          \"wcsv\"          \"y\"            \n[49] \"years\"         \"z\"            \n\nsave.image('intro.Rda')\nrm(list = ls())\nls()\n\ncharacter(0)\n\nload('intro.Rda') \n# the result of this may not be quite right in the slide version\nls()\n\n [1] \"country\"       \"denslines\"     \"densplot\"      \"devs\"         \n [5] \"dim2\"          \"f.dplot\"       \"f.ess\"         \"f.ess.old\"    \n [9] \"f.flushplot\"   \"f.gm\"          \"f.grstat\"      \"f.identity\"   \n[13] \"f.invlogit\"    \"f.logit\"       \"f.lonlat2eucl\" \"f.merge\"      \n[17] \"f.sort\"        \"f.sort2\"       \"f.trimat\"      \"f.vecrep\"     \n[21] \"format_bytes\"  \"getNcdf\"       \"im\"            \"indices\"      \n[25] \"ln\"            \"lnm\"           \"ls_sizes\"      \"makePoly\"     \n[29] \"mySeq\"         \"nums\"          \"pmap\"          \"pmap2\"        \n[33] \"pointsInPoly\"  \"pplot\"         \"print.quitter\" \"q\"            \n[37] \"R2\"            \"rcsv\"          \"temp.colors\"   \"thresh\"       \n[41] \"time_chol\"     \"tplot\"         \"tsplot\"        \"val\"          \n[45] \"Val\"           \"vals\"          \"wcsv\"          \"y\"            \n[49] \"years\"         \"z\"            \n\n\n\n\nPackages\nLet’s check out the packages on CRAN. In particular check out the CRAN Task Views.\nEssentially any well-established and many not-so-established statistical methods and other functionality is available in a package.\nIf you want to sound like an R expert, make sure to call them packages and not libraries. A library is the location in the directory structure where the packages are installed/stored.\n\n\nUsing packages\nTwo steps (similar to Python and Julia):\n\nInstall the package on your machine\n\none-time only - the package will be a set of files in the filesystem\n\nLoad the package\n\nevery time you start R and need to use a given package - the package will be loaded into memory\n\n\nTo install a package, in RStudio, just do Packages-&gt;Install Packages.\nFrom the command line, you generally will just do\n\ninstall.packages('gapminder') \n\nIf you’re on a network and are not the administrator of the machine, you may need to explicitly tell R to install it in a directory you are able to write in:\n\ninstall.packages('gapminder', lib = file.path('~', 'R'))\n\nIf you’re using R directly installed on your laptop, now would be a good point to install the various packages we need for the bootcamp, which can be done easily with the following command:\n\ninstall.packages(c('chron','colorspace','codetools', 'DBI','devtools',\n                   'dichromat','digest','doFuture','dplyr', 'fields',\n                   'foreach','future.apply', 'gapminder', 'ggplot2',\n                   'gridExtra','gtable','inline','iterators','knitr',\n                   'labeling','lattice','lme4','mapproj','maps','munsell',\n                   'proftools','proto','purrr','R6','rbenchmark',\n                   'RColorBrewer','Rcpp','reshape2','rJava',\n                   'RSQLite', 'scales','spam','stringr','tidyr','xlsx',\n                   'xlsxjars','xtable'))\n\nNote that packages often are dependent on other packages so these dependencies may be installed and loaded automatically. E.g., fields depends on maps and on spam.\n\n\nGeneral information about a package\nYou can use syntax as follows to get a list of the objects in a package and a brief description:\n\nlibrary(help = packageName)\n\nOn CRAN there often vignettes that are an overview and describe usage of a package if you click on a specific package. The reference manual is just a single document with the help files for all of the objects/functions in a package, so may be helpful but often it’s hard to get the big picture view from that.\n\n\nThe working directory\nTo read and write from R, you need to have a firm grasp of where in the computer’s filesystem you are reading and writing from.\n\n## What directory does R look for files in (working directory)?\ngetwd()\n\n## Changing the working directory (Linux/Mac specific)\nsetwd('~/Desktop') # change the working directory\nsetwd('/Users/paciorek/Desktop') # absolute path (here on MacOS)\ngetwd()\nsetwd('r-voleon-2025/units') # relative path\nsetwd('../tmp') # relative path, up and back down the tree\n\n## Changing the working directory (Windows specific)\n## Windows - use either \\\\ or / to indicate directories\n# setwd('C:\\\\Users\\\\Your_username\\\\Desktop\\\\r-voleon-2025')\n# setwd('..\\\\r-voleon-2025')\n\n## Changing the working directory (platform-agnostic)\nsetwd(file.path('~', 'Desktop', 'r-voleon-2025', 'modules')) # change the working directory\nsetwd(file.path('/', 'Users', 'paciorek', 'Desktop', 'r-voleon-2025', 'modules')) # absolute path\ngetwd()\nsetwd(file.path('..', 'data')) # relative path\n\nMany errors and much confusion result from you and R not being on the same page in terms of where in the directory structure you are.\nIn RStudio, you can use Session -&gt; Set Working Directory instead of setwd.\n\n\nWriting functions\nHere’s the syntax for writing our own function.\n\nadd_constant &lt;- function(x, constant = 0) {\n   result &lt;- x + constant\n   return(result)\n}\n\nadd_constant(7)\nadd_constant(7, 5)\n\nadd_constant(1:6, 5)\n\n\n\n\nFunction arguments\nR can match arguments by name (when provided) or by position (the fall-back). It also allows one to specify default values so that the user doesn’t have to explicitly provide all the arguments.\n\nlog(100)\n\n[1] 4.60517\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\nlog(base = 10, 100)\n\n[1] 2\n\nlog(base = 10, x = 100)\n\n[1] 2\n\n\n\n\nBranching (if-then-else syntax)\nOften we need our code to do different things depending on whether some condition is true or false.\nHere’s a simple example to illustrate the syntax. Note that the then is implicit.\n\nval &lt;- rnorm(1)\nval\n\n[1] 0.505331\n\nif (val &lt; 0) {\n  print(\"val is negative\")\n} else {\n  print(\"val is positive\")\n}\n\n[1] \"val is positive\"\n\n\nWe can chain together if statements as follows.\n\nval &lt;- rnorm(1)\nval\n\n[1] -0.6492264\n\nif (val &lt; -1) {\n  print(\"val is more than one standard deviation below the mean.\")\n} else if (abs(val) &lt;= 1) {\n  print(\"val is within one standard deviation of the mean.\")\n} else {\n  print(\"val is more than one standard deviation above the mean.\")\n}\n\n[1] \"val is within one standard deviation of the mean.\"\n\n\nIn general, the { brackets are only needed if you have multiple R expressions, but R will complain when an else starts a line of code, so generally using the { is good practice. That said, this works just fine:\n\nif (val &lt; 0) print(\"val is negative\") else print(\"val is positive\")\n\n[1] \"val is negative\"\n\n\n\n\nLoops\nIn many languages, looping (for loops, while loops, etc.) is one of the main constructs used to carry out computation. Loops are not emphasized as much in R, both because they can be slow and because other syntax (vectorized calls, lapply, etc.) is often cleaner, as we’ll see in a later module.\nBut there are lots of times when using a loop does make sense.\nMost of you are probably familiar at least with the basic idea of iterating through a series of steps. A for loop iterates through a pre-determined number of iterations, while a while loop iterates until some condition is met. For loops are more common in R, but while loops can be handy particularly for things like optimization.\nHere’s some example syntax.\n\nx &lt;- rnorm(50)\ncnt_neg &lt;- 0\nfor(i in seq_along(x)) {\n    if(x[i] &lt; 0) {\n       x[i] &lt;- 0\n       cnt_neg &lt;- cnt_neg + 1\n    }\n}\ncat(\"Found \", cnt_neg, \" negative values.\\n\")\n\nFound  25  negative values.\n\n\nThat said, the canonical way to do that in R is via vectorized operation:\n\nx[x &lt; 0] &lt;- 0\nx\n\n [1] 0.00000000 0.22005349 0.78398142 0.00000000 0.00000000 0.68707361\n [7] 0.86065167 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000\n[13] 0.00000000 0.68289856 0.41828775 0.00000000 0.99664315 0.00000000\n[19] 0.51522929 0.17357446 0.23358684 1.15640429 0.02864767 0.00000000\n[25] 0.68767266 0.94465793 0.00000000 0.00000000 0.00000000 0.35246404\n[31] 0.00000000 0.21089781 0.53904124 1.37227080 0.20364847 0.00000000\n[37] 1.46720518 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000\n[43] 1.13645032 0.21647624 1.18173567 0.00000000 0.00000000 0.65171864\n[49] 0.00000000 1.45453707\n\n\n\n\nWhile loop\nIt’s not a particularly interesting example, but we can see the while loop syntax in the same example. In this case\n\nfound &lt;- FALSE\ni &lt;- 1\nwhile(!found && i &lt;= length(vals)) {\n     if(x[i] &gt; 3) {\n       print(x[i])\n       found &lt;- TRUE\n     }\n     i &lt;- i+1\n}\n\n\n\nBreakout\nHere are some questions to get some practice with the syntax.\n\nCreate a variable called ‘x’ that contains the mean of 100 random uniform numbers.\nUse functions in R to round ‘x’ to two decimal places and to two significant digits.\nMake sure you are able to install packages from CRAN. E.g., try to install gapminder.\nFigure out what your current working directory is.\nPut the data/cpds.csv file in some other directory on your computer, such as Downloads. Use setwd() to set your working directory to be that directory. Read the file in using read.csv(). Now use setwd() to point to a different directory such as Desktop. Write the data frame out to a file using write.csv. You may also want to experiment with figuring out how to write it out without any row names and without quotes on the character strings.\nWrite an R function that will take an input vector and set any negative values in the vector to zero.\nWrite an R function that will take an input vector and set any value below a threshold to be the value of threshold. Optionally, the function should instead set values above a threshold to the value of the threshold.",
    "crumbs": [
      "Modules (a partial set)",
      "Basic Introduction (Module \"0\")"
    ]
  },
  {
    "objectID": "units/data.html",
    "href": "units/data.html",
    "title": "Data Structures and Manipulations",
    "section": "",
    "text": "I encourage you to:\n\nTry out the code as we walk through it.\nKeep your eyes open! – We’ll illustrate a lot of syntax and concepts by example.\nTry to guess what the syntax means in cases we haven’t yet seen that syntax.\nPlay with it and try variations and try to break it and see what happens.\nAsk questions and comment if something interesting happens as you experiment.\n\nThis is a bootcamp. So there may be some pain involved! If you find yourself not following everything, that’s ok. You may miss some details, but try to follow the basics and the big picture.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#na-is-a-missing-value",
    "href": "units/data.html#na-is-a-missing-value",
    "title": "Data Structures and Manipulations",
    "section": "NA is a missing value",
    "text": "NA is a missing value\n\nvec &lt;- rnorm(12)\nvec[c(3, 5)] &lt;- NA\nvec\n\n [1]  1.06364746 -1.24763359          NA  0.67934311          NA -1.77165468\n [7]  2.04246591 -0.07929869  0.06193655  0.33699900 -0.23198481  0.34626071\n\nlength(vec)\n\n[1] 12\n\nsum(vec)\n\n[1] NA\n\nsum(vec, na.rm = TRUE)\n\n[1] 1.200081\n\nhist(vec)\n\n\n\n\n\n\n\nis.na(vec)\n\n [1] FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nBe careful because many R functions won’t warn you that they are ignoring the missing values.",
    "crumbs": [
      "Modules (a partial set)",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#to-infinity-and-beyond",
    "href": "units/data.html#to-infinity-and-beyond",
    "title": "Data Structures and Manipulations",
    "section": "To infinity and beyond",
    "text": "To infinity and beyond\n\nbig &lt;- 1e500 \nbig\n\n[1] Inf\n\nbig + 7\n\n[1] Inf",
    "crumbs": [
      "Modules (a partial set)",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#nan-stands-for-not-a-number",
    "href": "units/data.html#nan-stands-for-not-a-number",
    "title": "Data Structures and Manipulations",
    "section": "NaN stands for Not a Number",
    "text": "NaN stands for Not a Number\n\nsqrt(-5)\n\nWarning in sqrt(-5): NaNs produced\n\n\n[1] NaN\n\nbig - big\n\n[1] NaN\n\n1/0\n\n[1] Inf",
    "crumbs": [
      "Modules (a partial set)",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#null",
    "href": "units/data.html#null",
    "title": "Data Structures and Manipulations",
    "section": "NULL",
    "text": "NULL\nNA can hold a place but NULL cannot. NULL is useful for having a function argument default to ‘nothing’. See help(crossprod), which can compute either \\(X^{\\top}X\\) or \\(X^{\\top}Y\\).\n\nc(3, NA, 7)\n\n[1]  3 NA  7\n\nc(3, NULL, 7)\n\n[1] 3 7\n\nmylist &lt;- list(3, 5, 7)\nmylist[[2]] &lt;- NULL\nmylist\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 7",
    "crumbs": [
      "Modules (a partial set)",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#by-direct-indexing",
    "href": "units/data.html#by-direct-indexing",
    "title": "Data Structures and Manipulations",
    "section": "1) by direct indexing",
    "text": "1) by direct indexing\n\nvec[c(3, 5, 12:14)]\n\n[1] 72.301 75.320 65.554 74.852 50.728\n\nvec[-c(3,5)]\n\n  [1] 43.828 76.423 42.731 81.235 79.829 75.635 64.062 79.441 56.728 65.554\n [11] 74.852 50.728 72.390 73.005 52.295 49.580 59.723 50.430 80.653 44.741\n [21] 50.651 78.553 72.961 72.889 65.152 46.462 55.322 78.782 48.328 75.748\n [31] 78.273 76.486 78.332 54.791 72.235 74.994 71.338 71.878 51.579 58.040\n [41] 52.947 79.313 80.657 56.735 59.448 79.406 60.022 79.483 70.259 56.007\n [51] 46.388 60.916 70.198 82.208 73.338 81.757 64.698 70.650 70.964 59.545\n [61] 78.885 80.745 80.546 72.567 82.603 72.535 54.110 67.297 78.623 77.588\n [71] 71.993 42.592 45.678 73.952 59.443 48.303 74.241 54.467 64.164 72.801\n [81] 76.195 66.803 74.543 71.164 42.082 62.069 52.906 63.785 79.762 80.204\n [91] 72.899 56.867 46.859 80.196 75.640 65.483 75.537 71.752 71.421 71.688\n[101] 75.563 78.098 78.746 76.442 72.476 46.242 65.528 72.777 63.062 74.002\n[111] 42.568 79.972 74.663 77.926 48.159 49.339 80.941 72.396 58.556 39.613\n[121] 80.884 81.701 74.143 78.400 52.517 70.616 58.420 69.819 73.923 71.777\n[131] 51.542 79.425 78.242 76.384 73.747 74.249 73.422 62.698 42.384 43.487\n\ngapminder[c(2,4), 5]\n\n[1] 30.332 34.020\n\ngapminder[c(2,4), 'lifeExp']\n\n[1] 30.332 34.020",
    "crumbs": [
      "Modules (a partial set)",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#by-a-vector-of-logicals",
    "href": "units/data.html#by-a-vector-of-logicals",
    "title": "Data Structures and Manipulations",
    "section": "2) by a vector of logicals",
    "text": "2) by a vector of logicals\n\nwealthy &lt;- gapminder$gdpPercap &gt; 50000\ngapminder$gdpPercap[wealthy]\n\n[1] 108382.35 113523.13  95458.11  80894.88 109347.87  59265.48\n\ngapminder[wealthy, ]\n\n    country year     pop continent lifeExp gdpPercap\n853  Kuwait 1952  160000      Asia  55.565 108382.35\n854  Kuwait 1957  212846      Asia  58.033 113523.13\n855  Kuwait 1962  358266      Asia  60.470  95458.11\n856  Kuwait 1967  575003      Asia  64.624  80894.88\n857  Kuwait 1972  841934      Asia  67.712 109347.87\n858  Kuwait 1977 1140357      Asia  69.343  59265.48\n\n\nWhat happened in the last subsetting operation?",
    "crumbs": [
      "Modules (a partial set)",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#by-a-vector-of-names",
    "href": "units/data.html#by-a-vector-of-names",
    "title": "Data Structures and Manipulations",
    "section": "3) by a vector of names",
    "text": "3) by a vector of names\n\nmat[c('a', 'd', 'a'), ]\n\n  [,1] [,2] [,3] [,4] [,5]\na    1    5    9   13   17\nd    4    8   12   16   20\na    1    5    9   13   17",
    "crumbs": [
      "Modules (a partial set)",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/data.html#using-dplyr-tools-such-as-filter-and-select-more-in-module-4",
    "href": "units/data.html#using-dplyr-tools-such-as-filter-and-select-more-in-module-4",
    "title": "Data Structures and Manipulations",
    "section": "4) using dplyr tools such as filter() and select() – more in Module 4",
    "text": "4) using dplyr tools such as filter() and select() – more in Module 4",
    "crumbs": [
      "Modules (a partial set)",
      "Data Structures"
    ]
  },
  {
    "objectID": "units/programming.html",
    "href": "units/programming.html",
    "title": "Programming Concepts and Tools",
    "section": "",
    "text": "R is a functional language\nFunctions are one of the most important constructs in R (and many other languages). They allow you to modularize your code - encapsulating a set of repeatable operations as an individual function call.\n\nOperations are carried out with functions. Functions take objects as inputs and return objects as outputs.\nAn analysis can be considered a pipeline of function calls, with output from a function used later in a subsequent operation as input to another function.\nFunctions themselves are objects with a class and that you can manipulate:\n\n\nmedian\n\nfunction (x, na.rm = FALSE, ...) \nUseMethod(\"median\")\n&lt;bytecode: 0x5e573fa30a20&gt;\n&lt;environment: namespace:stats&gt;\n\nargs(median)\n\nfunction (x, na.rm = FALSE, ...) \nNULL\n\nclass(median)\n\n[1] \"function\"\n\nmyfun &lt;- median\nlapply(list(c(2,4), c(2,6)), myfun)\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 4\n\n\n\n\nUsing functions\nYou should rely heavily on functions rather than having long sets of expressions in R scripts.\nFunctions have many important advantages:\n\nThey reduce bugs by avoiding having multiple instances of the same functionality.\nThey reduce time involved in coding by eliminating redundancy.\nThey make for cleaner and more easily-readable code.\n\nA basic goal is writing functions is modularity.\nIn general, a function should\n\nbe fairly short,\nbe focused and specific in what it does,\nbe designed so that it can be used in combination with other functions to carry out more complicated operations,\ngenerally make use only of arguments to the function and internal variables.\n\n\n\nFunction arguments\nR can match arguments by name (when provided) or by position (the fall-back). It also allows one to specify default values so that the user doesn’t have to explicitly provide all the arguments.\n\nlog(100)\n\n[1] 4.60517\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\nlog(base = 10, 100)\n\n[1] 2\n\nlog(base = 10, x = 100)\n\n[1] 2\n\n\n\n\nWhat is the “…” argument for?\nThe ... construct allows a function to take an unspecified number of arguments, e.g.,\n\nc\n\nfunction (...)  .Primitive(\"c\")\n\nsum\n\nfunction (..., na.rm = FALSE)  .Primitive(\"sum\")\n\n\nUsing ... as one of the arguments to a function allows a function to pass along user-provided arguments without specifying explicitly what the user might provide.\nHere’s an example of tailoring some plotting specifications that I use a lot.\n\npplot &lt;- function(x, y, ...) {\n      plot(x, y, pch = 16, cex = 0.6, ...)\n}\n\npplot(gapminder$gdpPercap, gapminder$lifeExp,  xlab = 'gdpPercap (log $)',\n      ylab = 'life expectancy (years)', log = 'x')\n\n\n\n\n\n\n\n\n\n\nPass-by-value\nFunctions in R are (roughly) pass-by-value and not pass-by-reference. This means that if you modify an argument inside the function it will not change the original value outside the function.\n\nx &lt;- rnorm(3)\n\nmyfun &lt;- function(x) {\n      x[1] &lt;- 0\n      return(x)\n}      \n\nnew_x &lt;- myfun(x)\nprint(new_x)\n\n[1] 0.00000000 0.08431392 0.12083039\n\nprint(x)\n\n[1] 1.03319065 0.08431392 0.12083039\n\n\nThis protects you from a major potential source of side effects. (There are exceptions to this rule.)\n\n\nCall-by-value\nIn actuality, functions in R are call-by-value.\nThis behavior is equivalent to copy-on-modify discussed in Unit 2.\n\nlibrary(pryr)\nif(exists('y')) rm(y)\n\nf &lt;- function(x, print_mem = FALSE){\n    if(print_mem) print(mem_used())\n    cat(\"Address of x from `address()`:\\n\")\n    print(address(x))  # address() is wrong here!\n    cat(\"Address of x from `inspect()`:\\n\")\n    print(.Internal(inspect(x)))\n\n    x[1] &lt;- 7\n    if(print_mem) print(mem_used())\n    cat(\"Address of x after modification:\\n\")\n    return(x)\n}\n\nn &lt;- 10\ny &lt;- rnorm(n)\ny[1:3]\n\n[1]  0.8923094 -0.2120904  0.5483678\n\ncat(\"Address of y:\\n\")\n\nAddress of y:\n\nprint(address(y))\n\n[1] \"0x5e5743f805a8\"\n\nz &lt;- f(y)\n\nAddress of x from `address()`:\n[1] \"0x5e5742c01140\"\nAddress of x from `inspect()`:\n@5e5743f805a8 14 REALSXP g0c5 [REF(3)] (len=10, tl=0) 0.892309,-0.21209,0.548368,-2.24,0.0170996,...\n [1]  0.89230944 -0.21209043  0.54836775 -2.23999672  0.01709957  0.90164560\n [7] -0.66734049  0.81807226  0.24342160 -0.06499593\nAddress of x after modification:\n\nz[1:3]\n\n[1]  7.0000000 -0.2120904  0.5483678\n\ncat(\"Address of z:\\n\")\n\nAddress of z:\n\nprint(address(z))\n\n[1] \"0x5e5743f7eef8\"\n\n\nStrangely, address gives the wrong answer when used inside f above. I’m not sure what is going on, but using .Internal(inspect) or trying this with a large value of n and seeing that memory use does not increase confirms that copy-on-modify is working.\n\n\nVariable scope and global variables\nIn general functions should not make use of variables from outside the function. (However, for quick-and-dirty work and in some other circumstances, one may do this.) This provides modularity and reduces bugs and surprises.\nIf R can’t find a variable that is used in a function based on the function arguments and variables defined locally in the function, it goes and looks elsewhere following a set of rules called lexical scoping.\n(This type of scoping has to do with R’s roots (and explains why R is very similar to other languages for functional programming) - we won’t go into details here but certainly worth looking into as you start using R more.)\nBasically this means that it looks for variables relative to where the function is defined (not relative to where the function is called).\nThis can get involved, but a couple brief examples illustrate the basic idea.\n\nx &lt;- 2\nf &lt;- function(y) {\n    return(x + y)\n}\nf(1)\n\n[1] 3\n\ng &lt;- function(y) {\n  x &lt;- 10\n  return(f(y))\n}\n\ng(1)\n\n[1] 3\n\ng &lt;- function(y) {\n  f &lt;- function(y) {\n     return(x + y)\n  }\n  x &lt;- 10\n  return(f(y))\n}\n\ng(1)\n\n[1] 11\n\n\nNote that x is used as a global variable here, which in general is bad practice.\n\n\nWhy does scoping work that way?\nConsider the lm function. It uses lm.fit for its actual computation.\nSuppose scoping depended on where the function (lm in this case) is called from? What would happen now:\n\nx &lt;- rnorm(5)\ny &lt;- rnorm(5)\nlm(y ~ x)\n\nlm.fit &lt;- function(...) print('Better luck next time, sucker.')\n\nlm.fit()\nlm(y~x)\n\nR’s scoping, in combination with package namespaces (collections of variables associated with a package) protects against this kind of problem.\n\n\nObject-oriented programming (OOP) in R\nConfusingly, R has three (well, actually five) different systems for OOP. This can be confusing, but they get the job done for a lot of tasks.\n\nS3: informal system used for lm(), glm(), and many other core features in R in the stats package\nS4 (and R7): more formal system, used with lme4\nR6 (and Reference Classes): new systems allowing for passing objects by reference, with R6 similar to OOP in other languages\n\nFor most users, I think it’s enough to understand two of the systems:\n\nTo understand how base R works, it’s helpful to understand S3.\nTo use OOP in a fashion similar to Python and C++, I suggest using R6.\n\n\n\nBasics of object-oriented programming (OOP)\nThe basic idea is that coding is structured around objects, which belong to a class, and methods that operate on objects in the class.\nObjects are like lists, but with methods that are specifically associated with particular classes.\nObjects have fields, analogous to the components of a list.\n\n\nWorking with S3 classes and methods\nS3 objects are generally built upon lists.\n\nmod &lt;- lm(gapminder$lifeExp ~ log(gapminder$gdpPercap))\nclass(mod)\n\n[1] \"lm\"\n\nis.list(mod)\n\n[1] TRUE\n\nnames(mod)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\nmod$coefficients\n\n             (Intercept) log(gapminder$gdpPercap) \n               -9.100889                 8.405085 \n\nmod[['coefficients']]\n\n             (Intercept) log(gapminder$gdpPercap) \n               -9.100889                 8.405085 \n\nmod[[1]]\n\n             (Intercept) log(gapminder$gdpPercap) \n               -9.100889                 8.405085 \n\n\nThe magic of R’s S3 OOP approach here is that ‘generic’ methods (i.e., functions) can be tailored to work specifically with specific kinds of objects. This has been called “functional OOP” because the generic methods look like regular functions. It’s basically how Julia works as well.\n\nsummary(gapminder$lifeExp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.60   48.20   60.71   59.47   70.85   82.60 \n\nsummary(mod)\n\n\nCall:\nlm(formula = gapminder$lifeExp ~ log(gapminder$gdpPercap))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.778  -4.204   1.212   4.658  19.285 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               -9.1009     1.2277  -7.413 1.93e-13 ***\nlog(gapminder$gdpPercap)   8.4051     0.1488  56.500  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.62 on 1702 degrees of freedom\nMultiple R-squared:  0.6522,    Adjusted R-squared:  0.652 \nF-statistic:  3192 on 1 and 1702 DF,  p-value: &lt; 2.2e-16\n\n\nQuestion: What do you think R is doing behind the scenes?\nConsider summary.lm.\n\n\nMore on working with S3 classes and methods\n\nlibrary(methods)\nyb &lt;- gapminder$lifeExp &gt; 75\nyc &lt;- gapminder$lifeExp\nx &lt;- log(gapminder$gdpPercap)\nmod1 &lt;- lm(yc ~ x)\nmod2 &lt;- glm(yb ~ x, family = binomial)\nmod2$residuals[1:20] # access field with list-like syntax\n\n        1         2         3         4         5         6         7         8 \n-1.000026 -1.000031 -1.000035 -1.000033 -1.000022 -1.000027 -1.000054 -1.000035 \n        9        10        11        12        13        14        15        16 \n-1.000015 -1.000014 -1.000021 -1.000053 -1.000258 -1.000477 -1.000832 -1.001461 \n       17        18        19        20 \n-1.002613 -1.003204 -1.003496 -1.003838 \n\nclass(mod2)\n\n[1] \"glm\" \"lm\" \n\nis(mod2, \"lm\")\n\n[1] TRUE\n\nis.list(mod2)\n\n[1] TRUE\n\nnames(mod2)\n\n [1] \"coefficients\"      \"residuals\"         \"fitted.values\"    \n [4] \"effects\"           \"R\"                 \"rank\"             \n [7] \"qr\"                \"family\"            \"linear.predictors\"\n[10] \"deviance\"          \"aic\"               \"null.deviance\"    \n[13] \"iter\"              \"weights\"           \"prior.weights\"    \n[16] \"df.residual\"       \"df.null\"           \"y\"                \n[19] \"converged\"         \"boundary\"          \"model\"            \n[22] \"call\"              \"formula\"           \"terms\"            \n[25] \"data\"              \"offset\"            \"control\"          \n[28] \"method\"            \"contrasts\"         \"xlevels\"          \n\nmethods(class = \"glm\")\n\n [1] add1           anova          coerce         confint        cooks.distance\n [6] deviance       drop1          effects        extractAIC     family        \n[11] formula        influence      initialize     logLik         model.frame   \n[16] nobs           predict        print          profile        residuals     \n[21] rstandard      rstudent       show           sigma          slotsFromS3   \n[26] summary        vcov           weights       \nsee '?methods' for accessing help and source code\n\nmethods(predict)\n\n [1] predict.ar*                predict.Arima*            \n [3] predict.arima0*            predict.glm               \n [5] predict.HoltWinters*       predict.lm                \n [7] predict.loess*             predict.mlm*              \n [9] predict.nls*               predict.poly*             \n[11] predict.ppr*               predict.prcomp*           \n[13] predict.princomp*          predict.smooth.spline*    \n[15] predict.smooth.spline.fit* predict.StructTS*         \nsee '?methods' for accessing help and source code\n\npredict\n\nfunction (object, ...) \nUseMethod(\"predict\")\n&lt;bytecode: 0x5e573fa97028&gt;\n&lt;environment: namespace:stats&gt;\n\n# predict.glm\n\nWhen predict() is called on a GLM object, it first calls the generic predict(), which then recognizes that the first argument is of the class glm and immediately calls the right class-specific method, predict.glm() in this case.\n\n\nMaking your own S3 class/object/method\nMaking an object and class-specific methods under S3 is simple.\n\nrboot2025 &lt;- list(month = 'August', year = 2025, \n  instructor = 'Paciorek', attendance = 100)\nclass(rboot2025) &lt;- \"workshop\"\n\nrboot2025\n\n$month\n[1] \"August\"\n\n$year\n[1] 2025\n\n$instructor\n[1] \"Paciorek\"\n\n$attendance\n[1] 100\n\nattr(,\"class\")\n[1] \"workshop\"\n\nis(rboot2025, \"workshop\")\n\n[1] TRUE\n\nrboot2025$instructor \n\n[1] \"Paciorek\"\n\nprint.workshop &lt;- function(x) {\n    with(x,\n       cat(\"A workshop held in \", month, \" \", year, \"; taught by \", instructor, \".\\nThe attendance was \", attendance, \".\\n\", sep = \"\"))\n    invisible(x)\n}\n\n# doesn't execute correctly in the slide creation, so comment out here:\n# rboot2025 \n\nNote that we rely on the generic print() already existing in R. Otherwise we’d need to create it.\n\n\nBrief introduction to R6 Classes\nR6 classes are a somewhat-recent feature in R that provides object-oriented programming with behavior more like in other languages like Python and C++.\nHere’s an extended example that simulates random time series.\n\nlibrary(R6)\n\ntsSimClass &lt;- R6Class(\"tsSimClass\",\n    ## Class for holding time series simulators\n    public = list(\n        ## Public methods (and possibly fields) are the user-facing interface.\n        initialize = function(times, mean = 0, corParam = 1){\n            library(fields)\n            stopifnot(is.numeric(corParam), length(corParam) == 1)\n            stopifnot(is.numeric(times))\n            private$times &lt;- times\n            private$n &lt;- length(times)\n            private$mean &lt;- mean\n            private$corParam &lt;- corParam\n            private$currentU &lt;- FALSE\n            private$calcMats()\n        },\n\n        simulate = function() {\n            if(!private$currentU)\n                private$calcMats()\n            ## analogous to mu+sigma*z for generating N(mu, sigma^2)\n            return(private$mean + crossprod(private$U, rnorm(private$n)))\n        },\n        \n        changeTimes = function(newTimes){\n            # Modifies a private member field (i.e., a 'setter') and recalculates.\n            private$times &lt;- newTimes\n            private$calcMats()\n        },\n        \n        getTimes = function(){\n            # A 'getter' method\n            return(private$times)\n        },\n\n        print = function(){ # 'print' method\n            cat(\"R6 Object of class 'tsSimClass' with \",\n                private$n, \" time points.\\n\", sep = '')\n            invisible(self)\n        }\n    ),\n\n    ## Private methods and functions not accessible externally\n    private = list(\n        calcMats = function() {\n            ## Calculates correlation matrix and Cholesky factor.\n            ## Caches results of expensive computation.\n            lagMat &lt;- fields::rdist(private$times) # local variable\n            corMat &lt;- exp(-lagMat^2 / private$corParam^2)\n            private$U &lt;- chol(corMat) # square root matrix\n            cat(\"Done updating correlation matrix and Cholesky factor.\\n\")\n            private$currentU &lt;- TRUE\n            invisible(self)\n        },\n        # Internal (private) fields not directly accessible from outside the object\n        n = NULL, \n        times = NULL,\n        mean = NULL,\n        corParam = NULL,\n        U = NULL,\n        currentU = FALSE\n    )\n)   \n\nmy_ts &lt;- tsSimClass$new(1:100, 2, 1)\n\nLoading required package: spam\n\n\nSpam version 2.11-1 (2025-01-20) is loaded.\nType 'help( Spam)' or 'demo( spam)' for a short introduction \nand overview of this package.\nHelp for individual functions is also obtained by adding the\nsuffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n\n\n\nAttaching package: 'spam'\n\n\nThe following objects are masked from 'package:base':\n\n    backsolve, forwardsolve\n\n\nLoading required package: viridisLite\n\n\n\nTry help(fields) to get started.\n\n\nDone updating correlation matrix and Cholesky factor.\n\nmy_ts\n\nR6 Object of class 'tsSimClass' with 100 time points.\n\nset.seed(1)\ny &lt;- my_ts$simulate()   # Generate a time series.\nplot(my_ts$getTimes(), y, type = 'l', xlab = 'time',\n      ylab = 'process values')\n## We can't directly access private fields or methods.\n## These will fail:\n# my_ts$times\n# my_ts$calcMats()\n\nmy_ts &lt;- tsSimClass$new(1:100, 2, 3)\n\nDone updating correlation matrix and Cholesky factor.\n\nset.seed(1)\ny &lt;- my_ts$simulate()   # generate a second time series\nlines(my_ts$getTimes(), y, col = 'red')\n\n\n\n\n\n\n\n\n\n\nError and warning messages\nWhen you write your own functions, and particularly for distributing to others, it’s a good idea to:\n\nCheck for possible errors (particularly in the input arguments) and give the user an informative error message,\nWarn them if you’re detect or do something they might not have anticipated,\n\nWe can use stop() and warning() to do this. They’re the same functions that are being called when you see an error message or a warning in reaction to your own work in R.\n\nmysqrt &lt;- function(x) {\n  if(is.list(x)) {\n    warning(\"x is a list; converting to a vector\")\n    x &lt;- unlist(x)\n  }\n  if(!is.numeric(x)) {\n    stop(\"What is the square root of 'sarah'?\")\n  } else {\n      if(any(x &lt; 0)) {\n        warning(\"mysqrt: found negative values; proceeding anyway\")\n        x[x &gt;= 0] &lt;- (x[x &gt;= 0])^(1/2)\n        x[x &lt; 0] &lt;- NaN\n        return(x)\n      } else return(x^(1/2))\n  }\n}\n\nmysqrt(c(1, 2, 3))\n\n[1] 1.000000 1.414214 1.732051\n\nmysqrt(c(5, -7))\n\nWarning in mysqrt(c(5, -7)): mysqrt: found negative values; proceeding anyway\n\n\n[1] 2.236068      NaN\n\nmysqrt(c('asdf', 'sdf'))\n\nError in mysqrt(c(\"asdf\", \"sdf\")): What is the square root of 'sarah'?\n\nmysqrt(list(5, 3, 'ab'))\n\nWarning in mysqrt(list(5, 3, \"ab\")): x is a list; converting to a vector\n\n\nError in mysqrt(list(5, 3, \"ab\")): What is the square root of 'sarah'?\n\nsqrt(c(5, -7))\n\nWarning in sqrt(c(5, -7)): NaNs produced\n\n\n[1] 2.236068      NaN\n\nsqrt('asdf')\n\nError in sqrt(\"asdf\"): non-numeric argument to mathematical function\n\nsqrt(list(5, 3, 2))\n\nError in sqrt(list(5, 3, 2)): non-numeric argument to mathematical function\n\n\nSo we’ve done something similar to what sqrt() actually does in R.\n\n\n‘Catching’ errors\nWhen you automate analyses, sometimes an R function call will fail. But you don’t want all of your analyses to grind to a halt because one failed. Rather, you want to catch the error, record that it failed, and move on.\nFor me this is most critical when I’m doing stratified analyses or sequential operations.\nThe try() function is a powerful tool here.\n\n\nWhy we need to try()\nSuppose we tried to do a stratified analysis of life expectancy on GDP within continents, for 2007. I’m going to do this as a for loop for pedagogical reasons, but it would be better to do this with dplyr/lapply type tools.\nFor the purpose of illustration, I’m going to monkey a bit with the data such that there is an error in fitting Oceania. This is artificial, but when you stratify data into smaller groups it’s not uncommon that the analysis can fail for one of the groups (often because of small sample size or missing data).\n\nmod &lt;- list()\nfakedat &lt;- gapminder[gapminder$year == 2007, ]\nfakedat$gdpPercap[fakedat$continent == 'Oceania'] &lt;- NA\n\nfor(cont in c('Asia', 'Oceania', 'Europe', 'Americas', 'Africa')) {\n      cat(\"Fitting model for continent \", cont, \".\\n\")\n      tmp &lt;- subset(fakedat, continent == cont)\n      mod[[cont]] &lt;- lm(lifeExp ~ log(gdpPercap), data = tmp)\n}\n\nFitting model for continent  Asia .\nFitting model for continent  Oceania .\n\n\nError in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...): 0 (non-NA) cases\n\n\nWhat happened?\n\n\nHow we can try() harder\n\nmod &lt;- list()\nfakedat &lt;- gapminder[gapminder$year == 2007, ]\nfakedat$gdpPercap[fakedat$continent == 'Oceania'] &lt;- NA\n\nfor(cont in c('Asia', 'Oceania', 'Europe', 'Americas', 'Africa')) {\n       cat(\"Fitting model for continent \", cont, \".\\n\")\n       tmp &lt;- subset(fakedat, continent == cont)\n\n       # Run without error-ing out.\n       curMod &lt;- try(lm(lifeExp ~ log(gdpPercap), data = tmp))\n\n       # Catch the error.\n       if(is(curMod, \"try-error\")) mod[[cont]] &lt;- NA \n           else mod[[cont]] &lt;- curMod            \n}\n\nFitting model for continent  Asia .\nFitting model for continent  Oceania .\nError in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : \n  0 (non-NA) cases\nFitting model for continent  Europe .\nFitting model for continent  Americas .\nFitting model for continent  Africa .\n\nmod[[1]]\n\n\nCall:\nlm(formula = lifeExp ~ log(gdpPercap), data = tmp)\n\nCoefficients:\n   (Intercept)  log(gdpPercap)  \n        25.650           5.157  \n\nmod[[2]]\n\n[1] NA\n\n\n\n\nDebugging\nAs a scripting language, R essentially has a debugger working automatically by virtue of you often being able to easily run code line by line.\nBut there is an official debugger and other tools that greatly help in figuring out problems, particularly for more complicated situations.\nLet’s briefly see these in action. I’ll demo this in a very basic way, but hopefully this will give you an idea of the power of these tools.\n\nbuggyFun &lt;- function(myDF) {\n   print(names(myDF))\n   myDF$id &lt;- seq_len(nrow(myDF))\n   sums &lt;- rowSums(myDF)\n   return(sums)\n}\n\nbuggyFun(gapminder)\n\n[1] \"country\"   \"continent\" \"year\"      \"lifeExp\"   \"pop\"       \"gdpPercap\"\n\n\nError in base::rowSums(x, na.rm = na.rm, dims = dims, ...): 'x' must be numeric\n\n## Here are the commands we'll use in the demo.\nif(FALSE) {\n  traceback()\n  debug(buggyFun)\n  buggyFun(gapminder)\n\n  undebug(buggyFun)\n  options(error = recover)\n  buggyFun(gapminder)\n}\n\n\nWe can use debug() to step through a function line by line\nAfter an error occurs, we can use traceback() to look at the call stack (the series of nested function calls) to determine the steps leading to the error. (Note that Python error message show the stack. R’s do not.)\nMore helpfully, if we set options(error = recover) before running code, we can go into the function call in which the error occurred\nWe can insert browser() inside a function to set breakpoints and R will stop there and allow us to proceed with debugging statements\nYou can temporarily insert code into a function (including built-in functions) with trace(fxnName, edit = TRUE)\n\nThese tools are integrated into RStudio as a visual debugger.\n\n\nTesting\nTesting should be performed on multiple levels and begun as early as possible in the development process. For programs that accept input either from a user or file, it is important that the code validates the input is what it expects to receive. Tests that ensure individual code elements (e.g., functions, classes, and class methods) behave correctly are called unit tests. Writing unit tests early in the process of implementing new functionality helps you think about what you want a piece of code to do, rather than just how it does it. This practice improves code quality by focusing your attention on use cases rather than getting lost in implementation details.\nThe testthat package is very helpful for setting up tests.\nFor automated testing (continuous integration), many developers use GitHub Actions to run a test suite automatically (e.g., for each pull request or each commit). Here’s an example from an R package that I am a developer of. One creates a configuration (yaml) file and then GitHub runs the action automatically, giving the results in the Actions tab.\n\n\nBreakout\n\nBasics\n\nWrite an R function that will take an input vector and set any negative values in the vector to zero.\n\n\n\nUsing the ideas\n\nWrite an R function that will take an input vector and set any value below a threshold to be the value of threshold. Optionally, the function should instead set values above a threshold to the value of the threshold.\nAugment your function so that it checks that the input is a numeric vector and return an error if not. (See the help information for stop() (or stopifnot().)\nFigure out what invisible() does and why it is useful when writing functions. Use invisible() in your function from just above.\n\n\n\nAdvanced\n\nExplore scoping in the following code. Explain why the result is 11 and not 3. Note that funGenerator() returns a function as the return object, consistent with the idea that functions are objects in R. This is an example of what is called a closure in R. Basically, the function contains object(s) enclosed with and accessible to the function.\n\nfunGenerator &lt;- function(x) {\n  x &lt;- 10\n  g &lt;- function(y) {\n    return(x + y)\n  }\n  return(g)\n}\n\nx &lt;- 2\nf &lt;- funGenerator()\nf(1)\n\n[1] 11",
    "crumbs": [
      "Modules (a partial set)",
      "Programming"
    ]
  }
]